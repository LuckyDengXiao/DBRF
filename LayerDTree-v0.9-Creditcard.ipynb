{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119907.0</td>\n",
       "      <td>-0.611712</td>\n",
       "      <td>-0.769705</td>\n",
       "      <td>-0.149759</td>\n",
       "      <td>-0.224877</td>\n",
       "      <td>2.028577</td>\n",
       "      <td>-2.019887</td>\n",
       "      <td>0.292491</td>\n",
       "      <td>-0.523020</td>\n",
       "      <td>0.358468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075208</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>0.380739</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>-2.220686</td>\n",
       "      <td>-0.201146</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.221180</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78340.0</td>\n",
       "      <td>-0.814682</td>\n",
       "      <td>1.319219</td>\n",
       "      <td>1.329415</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.284871</td>\n",
       "      <td>-0.653985</td>\n",
       "      <td>0.321552</td>\n",
       "      <td>0.435975</td>\n",
       "      <td>-0.704298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128619</td>\n",
       "      <td>-0.368565</td>\n",
       "      <td>0.090660</td>\n",
       "      <td>0.401147</td>\n",
       "      <td>-0.261034</td>\n",
       "      <td>0.080621</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.059456</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82382.0</td>\n",
       "      <td>-0.318193</td>\n",
       "      <td>1.118618</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>-0.127052</td>\n",
       "      <td>0.569563</td>\n",
       "      <td>-0.532484</td>\n",
       "      <td>0.706252</td>\n",
       "      <td>-0.064966</td>\n",
       "      <td>-0.463271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305402</td>\n",
       "      <td>-0.774704</td>\n",
       "      <td>-0.123884</td>\n",
       "      <td>-0.495687</td>\n",
       "      <td>-0.018148</td>\n",
       "      <td>0.121679</td>\n",
       "      <td>0.249050</td>\n",
       "      <td>0.092516</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31717.0</td>\n",
       "      <td>-1.328271</td>\n",
       "      <td>1.018378</td>\n",
       "      <td>1.775426</td>\n",
       "      <td>-1.574193</td>\n",
       "      <td>-0.117696</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>0.681867</td>\n",
       "      <td>-0.031641</td>\n",
       "      <td>0.383872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220815</td>\n",
       "      <td>-0.419013</td>\n",
       "      <td>-0.239197</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.232829</td>\n",
       "      <td>0.814177</td>\n",
       "      <td>0.098797</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>15.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80923.0</td>\n",
       "      <td>1.276712</td>\n",
       "      <td>0.617120</td>\n",
       "      <td>-0.578014</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>0.061706</td>\n",
       "      <td>-1.472002</td>\n",
       "      <td>0.373692</td>\n",
       "      <td>-0.287204</td>\n",
       "      <td>-0.084482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160161</td>\n",
       "      <td>-0.430404</td>\n",
       "      <td>-0.076738</td>\n",
       "      <td>0.258708</td>\n",
       "      <td>0.552170</td>\n",
       "      <td>0.370701</td>\n",
       "      <td>-0.034255</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  119907.0 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
       "1   78340.0 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
       "2   82382.0 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
       "3   31717.0 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
       "4   80923.0  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
       "\n",
       "         V7        V8        V9  ...         V21       V22       V23  \\\n",
       "0  0.292491 -0.523020  0.358468  ...   -0.075208  0.045536  0.380739   \n",
       "1  0.321552  0.435975 -0.704298  ...   -0.128619 -0.368565  0.090660   \n",
       "2  0.706252 -0.064966 -0.463271  ...   -0.305402 -0.774704 -0.123884   \n",
       "3  0.681867 -0.031641  0.383872  ...   -0.220815 -0.419013 -0.239197   \n",
       "4  0.373692 -0.287204 -0.084482  ...   -0.160161 -0.430404 -0.076738   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  Class  \n",
       "0  0.023440 -2.220686 -0.201146  0.066501  0.221180    1.79      0  \n",
       "1  0.401147 -0.261034  0.080621  0.162427  0.059456    1.98      0  \n",
       "2 -0.495687 -0.018148  0.121679  0.249050  0.092516    0.89      0  \n",
       "3  0.009967  0.232829  0.814177  0.098797 -0.004273   15.98      0  \n",
       "4  0.258708  0.552170  0.370701 -0.034255  0.041709    0.76      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datasetes/credit/creditcard.csv\", low_memory=False)\n",
    "# df = pd.read_csv('creditcard.csv', low_memory=False)\n",
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 492 fraud data points and 284315 nonfraudulent data points.\n"
     ]
    }
   ],
   "source": [
    "frauds = df.loc[df['Class'] == 1]\n",
    "non_frauds = df.loc[df['Class'] == 0]\n",
    "print(\"We have\", len(frauds), \"fraud data points and\", len(non_frauds), \"nonfraudulent data points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and y sizes, respectively: 284807 284807\n",
      "Train and test sizes, respectively: 185124 185124 | 99683 99683\n",
      "Total number of frauds: 492 0.001727485630620034\n",
      "Number of frauds on y_test: 182 0.0018257877471584924\n",
      "Number of frauds on y_train: 310 0.0016745532724012013\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df['Class']\n",
    "\n",
    "print(\"X and y sizes, respectively:\", len(X), len(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=500)\n",
    "# trainpd = pd.read_csv(\"./datasetes/credit/credit_train3.csv\")\n",
    "# X_train = trainpd.iloc[:, :-1]\n",
    "# y_train = trainpd.iloc[:, -1]\n",
    "# testpd = pd.read_csv(\"./datasetes/credit/credit_test3.csv\")\n",
    "# X_test = testpd.iloc[:, :-1]\n",
    "# y_test = testpd.iloc[:, -1]\n",
    "\n",
    "print(\"Train and test sizes, respectively:\", len(X_train), len(y_train), \"|\", len(X_test), len(y_test))\n",
    "print(\"Total number of frauds:\", len(y.loc[df['Class'] == 1]), len(y.loc[df['Class'] == 1])/len(y))\n",
    "print(\"Number of frauds on y_test:\", len(y_test.loc[y_test == 1]), len(y_test.loc[y_test == 1]) / len(y_test))\n",
    "print(\"Number of frauds on y_train:\", len(y_train.loc[y_train == 1]), len(y_train.loc[y_train == 1])/len(y_train))\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.05680000e+04,   1.07986004e+00,   3.74335739e-02,\n",
       "          4.05189660e-01,   1.11623980e+00,  -3.52652667e-01,\n",
       "         -4.05465558e-01,   1.48082619e-02,   1.37820957e-03,\n",
       "          2.03991389e-01,  -5.03189566e-02,  -2.98616675e-01,\n",
       "         -1.76794270e-01,  -8.90378215e-01,   5.41904085e-01,\n",
       "          1.40271242e+00,  -4.02862035e-02,  -1.52854308e-01,\n",
       "         -4.93987693e-01,  -7.41539707e-01,  -1.17354908e-01,\n",
       "         -2.28408518e-02,  -1.78534699e-01,  -8.77119112e-03,\n",
       "          4.11553535e-02,   3.84051242e-01,  -4.37645941e-01,\n",
       "          2.44553934e-02,   3.11215578e-02,   5.93500000e+01]), 0)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.52093000e+05,   7.44982141e-03,   1.13163011e+00,\n",
       "         -2.66036367e+00,  -6.75345504e-01,   1.81505622e+00,\n",
       "         -5.32755745e-01,   1.19830550e+00,   4.38943170e-02,\n",
       "         -5.81932719e-01,  -7.11666890e-02,  -5.36796316e-01,\n",
       "          1.16766819e-01,  -7.22340099e-01,   1.37877058e+00,\n",
       "         -1.05032091e+00,  -6.54230796e-01,  -5.43860498e-01,\n",
       "          5.89924506e-01,   9.33565770e-01,  -4.09520114e-01,\n",
       "          5.82155900e-01,   1.66838208e+00,  -5.99436990e-02,\n",
       "         -2.95606238e-01,  -1.03082614e+00,  -1.61548812e-01,\n",
       "         -6.69506565e-02,   2.40108311e-01,   1.00000000e+00]), 0)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565.3806818181819"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(99683-176)/176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'EnhancedDTree' from 'C:\\\\github_workspace\\\\ecoForest\\\\EnhancedDTree.py'>"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import EnhancedForest\n",
    "import EnhancedForest_0322\n",
    "import EnhancedDTree\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "import numpy as np\n",
    "importlib.reload(EnhancedForest)\n",
    "importlib.reload(EnhancedForest_0322)\n",
    "importlib.reload(EnhancedDTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def acc_metrix_mult(a, p):\n",
    "#     print(p)\n",
    "    return \"acc\", metrics.accuracy_score(a, p)\n",
    "def roc_metrix_mult(a, p, labels=[0,1]):\n",
    "# #     print(p)\n",
    "    if len(set(a)) == 1:\n",
    "#         return \"acc\", metrics.accuracy_score(a, p)\n",
    "        return \"mean\", np.mean(p), set(a)\n",
    "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
    "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
    "    if len(p.shape) == 1:\n",
    "#         print(type(p), p.shape)\n",
    "        return \"roc\", metrics.roc_auc_score(a, p)\n",
    "#     elif len(p[0]) == 2:\n",
    "    elif len(p.shape) == 2:\n",
    "        p = [i[1] for i in p]\n",
    "        return \"roc\", metrics.roc_auc_score(a, p)\n",
    "    else:\n",
    "        print(type(p), p.shape, \"error\")\n",
    "def confusion_matrix_mult(a, p):\n",
    "    if len(set(a)) == 1:\n",
    "        return len(a), len(a) - len(np.where(a == p)[0])\n",
    "    return metrics.confusion_matrix(a, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-24 15:54:56.864408\n",
      "\n",
      "layer: 1\n",
      "start train: 2018-03-24 15:54:56.864408\n",
      "[train - p:0/1:0|n:185124/1:310] \n",
      "start test: 2018-03-24 15:55:56.673370\n",
      "end test: 2018-03-24 15:55:56.996227\n",
      "test loss: y_true 99683 99683, y_pred:99683 99683\n",
      "1 [test - now p:0/1:0 | all p:0/1:0 | np:99683/1:182] \n",
      "(0,) (99683,) 99683\n",
      "train loss ('roc', 0.99759812568311923)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.99759983620847048)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.97294924751432732)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 15:55:57.136599\n",
      "best test loss: 0.972949247514\n",
      "\n",
      "layer: 2\n",
      "start train: 2018-03-24 15:55:57.154647\n",
      "[train - p:181572/1:73|n:3552/1:237] start test: 2018-03-24 15:57:00.787854\n",
      "end test: 2018-03-24 15:57:03.771780\n",
      "test loss: y_true 1948 99683, y_pred:1948 99683\n",
      "2 [train - now p:181572/1:73 | all p:181572/1:73 | np:3552/1:237] \n",
      "2 [test - now p:97735/1:48 | all p:97735/1:48 | np:1948/1:134] \n",
      "(97735,) (1948,) 99683\n",
      "train loss ('roc', 0.99893374925862688)\n",
      "pass train loss ('roc', 0.99642626054696548)\n",
      "pass train loss now ('roc', 0.99642626054696548)\n",
      "vaild loss ('roc', 0.9989354074209571)\n",
      "pass vaild loss ('roc', 0.9964329023436258)\n",
      "pass vaild loss now ('roc', 0.9964329023436258)\n",
      "test loss ('roc', 0.97349794706353932)\n",
      "pass test loss ('roc', 0.90621992946860885)\n",
      "pass test loss now ('roc', 0.90621992946860885)\n",
      "2018-03-24 15:57:04.215960\n",
      "best test loss: 0.973497947064\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### stackplot\n",
    "pass_data_len = []\n",
    "pass_data_pos_len = []\n",
    "### stackplot\n",
    "\n",
    "# 统计信息\n",
    "train_loss_lt = []\n",
    "pass_train_loss_lt = []\n",
    "pass_train_loss_lt_now = []\n",
    "vaild_loss_lt = []\n",
    "pass_vaild_loss_lt = []\n",
    "pass_vaild_loss_lt_now = []\n",
    "test_loss_lt = []\n",
    "pass_test_loss_lt = []\n",
    "pass_test_loss_lt_now = []\n",
    "pass_data_rate_lt = []\n",
    "pass_data_rate_train_lt = []\n",
    "\n",
    "# 数据\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "X_test = X_test.copy()\n",
    "test_y = np.array(([0.0] * len(X_test)))\n",
    "all_pass_data_mask = np.array([False] * len(X_test))\n",
    "# data_mask = np.array([False] * len(X_test))\n",
    "real_y = y_test.copy()\n",
    "\n",
    "# 不均衡数据进行layer\n",
    "X_train_np = X\n",
    "y_train_np = y\n",
    "maxlayer = 100\n",
    "maxlayer = 10\n",
    "layer = 0\n",
    "\n",
    "# 不降低不更新\n",
    "last_train_loss = 0\n",
    "last_vaild_loss = 0\n",
    "\n",
    "# enhancedDTree = EnhancedForest_0322.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
    "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
    "counter = 0\n",
    "early_stop = 0\n",
    "early_stop_up = 0\n",
    "tmp_test_loss = 0\n",
    "\n",
    "ts = time.time()\n",
    "tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "print(tm)\n",
    "    \n",
    "while 1:\n",
    "    layer += 1\n",
    "    print()\n",
    "    print(\"layer:\", layer)\n",
    "    X = X_train_np\n",
    "    y = y_train_np\n",
    "    if layer == 1: isFirst = True\n",
    "    else: isFirst = False\n",
    "        \n",
    "    clf, now_pass_data_mask, p_test = \\\n",
    "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
    "                                      feval=roc_metrix_mult, dropout=0.99, criterion='gini', random_state=layer, \\\n",
    "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
    "                                     )\n",
    "    feval=roc_metrix_mult\n",
    "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
    "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
    "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
    "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
    "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
    "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
    "    test_loss = enhancedDTree.getTestLoss(feval)\n",
    "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
    "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
    "    \n",
    "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
    "# #     if vaild_loss[1] < last_vaild_loss: \n",
    "#         if not isFirst: enhancedDTree.remove_last_items()\n",
    "# #         early_stop_up += 1\n",
    "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
    "#             break\n",
    "#         continue\n",
    "        \n",
    "    last_train_loss = train_loss[1]\n",
    "    last_vaild_loss = vaild_loss[1]\n",
    "    \n",
    "    \n",
    "    # 打印信息\n",
    "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
    "#     X_test_np = X_test[all_np_data_index]\n",
    "    \n",
    "    X_train_np = enhancedDTree.X_train_np\n",
    "    y_train_np = enhancedDTree.y_train_np\n",
    "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
    "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
    "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
    "    if layer != 1:\n",
    "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
    "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
    "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
    "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
    "    \n",
    "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
    "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
    "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
    "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
    "    now_test_y = real_y[~all_pass_data_mask]\n",
    "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
    "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
    "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
    "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
    "    \n",
    "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
    "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
    "\n",
    "    #len(pass_data_id),\n",
    "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
    "#                                       len(X_test_np) - len(pass_data_id), \\\n",
    "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
    "    ### stackplot\n",
    "#     pass_data_len.append(len(pass_data_id))\n",
    "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
    "    ### stackplot\n",
    "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
    "        \n",
    "    print(\"train loss\", train_loss)\n",
    "    print(\"pass train loss\", pass_train_loss)\n",
    "    print(\"pass train loss now\", pass_train_loss_now)\n",
    "    print(\"vaild loss\", vaild_loss)\n",
    "    print(\"pass vaild loss\", pass_vaild_loss)\n",
    "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
    "    print(\"test loss\", test_loss)\n",
    "    print(\"pass test loss\", pass_test_loss)\n",
    "    print(\"pass test loss now\", pass_test_loss_now)\n",
    "    \n",
    "    ts = time.time()\n",
    "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    print(tm)\n",
    "    \n",
    "    \n",
    "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
    "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
    "    tmp =  metrics.roc_auc_score(y_test, test_y)\n",
    "    if tmp_test_loss < tmp:\n",
    "        tmp_test_loss = tmp\n",
    "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
    "        best_test_y = test_y.copy()\n",
    "    print(\"best test loss:\", tmp_test_loss)\n",
    "    \n",
    "    train_loss_lt.append(train_loss[1])\n",
    "    pass_train_loss_lt.append(pass_train_loss[1])\n",
    "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
    "    vaild_loss_lt.append(vaild_loss[1])\n",
    "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
    "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
    "    test_loss_lt.append(test_loss[1])\n",
    "    pass_test_loss_lt.append(pass_test_loss[1])\n",
    "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
    "    \n",
    "    \n",
    "#     if len(pass_data_rate_lt) == 0:\n",
    "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
    "#         pass_data_rate_train_lt.append(0)\n",
    "#     else:\n",
    "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
    "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
    "    # 打印信息结束\n",
    "    \n",
    "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
    "#     if layer > maxlayer or early_stop > 5:\n",
    "#         break\n",
    "        \n",
    "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
    "    \n",
    "    if layer == 2: break\n",
    "#     if layer == 20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185124,)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancedDTree.p_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185124,)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancedDTree.p_all_fold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97349794706353932"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3552, 30), (3552,), (181572, 30), (181572,))"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np = enhancedDTree.X_train_np.copy()\n",
    "y_train_np = enhancedDTree.y_train_np.copy()\n",
    "X_train_pass_lt = enhancedDTree.pass_data_x_list.copy()\n",
    "y_train_pass_lt = enhancedDTree.pass_data_y_list.copy()\n",
    "X_train_pass = np.array([j for i in np.array(X_train_pass_lt) for j in i])\n",
    "y_train_pass = np.array([j for i in np.array(y_train_pass_lt) for j in i])\n",
    "\n",
    "enhancedDTree.p_all\n",
    "\n",
    "X_train_np.shape, y_train_np.shape, X_train_pass.shape, y_train_pass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97735, 30), (97735,), (1948, 30), (1948,), (97735,), (1948,))"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_np = X_test[~all_pass_data_mask].copy()\n",
    "y_test_np = real_y[~all_pass_data_mask].copy()\n",
    "X_test_pass = X_test[all_pass_data_mask].copy()\n",
    "y_test_pass = real_y[all_pass_data_mask].copy()\n",
    "y_test_pass_pred = test_y[all_pass_data_mask].copy()\n",
    "y_test_np_pred = test_y[~all_pass_data_mask].copy()\n",
    "\n",
    "X_test_pass.shape, y_test_pass.shape, X_test_np.shape, y_test_np.shape, y_test_pass_pred.shape, y_test_np_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass auc: 0.906219929469\n",
      "np auc: 0.980302456845\n",
      "all auc: 0.973497947064\n"
     ]
    }
   ],
   "source": [
    "print(\"pass auc:\", metrics.roc_auc_score(y_test_pass, y_test_pass_pred))\n",
    "print(\"np auc:\", metrics.roc_auc_score(y_test_np, y_test_np_pred))\n",
    "print(\"all auc:\", metrics.roc_auc_score(np.hstack((y_test_np, y_test_pass)), np.hstack((y_test_np_pred, y_test_pass_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ModelUtils' from 'C:\\\\github_workspace\\\\ecoForest\\\\ModelUtils.py'>"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ModelUtils\n",
    "import importlib\n",
    "from collections import Counter\n",
    "importlib.reload(ModelUtils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ('roc', 0.55517243573833297)\n",
      "test ('roc', 0.55108073195214669)\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False) (1948,)\n",
      "all auc: 0.959817456139\n",
      "Wall time: 71.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf, pred_y = ModelUtils.mlp_classifier(X_train_np, y_train_np, X_test_np, y_test_np, feval=roc_metrix_mult)\n",
    "pred_y = np.array([i[1] for i in pred_y])\n",
    "print(clf, pred_y.shape)\n",
    "print(\"all auc:\", metrics.roc_auc_score(np.hstack((y_test_np, y_test_pass)), np.hstack((pred_y, y_test_pass_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ('roc', 1.0)\n",
      "test ('roc', 0.91116770063683783)\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') (1948,)\n",
      "all auc: 0.86114356242\n",
      "Wall time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf, pred_y = ModelUtils.decision_tree(X_train_np, y_train_np, X_test_np, y_test_np, feval=roc_metrix_mult)\n",
    "pred_y = np.array([i[1] for i in pred_y])\n",
    "print(clf, pred_y.shape)\n",
    "print(\"all auc:\", metrics.roc_auc_score(np.hstack((y_test_np, y_test_pass)), np.hstack((pred_y, y_test_pass_pred))))\n",
    "# pass auc: 0.906219929469\n",
    "# np auc: 0.90923826293\n",
    "# all auc: 0.861099109833\n",
    "# raw all auc: 0.973497947064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train: 2018-03-24 16:22:10.864703\n",
      "start test: 2018-03-24 16:22:11.463306\n",
      "end test: 2018-03-24 16:22:11.566588\n",
      "test ('roc', 0.99413763596570626)\n",
      "train ('roc', 1.0)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) (1948,)\n",
      "Wall time: 922 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf, pred_y = ModelUtils.random_forest(X_train_np, y_train_np, X_test_np, y_test_np, feval=roc_metrix_mult)\n",
    "pred_y = np.array([i[1] for i in pred_y])\n",
    "print(clf, pred_y.shape)\n",
    "\n",
    "# pass auc: 0.906219929469\n",
    "# np auc: 0.993767381395\n",
    "# all auc: 0.974001586598\n",
    "# raw all auc: 0.973497947064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ('roc', 1.0)\n",
      "test ('roc', 0.99166927216179301)\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False) (1948,)\n",
      "all auc: 0.973781283992\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf, pred_y = ModelUtils.gdbt_model(X_train_np, y_train_np, X_test_np, y_test_np, feval=roc_metrix_mult)\n",
    "pred_y = np.array([i[1] for i in pred_y])\n",
    "print(clf, pred_y.shape)\n",
    "print(\"all auc:\", metrics.roc_auc_score(np.hstack((y_test_np, y_test_pass)), np.hstack((pred_y, y_test_pass_pred))))\n",
    "\n",
    "# pass auc: 0.906219929469\n",
    "# np auc: 0.991953133999\n",
    "# all auc: 0.973785094214\n",
    "# raw all auc: 0.973497947064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3552, 31)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_np = pd.DataFrame(X_train_np)\n",
    "train_np['y'] = y_train_np\n",
    "train_np.to_csv(\"./output/train.np.csv\", index=False)\n",
    "train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1948, 31)"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_np = pd.DataFrame(X_test_np)\n",
    "train_np['y'] = y_test_np\n",
    "train_np.to_csv(\"./output/test.np.csv\", index=False)\n",
    "train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': array([[  1.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
      "          1.83962494e-01,   1.52030399e-01,   2.69000000e+00],\n",
      "       [  1.00000000e+00,   0.00000000e+00,   9.90000010e-01, ...,\n",
      "         -1.42641145e-01,  -1.39459872e-01,   6.50000000e+01],\n",
      "       [  1.00000000e+00,   0.00000000e+00,   9.90000010e-01, ...,\n",
      "         -4.55486608e-02,  -8.73240204e-02,   1.54800000e+02],\n",
      "       ..., \n",
      "       [  9.90000010e-01,   0.00000000e+00,   1.00000000e+00, ...,\n",
      "         -1.54527041e-01,   1.55418301e-03,   3.99900000e+01],\n",
      "       [  9.90000010e-01,   0.00000000e+00,   1.00000000e+00, ...,\n",
      "          3.64368385e-03,   7.24227450e-02,   1.15000000e+01],\n",
      "       [  9.90000010e-01,   0.00000000e+00,   1.00000000e+00, ...,\n",
      "         -7.25914532e-02,  -4.01702288e-02,   2.10820000e+02]]), 'y': array([0, 0, 0, ..., 0, 0, 0], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(r\"./output/layer_1-test.pkl\", \"rb\") as input_file:\n",
    "    e = pickle.load(input_file)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99683,)"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['y'].shape\n",
    "# print(\"all auc:\", metrics.roc_auc_score(np.hstack((y_test_np, y_test_pass)), np.hstack((e['y'], y_test_pass_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y = [0.017373275011777878, 0.5296658873558044, 0.006504380609840155, 0.018391979858279228, 0.035247836261987686, 0.022969642654061317, 0.014645211398601532, 0.057818979024887085, 0.0006876034894958138, 0.012000015936791897, 0.08391909301280975, 0.013830987736582756, 0.016791561618447304, 0.008420171216130257, 0.005016902461647987, 0.029426421970129013, 0.018485961481928825, 0.006502320058643818, 0.788286566734314, 0.03666052967309952, 0.021527007222175598, 0.005592777859419584, 0.0019865124486386776, 0.016422029584646225, 0.047405920922756195, 0.014981021173298359, 0.021692391484975815, 0.7968577146530151, 0.0026456774212419987, 0.7863301038742065, 0.5103703737258911, 0.015420911833643913, 0.0066864811815321445, 0.018325163051486015, 0.0034751351922750473, 0.011742091737687588, 0.002824952360242605, 0.0073191821575164795, 0.01465154904872179, 0.06086357682943344, 0.011609537526965141, 0.029849817976355553, 0.01921244151890278, 0.05051035434007645, 0.003903837176039815, 0.057366084307432175, 0.7505898475646973, 0.0094886664301157, 0.019126374274492264, 0.029874077066779137, 0.0028636816423386335, 0.7427888512611389, 0.014663000591099262, 0.03257666900753975, 0.0018982257461175323, 0.019691865891218185, 0.018431970849633217, 0.005010942928493023, 0.015826808288693428, 0.04055057093501091, 0.007859080098569393, 0.01775446906685829, 0.026746314018964767, 0.019608506932854652, 0.6268575191497803, 0.05542009323835373, 0.008031964302062988, 0.06285841017961502, 0.023305321112275124, 0.005316756200045347, 0.24636586010456085, 0.006915017031133175, 0.009762397035956383, 0.01698221266269684, 0.004414455033838749, 0.0032214645761996508, 0.020980076864361763, 0.021970409899950027, 0.002997844945639372, 0.79892897605896, 0.015864070504903793, 0.008422939106822014, 0.022516585886478424, 0.014257745817303658, 0.014272339642047882, 0.010181247256696224, 0.014711184427142143, 0.06699393689632416, 0.03615623340010643, 0.02134370617568493, 0.008949466049671173, 0.007909637875854969, 0.014343975111842155, 0.008900961838662624, 0.021433796733617783, 0.03547007963061333, 0.052807122468948364, 0.010244157165288925, 0.038035281002521515, 0.042865388095378876, 0.0013257572427392006, 0.0027996215503662825, 0.033057279884815216, 0.023968001827597618, 0.017332475632429123, 0.006874344311654568, 0.010994470678269863, 0.02262548729777336, 0.0265668872743845, 0.031887371093034744, 0.011631272733211517, 0.019217099994421005, 0.02369007095694542, 0.007221376057714224, 0.06030086427927017, 0.013853433541953564, 0.02537407912313938, 0.0122151467949152, 0.6683274507522583, 0.009311958216130733, 0.0021851607598364353, 0.011287831701338291, 0.00499003054574132, 0.010761205106973648, 0.0015659003984183073, 0.015291878953576088, 0.019551027566194534, 0.03672057390213013, 0.5509480834007263, 0.012051362544298172, 0.0078772297129035, 0.019699668511748314, 0.01891331933438778, 0.0005452922778204083, 0.02054789662361145, 0.027418961748480797, 0.00574143324047327, 0.014528719708323479, 0.014382034540176392, 0.04234138876199722, 0.5602814555168152, 0.020304884761571884, 0.013857625424861908, 0.7897108793258667, 0.008237125352025032, 0.02570701204240322, 0.014574013650417328, 0.011380244046449661, 0.010771208442747593, 0.005901156924664974, 0.21766841411590576, 0.009943797253072262, 0.01318387221544981, 0.006103109568357468, 0.0037484567146748304, 0.003523288294672966, 0.011656878516077995, 0.005491368006914854, 0.02138931304216385, 0.03672090917825699, 0.012793958187103271, 0.7257700562477112, 0.00433474313467741, 0.018132157623767853, 0.0026595820672810078, 0.06859704107046127, 0.006517372094094753, 0.006526739802211523, 0.016409125179052353, 0.03626822680234909, 0.01199362799525261, 0.004284619819372892, 0.006876923143863678, 0.001672145677730441, 0.03264761343598366, 0.7221039533615112, 0.013787914998829365, 0.007360903080552816, 0.018354974687099457, 0.04047094285488129, 0.014414471574127674, 0.005720330402255058, 0.013314327225089073, 0.0036658074241131544, 0.3396499454975128, 0.01333356648683548, 0.031255125999450684, 0.04530109465122223, 0.07795090228319168, 0.057240139693021774, 0.015762757509946823, 0.0038520428352057934, 0.0036331000737845898, 0.005908840801566839, 0.006792108528316021, 0.024961106479167938, 0.004200306721031666, 0.013584403321146965, 0.7427888512611389, 0.024722248315811157, 0.08254598081111908, 0.06305475533008575, 0.00675192940980196, 0.023009708151221275, 0.0029392321594059467, 0.052833426743745804, 0.012415889650583267, 0.009211631491780281, 0.011640009470283985, 0.019026463851332664, 0.039073411375284195, 0.006755986250936985, 0.01765204593539238, 0.0037479388993233442, 0.03642241656780243, 0.015909958630800247, 0.012600083835422993, 0.04567399248480797, 0.007796233054250479, 0.007419233676046133, 0.00994357280433178, 0.002552430611103773, 0.009484672918915749, 0.019553901627659798, 0.012485139071941376, 0.029160847887396812, 0.029235947877168655, 0.00985616073012352, 0.004875434562563896, 0.008445685729384422, 0.010202103294432163, 0.021368972957134247, 0.044330839067697525, 0.020006919279694557, 0.029070502147078514, 0.01361512579023838, 0.0010789614170789719, 0.029449906200170517, 0.027078663930296898, 0.017541542649269104, 0.03387894481420517, 0.014202450402081013, 0.021371902897953987, 0.022531989961862564, 0.007878140546381474, 0.01686924509704113, 0.011233515106141567, 0.009899922646582127, 0.007665822748094797, 0.006179171614348888, 0.47909021377563477, 0.7991488575935364, 0.0114738829433918, 0.0005516826640814543, 0.005440885666757822, 0.01589060202240944, 0.012965510599315166, 0.017403636127710342, 0.004071710631251335, 0.01718323305249214, 0.009133590385317802, 0.0021489711944013834, 0.009572884067893028, 0.021766452118754387, 0.01219774130731821, 0.016356967389583588, 0.7732225656509399, 0.01618056371808052, 0.051213979721069336, 0.0032128836028277874, 0.011234534904360771, 0.008916430175304413, 0.0059528774581849575, 0.7988245487213135, 0.011302550323307514, 0.02504071220755577, 0.0010839613387361169, 0.7931621670722961, 0.7211266160011292, 0.02643592655658722, 0.03356663137674332, 0.04118141159415245, 0.005996447987854481, 0.003836885094642639, 0.020317915827035904, 0.011039230041205883, 0.08708856254816055, 0.07708508521318436, 0.04345439374446869, 0.4639764726161957, 0.3888685405254364, 0.009514862671494484, 0.1302444487810135, 0.004460679832845926, 0.0049877651035785675, 0.011850165203213692, 0.03129049018025398, 0.026232104748487473, 0.005829543806612492, 0.5800355672836304, 0.00801447406411171, 0.026706844568252563, 0.07996918261051178, 0.007582538761198521, 0.02219667099416256, 0.01503010280430317, 0.01540770661085844, 0.014843383803963661, 0.0032690491061657667, 0.011463915929198265, 0.0058307889848947525, 0.755370020866394, 0.012406108900904655, 0.05819474533200264, 0.021205581724643707, 0.021838953718543053, 0.011301328428089619, 0.01852543093264103, 0.011606586165726185, 0.014552523382008076, 0.03339875116944313, 0.0052100783213973045, 0.041973866522312164, 0.013792477548122406, 0.01905975677073002, 0.014909252524375916, 0.03449065238237381, 0.012742611579596996, 0.011398402974009514, 0.020449664443731308, 0.007152874022722244, 0.010233627632260323, 0.004633999429643154, 0.011565073393285275, 0.017124321311712265, 0.025070831179618835, 0.011884624138474464, 0.018051717430353165, 0.009856832213699818, 0.004314964171499014, 0.00563643965870142, 0.005024842917919159, 0.019214361906051636, 0.04831831529736519, 0.010944249108433723, 0.013504577800631523, 0.07275697588920593, 0.024218101054430008, 0.0172610841691494, 0.037753067910671234, 0.07866612821817398, 0.004549759440124035, 0.0033846187870949507, 0.004291242454200983, 0.018226955085992813, 0.7985831499099731, 0.011482560075819492, 0.049827564507722855, 0.006320702377706766, 0.0433957576751709, 0.02837066911160946, 0.025925669819116592, 0.010630648583173752, 0.009220225736498833, 0.018761353567242622, 0.015940673649311066, 0.7974642515182495, 0.2664913535118103, 0.01020713523030281, 0.00416598143056035, 0.035607144236564636, 0.0006096134893596172, 0.012468380853533745, 0.021548017859458923, 0.008259768597781658, 0.7957059144973755, 0.00442615058273077, 0.0031932364217936993, 0.0345124825835228, 0.005471201613545418, 0.01326869148761034, 0.03988537937402725, 0.0014019440859556198, 0.013067388907074928, 0.01002578902989626, 0.00424384418874979, 0.003177922684699297, 0.009832648560404778, 0.1247418150305748, 0.009887478314340115, 0.011826416477560997, 0.024484165012836456, 0.7641804814338684, 0.01600443199276924, 0.03554058447480202, 0.014965209178626537, 0.005988942459225655, 0.7989263534545898, 0.009426278993487358, 0.003858376992866397, 0.010225851088762283, 0.004922335036098957, 0.004522680304944515, 0.015940386801958084, 0.019008208066225052, 0.005268228240311146, 0.0419112853705883, 0.03694049268960953, 0.004037960432469845, 0.009614480659365654, 0.015232725068926811, 0.013144969940185547, 0.006494271568953991, 0.009866632521152496, 0.003345006611198187, 0.7988566160202026, 0.07007159292697906, 0.007097143679857254, 0.018077362328767776, 0.0050402614288032055, 0.05393493175506592, 0.01159440353512764, 0.040998801589012146, 0.026998326182365417, 0.007378729991614819, 0.014425856061279774, 0.001139722648076713, 0.04764977842569351, 0.006399013102054596, 0.004476641770452261, 0.060739584267139435, 0.014261556789278984, 0.014277671463787556, 0.03303374722599983, 0.0009871716611087322, 0.01828600838780403, 0.008589264936745167, 0.022488215938210487, 0.7795721292495728, 0.01406009029597044, 0.04915367066860199, 0.019638780504465103, 0.005960238631814718, 0.03269707411527634, 0.01342240534722805, 0.02581273950636387, 0.005694539286196232, 0.006948848720639944, 0.008851082064211369, 0.014080566354095936, 0.019906308501958847, 0.22650980949401855, 0.002410620916634798, 0.01998978853225708, 0.029176363721489906, 0.0008225355995818973, 0.008245101198554039, 0.019202271476387978, 0.028942298144102097, 0.058671336621046066, 0.02371818758547306, 0.008002405986189842, 0.0026571995113044977, 0.04536427929997444, 0.013913119211792946, 0.004102804698050022, 0.060739584267139435, 0.002594913588836789, 0.01704864762723446, 0.019816813990473747, 0.03439240902662277, 0.0016627408331260085, 0.016648299992084503, 0.018029486760497093, 0.022626599296927452, 0.017848696559667587, 0.49331340193748474, 0.048971060663461685, 0.04527802765369415, 0.025575365871191025, 0.01434917002916336, 0.05269024521112442, 0.007563881576061249, 0.7342223525047302, 0.02224036492407322, 0.053138863295316696, 0.009666437283158302, 0.018552932888269424, 0.01853792369365692, 0.05816754698753357, 0.004644212778657675, 0.01827661693096161, 0.007881460711359978, 0.0031903316266834736, 0.010089547373354435, 0.002599436789751053, 0.027749136090278625, 0.019950928166508675, 0.09717091917991638, 0.00845608301460743, 0.00449781958013773, 0.006604361347854137, 0.012040821835398674, 0.7898370623588562, 0.005770877003669739, 0.007912005297839642, 0.017412174493074417, 0.0022533321753144264, 0.0065137892961502075, 0.02433263510465622, 0.011531932279467583, 0.004790579900145531, 0.01127619482576847, 0.012809721753001213, 0.07637793570756912, 0.05357833951711655, 0.016066376119852066, 0.027986910194158554, 0.005303931888192892, 0.01242026500403881, 0.7848290801048279, 0.1359216868877411, 0.011214444413781166, 0.06123863905668259, 0.05643140524625778, 0.025728780776262283, 0.01979057863354683, 0.020235491916537285, 0.009516931138932705, 0.0039718435145914555, 0.00750143826007843, 0.007229264825582504, 0.030373448505997658, 0.015322381630539894, 0.006092099007219076, 0.019381999969482422, 0.019168294966220856, 0.034505441784858704, 0.008858454413712025, 0.0024957931600511074, 0.009908121079206467, 0.0479462705552578, 0.024510134011507034, 0.017742855474352837, 0.007726243231445551, 0.05774630233645439, 0.010960419662296772, 0.016296686604619026, 0.005244048777967691, 0.025617891922593117, 0.024614553898572922, 0.006457251496613026, 0.7992965579032898, 0.012275188229978085, 0.010217997245490551, 0.0019284030422568321, 0.009758164174854755, 0.050312381237745285, 0.02056395448744297, 0.005355328321456909, 0.01026935689151287, 0.029507627710700035, 0.007060515694320202, 0.011056369170546532, 0.007399679161608219, 0.013817444443702698, 0.007117927074432373, 0.013253578916192055, 0.017311517149209976, 0.033643752336502075, 0.01602247916162014, 0.01762128248810768, 0.02118730917572975, 0.0241570882499218, 0.013477230444550514, 0.012789204716682434, 0.037260863929986954, 0.010415473021566868, 0.7891209721565247, 0.005386178381741047, 0.01799372211098671, 0.0028292909264564514, 0.013735286891460419, 0.02793196402490139, 0.027508467435836792, 0.055453039705753326, 0.35856893658638, 0.02450341358780861, 0.037456411868333817, 0.009549910202622414, 0.01208348199725151, 0.050541408360004425, 0.04038074612617493, 0.032299451529979706, 0.014396831393241882, 0.0343584343791008, 0.020681429654359818, 0.018091756850481033, 0.028019672259688377, 0.010657012462615967, 0.009859563782811165, 0.01680181175470352, 0.6800929307937622, 0.019166694954037666, 0.014141259714961052, 0.007488034665584564, 0.5619481205940247, 0.008868333883583546, 0.005384624004364014, 0.01705075241625309, 0.011483828537166119, 0.007213068660348654, 0.0040262620896101, 0.3133295178413391, 0.006907460279762745, 0.011831505224108696, 0.0014195690164342523, 0.028627658262848854, 0.7992515563964844, 0.017391476780176163, 0.025464698672294617, 0.006602267734706402, 0.0896633118391037, 0.3829839825630188, 0.02098555490374565, 0.01286264043301344, 0.00996293406933546, 0.014107780531048775, 0.011054756119847298, 0.005513983778655529, 0.771025538444519, 0.006425293628126383, 0.019166097044944763, 0.5877149105072021, 0.0028194566257297993, 0.7984687089920044, 0.010126596316695213, 0.4956963062286377, 0.7944839596748352, 0.03603373095393181, 0.003201258834451437, 0.015575329773128033, 0.012612099759280682, 0.03337668627500534, 0.04247443377971649, 0.016186194494366646, 0.0060460749082267284, 0.006262429989874363, 0.5525110960006714, 0.012212472036480904, 0.01509789563715458, 0.02173730544745922, 0.0026522167026996613, 0.022866910323500633, 0.7340213656425476, 0.003742169588804245, 0.009176524356007576, 0.07723084092140198, 0.015696071088314056, 0.00366184557788074, 0.06009534001350403, 0.0033680039923638105, 0.02950323559343815, 0.0006404215237125754, 0.08743733912706375, 0.013264475390315056, 0.009977941401302814, 0.005135043524205685, 0.05189099162817001, 0.007493700832128525, 0.052798230201005936, 0.010689789429306984, 0.022339101880788803, 0.021841377019882202, 0.022848378866910934, 0.0018066115444526076, 0.002210916019976139, 0.009204575791954994, 0.016699131578207016, 0.01892232522368431, 0.028190305456519127, 0.03307923302054405, 0.020878294482827187, 0.013144969940185547, 0.014847862534224987, 0.18073591589927673, 0.1332027018070221, 0.02513972483575344, 0.01256859116256237, 0.04242383688688278, 0.25415390729904175, 0.0017944092396646738, 0.02261454239487648, 0.011807208880782127, 0.00918958056718111, 0.004640910774469376, 0.020884830504655838, 0.030794421210885048, 0.007930254563689232, 0.07480847090482712, 0.003907465375959873, 0.015712518244981766, 0.011591116897761822, 0.005444325506687164, 0.013071452267467976, 0.01593806967139244, 0.7983695864677429, 0.0032935049384832382, 0.002090649213641882, 0.0014704575296491385, 0.017036201432347298, 0.03709547221660614, 0.01039104349911213, 0.00921674631536007, 0.002394047100096941, 0.013847333379089832, 0.005728856194764376, 0.028090011328458786, 0.019772371277213097, 0.027874698862433434, 0.005140985827893019, 0.0022236371878534555, 0.005741523578763008, 0.013221639208495617, 0.018751202151179314, 0.013307645916938782, 0.004823215305805206, 0.009351864457130432, 0.0017783408984541893, 0.5265321135520935, 0.02080456167459488, 0.006389358546584845, 0.01855490729212761, 0.05694546177983284, 0.02645755372941494, 0.029680948704481125, 0.018528074026107788, 0.0289352685213089, 0.0038953195326030254, 0.016093488782644272, 0.0010243650758638978, 0.004620541352778673, 0.011017578653991222, 0.03327295929193497, 0.020197344943881035, 0.020179947838187218, 0.7929915189743042, 0.005490308161824942, 0.01810171827673912, 0.005853912327438593, 0.012148315086960793, 0.011973711661994457, 0.01117370743304491, 0.005352174397557974, 0.006818667985498905, 0.01130871195346117, 0.026338797062635422, 0.027928020805120468, 0.01835891604423523, 0.005706202704459429, 0.03060704842209816, 0.018286967650055885, 0.005421725567430258, 0.0014007032150402665, 0.01785150170326233, 0.015058545395731926, 0.027107760310173035, 0.024854807183146477, 0.0017706922953948379, 0.02471163123846054, 0.013085708022117615, 0.03379449620842934, 0.7991265058517456, 0.0036602660547941923, 0.0446307472884655, 0.0038516498170793056, 0.041112806648015976, 0.001896719797514379, 0.002757227746769786, 0.03387506306171417, 0.029979264363646507, 0.0022721439599990845, 0.0032211311627179384, 0.014335905201733112, 0.02209588512778282, 0.46672916412353516, 0.02156093344092369, 0.7820351719856262, 0.3335328698158264, 0.004634219221770763, 0.012553086504340172, 0.006885928101837635, 0.01886684074997902, 0.05125398188829422, 0.00513252941891551, 0.05149061232805252, 0.007929349318146706, 0.04577641189098358, 0.019279565662145615, 0.037460193037986755, 0.031113917008042336, 0.02399691939353943, 0.029640421271324158, 0.008986339904367924, 0.0019458995666354895, 0.797075629234314, 0.035351961851119995, 0.024698752909898758, 0.04089133441448212, 0.012323630042374134, 0.03355562686920166, 0.038476504385471344, 0.002345156157389283, 0.033151619136333466, 0.015400993637740612, 0.004014655947685242, 0.031637609004974365, 0.006706306245177984, 0.011052540503442287, 0.029536226764321327, 0.057537782937288284, 0.005136632360517979, 0.00788053311407566, 0.007761652581393719, 0.015591387636959553, 0.024555834010243416, 0.001096993568353355, 0.786665141582489, 0.009176066145300865, 0.011916312389075756, 0.14160576462745667, 0.009897546842694283, 0.015145620331168175, 0.012792052701115608, 0.012769067659974098, 0.020701676607131958, 0.007351698819547892, 0.01817377097904682, 0.023043658584356308, 0.0403100810945034, 0.0019305454334244132, 0.014801179990172386, 0.030167192220687866, 0.007664378732442856, 0.07639651000499725, 0.01647115871310234, 0.7318116426467896, 0.025435511022806168, 0.07328964024782181, 0.007237693760544062, 0.054391421377658844, 0.029300887137651443, 0.05317564681172371, 0.009371491149067879, 0.02129421755671501, 0.0013686781749129295, 0.026036936789751053, 0.04267827421426773, 0.00854444783180952, 0.015625476837158203, 0.009849629364907742, 0.005934655200690031, 0.007256222423166037, 0.013108988292515278, 0.017686359584331512, 0.00545755447819829, 0.016424518078565598, 0.10945393890142441, 0.01157607976347208, 0.013067510910332203, 0.00870560947805643, 0.05102187395095825, 0.021222051233053207, 0.010484178550541401, 0.013648249208927155, 0.009595897980034351, 0.010351920500397682, 0.06740236282348633, 0.02699732407927513, 0.01813097670674324, 0.02995445765554905, 0.01657779887318611, 0.028696808964014053, 0.0047288816422224045, 0.00994079653173685, 0.0025271703489124775, 0.021433454006910324, 0.03558861464262009, 0.004699789918959141, 0.035612042993307114, 0.030848180875182152, 0.1419312059879303, 0.012128465808928013, 0.018680308014154434, 0.012143224477767944, 0.003584557445719838, 0.003712394507601857, 0.7850422859191895, 0.016267215833067894, 0.019747337326407433, 0.010049632750451565, 0.029548654332756996, 0.006949769798666239, 0.015379336662590504, 0.01871190220117569, 0.018714217469096184, 0.01476549357175827, 0.02955901250243187, 0.006783544085919857, 0.010539408773183823, 0.0069957999512553215, 0.018431615084409714, 0.022058935835957527, 0.010546018369495869, 0.02095358446240425, 0.003799881087616086, 0.08077210932970047, 0.006900551728904247, 0.012612305581569672, 0.012275805696845055, 0.026800666004419327, 0.009212782606482506, 0.013546230271458626, 0.06129469722509384, 0.017609044909477234, 0.05434470623731613, 0.010078595951199532, 0.005886129569262266, 0.01863917149603367, 0.007361638359725475, 0.0038166765589267015, 0.0018342894036322832, 0.004290641285479069, 0.0051864199340343475, 0.005042790435254574, 0.11938533931970596, 0.028976669535040855, 0.022061143070459366, 0.008910028263926506, 0.004054263699799776, 0.0015266912523657084, 0.0033915466628968716, 0.013451695442199707, 0.07510938495397568, 0.01999467983841896, 0.007399258203804493, 0.0027679603081196547, 0.0052717262879014015, 0.0076686060056090355, 0.008810010738670826, 0.013458779081702232, 0.020658615976572037, 0.0024943402968347073, 0.003206395311281085, 0.021091828122735023, 0.0015855375677347183, 0.01411491073668003, 0.014023391529917717, 0.0017409672727808356, 0.003856778610497713, 0.0013633384369313717, 0.011487049981951714, 0.025412151589989662, 0.013399568386375904, 0.015828367322683334, 0.01226835511624813, 0.02201477624475956, 0.013904069550335407, 0.7484975457191467, 0.029562372714281082, 0.02231970801949501, 0.01587410271167755, 0.06138639524579048, 0.02355235256254673, 0.007746313698589802, 0.007603647653013468, 0.037668321281671524, 0.01700596697628498, 0.013991144485771656, 0.018292108550667763, 0.015287131071090698, 0.018221260979771614, 0.05152348801493645, 0.018434513360261917, 0.025975197553634644, 0.015108875930309296, 0.0006350194453261793, 0.005548160523176193, 0.7971071004867554, 0.006190852262079716, 0.020936887711286545, 0.018306951969861984, 0.00470831198617816, 0.012841063551604748, 0.012595849111676216, 0.035508010536432266, 0.004889178555458784, 0.022519633173942566, 0.004700097721070051, 0.00908735767006874, 0.02395402267575264, 0.016391940414905548, 0.03558861464262009, 0.6136072278022766, 0.0011385844554752111, 0.3985089063644409, 0.0035142642445862293, 0.004644252825528383, 0.0016521066427230835, 0.013420147821307182, 0.03584476187825203, 0.04933644458651543, 0.00521876011043787, 0.013144969940185547, 0.43562763929367065, 0.013954607769846916, 0.04236485809087753, 0.009208486415445805, 0.003971907310187817, 0.005091313272714615, 0.024683209136128426, 0.019437510520219803, 0.0012519977753981948, 0.034998297691345215, 0.010992627590894699, 0.01405179500579834, 0.0056882742792367935, 0.001846863655373454, 0.01077168807387352, 0.01245925109833479, 0.002025362104177475, 0.0010266151512041688, 0.0043753208592534065, 0.012461700476706028, 0.1413009762763977, 0.02164541557431221, 0.025098372250795364, 0.010954691097140312, 0.26836395263671875, 0.012430358678102493, 0.02405276522040367, 0.017512645572423935, 0.007297874428331852, 0.00579366460442543, 0.014293292537331581, 0.00489145377650857, 0.0018543772166594863, 0.7827099561691284, 0.012123478576540947, 0.006872580852359533, 0.001752949319779873, 0.04732881486415863, 0.007913224399089813, 0.007457011379301548, 0.005488124676048756, 0.012250043451786041, 0.00928867794573307, 0.007230966351926327, 0.011620813980698586, 0.017780369147658348, 0.02058388665318489, 0.008027320727705956, 0.019432920962572098, 0.0013134548207744956, 0.004242546856403351, 0.09029731899499893, 0.03255680948495865, 0.005386067554354668, 0.005003504920750856, 0.046967826783657074, 0.21011340618133545, 0.5491610169410706, 0.013554109260439873, 0.0020818249322474003, 0.0035318401642143726, 0.04035472124814987, 0.008711768314242363, 0.019372520968317986, 0.013654472306370735, 0.0016621677204966545, 0.0051559885032474995, 0.01807180978357792, 0.007760118693113327, 0.0018058840651065111, 0.027877841144800186, 0.7427888512611389, 0.7979952692985535, 0.008720692247152328, 0.02862287126481533, 0.0008762525394558907, 0.008696621283888817, 0.011644944548606873, 0.709497332572937, 0.014105292968451977, 0.005643332377076149, 0.019218910485506058, 0.01809411123394966, 0.005581283010542393, 0.039100874215364456, 0.01546960324048996, 0.0023598598781973124, 0.5863011479377747, 0.03080674633383751, 0.041374824941158295, 0.0072994111105799675, 0.029451195150613785, 0.002870334777981043, 0.008522051386535168, 0.0015203278744593263, 0.0076773501932621, 0.005037288181483746, 0.011176316998898983, 0.010825969278812408, 0.01917634904384613, 0.03249930962920189, 0.0019510251004248857, 0.0026254369877278805, 0.003891425207257271, 0.03337033838033676, 0.02247815951704979, 0.00905668456107378, 0.02099435403943062, 0.00827793963253498, 0.007944884710013866, 0.01645679399371147, 0.008018378168344498, 0.009059158153831959, 0.0015505633782595396, 0.013864360749721527, 0.03490142896771431, 0.610834002494812, 0.008229358121752739, 0.31508868932724, 0.006843607872724533, 0.015728164464235306, 0.02619912289083004, 0.012826338410377502, 0.0316220298409462, 0.7994226217269897, 0.7123047113418579, 0.0022908239625394344, 0.5249418020248413, 0.006609031464904547, 0.006825292017310858, 0.010003326460719109, 0.010375714860856533, 0.007283846847712994, 0.01671861670911312, 0.05257589742541313, 0.02692997083067894, 0.04516677185893059, 0.008974053896963596, 0.540996253490448, 0.03483961150050163, 0.042053766548633575, 0.03171784058213234, 0.008817029185593128, 0.014254873618483543, 0.0027329239528626204, 0.006595645099878311, 0.013923401944339275, 0.0400393083691597, 0.011800643056631088, 0.006594747304916382, 0.031138399615883827, 0.014485813677310944, 0.03601197153329849, 0.06855536997318268, 0.0055207558907568455, 0.004488957114517689, 0.011106221936643124, 0.05982198193669319, 0.010721703991293907, 0.05074462294578552, 0.00487550999969244, 0.007354539819061756, 0.032306112349033356, 0.013545011170208454, 0.003349995706230402, 0.014372343197464943, 0.016074661165475845, 0.032047830522060394, 0.060991235077381134, 0.005597203969955444, 0.004140029661357403, 0.025011921301484108, 0.00918569602072239, 0.016333429142832756, 0.04634179547429085, 0.011099902912974358, 0.019937414675951004, 0.025475597009062767, 0.010995300486683846, 0.006566372700035572, 0.0033633168786764145, 0.0032548781018704176, 0.03347328305244446, 0.7990669012069702, 0.02146749570965767, 0.046380188316106796, 0.029824841767549515, 0.034146737307310104, 0.04066772386431694, 0.029179204255342484, 0.04732881486415863, 0.017677919939160347, 0.021747048944234848, 0.13173255324363708, 0.01061213668435812, 0.7730404138565063, 0.013723602518439293, 0.007861694321036339, 0.08927226811647415, 0.008445612154901028, 0.014679272659122944, 0.0035243325401097536, 0.016662437468767166, 0.008714535273611546, 0.007468762341886759, 0.03531308099627495, 0.012433050200343132, 0.0008067369344644248, 0.007748984731733799, 0.0038523643743246794, 0.0038841553032398224, 0.005546965636312962, 0.0329815112054348, 0.021151667460799217, 0.018920812755823135, 0.003921818919479847, 0.1042928546667099, 0.029127690941095352, 0.00655739288777113, 0.006293904036283493, 0.016702961176633835, 0.0006638659397140145, 0.0034609835129231215, 0.0031725415028631687, 0.04676453024148941, 0.012329446151852608, 0.04963136836886406, 0.007979931309819221, 0.002108860295265913, 0.015861928462982178, 0.02804766222834587, 0.040198903530836105, 0.005246391054242849, 0.012063311412930489, 0.009874257259070873, 0.023046012967824936, 0.022833842784166336, 0.005655861925333738, 0.0071122124791145325, 0.017339609563350677, 0.032384179532527924, 0.006173145957291126, 0.0024827048182487488, 0.029618000611662865, 0.6860544085502625, 0.013133442029356956, 0.0025915405713021755, 0.0018057137494906783, 0.016339385882019997, 0.004041613079607487, 0.037094149738550186, 0.00302955717779696, 0.006063877139240503, 0.016430405899882317, 0.012473276816308498, 0.0160900317132473, 0.03226685896515846, 0.008140452206134796, 0.0056492118164896965, 0.007098359055817127, 0.04505458101630211, 0.006043232046067715, 0.00947137363255024, 0.014228890649974346, 0.0339035838842392, 0.04538992419838905, 0.029417211189866066, 0.01062445156276226, 0.017955658957362175, 0.5219178795814514, 0.023919012397527695, 0.009243174456059933, 0.011609119363129139, 0.017588479444384575, 0.010180836543440819, 0.024042483419179916, 0.01066206768155098, 0.0068616680800914764, 0.04096519201993942, 0.037188492715358734, 0.01623620092868805, 0.02383585087954998, 0.0039660073816776276, 0.021152615547180176, 0.04088202491402626, 0.026015426963567734, 0.035508010536432266, 0.013851727358996868, 0.03282976150512695, 0.01955481991171837, 0.7947853207588196, 0.004443374462425709, 0.00924711674451828, 0.00516932737082243, 0.7468046545982361, 0.08478377014398575, 0.027326080948114395, 0.02326912060379982, 0.012075776234269142, 0.01087232492864132, 0.007397481705993414, 0.013117566704750061, 0.02487994357943535, 0.008949890732765198, 0.019079716876149178, 0.017129167914390564, 0.010345329530537128, 0.012812817469239235, 0.1399943232536316, 0.006003330461680889, 0.019400404766201973, 0.007835657335817814, 0.004143404774367809, 0.01901945099234581, 0.005195648409426212, 0.0025588113348931074, 0.006288235541433096, 0.017681721597909927, 0.007190951611846685, 0.04071755334734917, 0.006951703689992428, 0.03647955507040024, 0.015160106122493744, 0.03315640613436699, 0.034779857844114304, 0.03547058254480362, 0.01472338568419218, 0.049609776586294174, 0.013045755214989185, 0.049875304102897644, 0.007618753705173731, 0.007243382278829813, 0.01390499621629715, 0.07671725749969482, 0.03177288919687271, 0.1072876825928688, 0.01982465758919716, 0.008577315136790276, 0.009570173919200897, 0.016300929710268974, 0.06762494146823883, 0.011593560688197613, 0.02509312704205513, 0.4561030864715576, 0.01536954939365387, 0.018652144819498062, 0.004615801386535168, 0.011038366705179214, 0.014407563023269176, 0.06850866973400116, 0.016631141304969788, 0.05008067935705185, 0.0037518013268709183, 0.05010642483830452, 0.005389931611716747, 0.011215883307158947, 0.017167892307043076, 0.008427544496953487, 0.04097447171807289, 0.06162597984075546, 0.0024655989836901426, 0.007060551084578037, 0.017214616760611534, 0.020295869559049606, 0.009516451507806778, 0.03058432601392269, 0.003194078104570508, 0.7931480407714844, 0.0314171239733696, 0.006652437150478363, 0.021185612305998802, 0.02257198467850685, 0.010080356150865555, 0.00833502970635891, 0.060739584267139435, 0.013906446285545826, 0.02565295435488224, 0.02962673269212246, 0.0013546880800276995, 0.06372953951358795, 0.024545541033148766, 0.007499397732317448, 0.007762424647808075, 0.7766894698143005, 0.03313034027814865, 0.02296336181461811, 0.024643348529934883, 0.019367080181837082, 0.004676997195929289, 0.008402569219470024, 0.01083466224372387, 0.011334804818034172, 0.016716795042157173, 0.3180622458457947, 0.011566182598471642, 0.0019420005846768618, 0.004575107712298632, 0.003167195711284876, 0.014276988804340363, 0.016026025637984276, 0.024213479831814766, 0.011663383804261684, 0.010580601170659065, 0.005875450558960438, 0.00655842199921608, 0.017035622149705887, 0.006242569535970688, 0.02158130146563053, 0.007294252514839172, 0.04413653537631035, 0.010182378813624382, 0.05082466080784798, 0.019703252241015434, 0.0045223841443657875, 0.005725218448787928, 0.010317507199943066, 0.011670556850731373, 0.00722495699301362, 0.010396646335721016, 0.0074952105060219765, 0.02534530684351921, 0.71342933177948, 0.0028498664032667875, 0.7985759377479553, 0.016310619190335274, 0.05789921432733536, 0.005041508935391903, 0.004341715481132269, 0.037501584738492966, 0.006448931060731411, 0.003933249972760677, 0.009845755994319916, 0.010351905599236488, 0.03423058241605759, 0.0004242131544742733, 0.5837501287460327, 0.031579550355672836, 0.03334682062268257, 0.02683817408978939, 0.016815420240163803, 0.04633215814828873, 0.027405446395277977, 0.03829135373234749, 0.009975893422961235, 0.029600244015455246, 0.004902761895209551, 0.006490075029432774, 0.008025174960494041, 0.006018985528498888, 0.019188176840543747, 0.017486605793237686, 0.01182558387517929, 0.006090191192924976, 0.014961103908717632, 0.019247272983193398, 0.7064689993858337, 0.018219906836748123, 0.32728007435798645, 0.44206753373146057, 0.011906839907169342, 0.04477505385875702, 0.01565307378768921, 0.03172514960169792, 0.03522590547800064, 0.006763766519725323, 0.04233648627996445, 0.012086229398846626, 0.00812331959605217, 0.0018632113933563232, 0.052574627101421356, 0.005986823700368404, 0.007782424800097942, 0.01907246932387352, 0.0073248036205768585, 0.0063599394634366035, 0.00722541194409132, 0.027338802814483643, 0.011759989894926548, 0.043192680925130844, 0.035583943128585815, 0.018008481711149216, 0.010203292593359947, 0.00767035037279129, 0.5270992517471313, 0.017897233366966248, 0.0048968177288770676, 0.00679413229227066, 0.7889317870140076, 0.00935734249651432, 0.795760989189148, 0.006080320570617914, 0.026967328041791916, 0.007434861268848181, 0.040806226432323456, 0.015673767775297165, 0.1310882866382599, 0.019965117797255516, 0.7914215326309204, 0.009126223623752594, 0.03275231271982193, 0.006715558469295502, 0.014736910350620747, 0.014092057943344116, 0.003997218795120716, 0.7032532691955566, 0.007791305426508188, 0.03571920841932297, 0.028572801500558853, 0.0031733070500195026, 0.010173799470067024, 0.016058634966611862, 0.0165203008800745, 0.006256780121475458, 0.017423544079065323, 0.008277333341538906, 0.004491849802434444, 0.04711639881134033, 0.041167814284563065, 0.005801443941891193, 0.015449906699359417, 0.7939680814743042, 0.009178085252642632, 0.02420809306204319, 0.0136442631483078, 0.015486876480281353, 0.0025302297435700893, 0.009373238310217857, 0.001973686972633004, 0.016220655292272568, 0.032148122787475586, 0.007151850499212742, 0.011561871506273746, 0.010905945673584938, 0.053281642496585846, 0.010355156846344471, 0.7427888512611389, 0.014084519818425179, 0.014713674783706665, 0.012822343036532402, 0.020523834973573685, 0.005580001510679722, 0.003294697031378746, 0.020244857296347618, 0.021396087482571602, 0.015877963975071907, 0.22211095690727234, 0.011289423331618309, 0.0007730574579909444, 0.01645372062921524, 0.037445902824401855, 0.014320085756480694, 0.14765354990959167, 0.008233020082116127, 0.00993806030601263, 0.006777023430913687, 0.12858846783638, 0.005567420274019241, 0.03455645591020584, 0.028041299432516098, 0.007669483311474323, 0.012013810686767101, 0.0036708160769194365, 0.02974669076502323, 0.03558861464262009, 0.004915958270430565, 0.021405035629868507, 0.02214599959552288, 0.00587562657892704, 0.017748001962900162, 0.009103347547352314, 0.4495534300804138, 0.002095217350870371, 0.007790678646415472, 0.006807462777942419, 0.0018916536355391145, 0.02385825291275978, 0.011835863813757896, 0.015541598200798035, 0.002627541311085224, 0.0013878158060833812, 0.009572582319378853, 0.0051864078268408775, 0.008334135636687279, 0.012739797122776508, 0.05194476246833801, 0.007642984390258789, 0.006937201134860516, 0.015208827331662178, 0.011535702273249626, 0.000922303763218224, 0.013142202980816364, 0.030158009380102158, 0.00815549399703741, 0.031006980687379837, 0.007674858905375004, 0.003510191338136792, 0.003995959181338549, 0.000882267311681062, 0.020303521305322647, 0.027576137334108353, 0.013731783255934715, 0.0042653074488043785, 0.02265099063515663, 0.02472085691988468, 0.012903111055493355, 0.015360469929873943, 0.0264752060174942, 0.04297728091478348, 0.005768514238297939, 0.004601945634931326, 0.02767818607389927, 0.006723341997712851, 0.7823797464370728, 0.03558861464262009, 0.029763218015432358, 0.026130497455596924, 0.01173117570579052, 0.01750556379556656, 0.0037709407042711973, 0.01499467808753252, 0.004381931386888027, 0.018318748101592064, 0.013513992540538311, 0.020068589597940445, 0.024749992415308952, 0.035911478102207184, 0.015974199399352074, 0.006332190241664648, 0.015267692506313324, 0.018252264708280563, 0.013784225098788738, 0.03334534540772438, 0.008803388103842735, 0.04180454835295677, 0.004338090308010578, 0.04165572673082352, 0.013378609903156757, 0.011101665906608105, 0.031738921999931335, 0.01620449498295784, 0.013483117334544659, 0.0066616833209991455, 0.028700504451990128, 0.007009644061326981, 0.04382512718439102, 0.01323418878018856, 0.002113904105499387, 0.010136207565665245, 0.012921979650855064, 0.014905201271176338, 0.010839363560080528, 0.7202579379081726, 0.7309330105781555, 0.004120420198887587, 0.004893033765256405, 0.011087691411376, 0.006112044211477041, 0.026592236012220383, 0.015242154709994793, 0.008272229693830013, 0.017428621649742126, 0.0039664143696427345, 0.022558681666851044, 0.02616768144071102, 0.007160642649978399, 0.006886645220220089, 0.01970044896006584, 0.08017397671937943, 0.00918360985815525, 0.018970172852277756, 0.00890717376023531, 0.022911669686436653, 0.01812494918704033, 0.016348909586668015, 0.742551863193512, 0.010989641770720482, 0.7869173288345337, 0.014083323068916798, 0.022504864260554314, 0.009088326245546341, 0.008585870265960693, 0.04405469819903374, 0.006574543658643961, 0.025054702535271645, 0.028510263189673424, 0.0026367336977273226, 0.007697162218391895, 0.018692631274461746, 0.4468381404876709, 0.03589916601777077, 0.04916497692465782, 0.01852693222463131, 0.005973205901682377, 0.03189655393362045, 0.04107426851987839, 0.016912560909986496, 0.04338343068957329, 0.005597322713583708, 0.5499746203422546, 0.007360382471233606, 0.002289910800755024, 0.012493662536144257, 0.024517681449651718, 0.007399809546768665, 0.01390500646084547, 0.009457974694669247, 0.0014705922221764922, 0.0006625921232625842, 0.007783929817378521, 0.016422029584646225, 0.0017103493446484208, 0.0063097127713263035, 0.007139877416193485, 0.008721228688955307, 0.0019887604285031557, 0.0014629680663347244, 0.023413870483636856, 0.040584735572338104, 0.020570334047079086, 0.02051016315817833, 0.007800427731126547, 0.07119996845722198, 0.009194997139275074, 0.01497562788426876, 0.03596959263086319, 0.01775219850242138, 0.012160922400653362, 0.03094891645014286, 0.008030841127038002, 0.013922160491347313, 0.006628178060054779, 0.040500394999980927, 0.01795930042862892, 0.017255915328860283, 0.005027745850384235, 0.0021177518647164106, 0.0054833898320794106, 0.029896575957536697, 0.009526753798127174, 0.035335518419742584, 0.020311202853918076, 0.004240009468048811, 0.006591949611902237, 0.013411017134785652, 0.0035469543654471636, 0.00346316397190094, 0.013256405480206013, 0.04767502471804619, 0.009653797373175621, 0.09990601241588593, 0.016066376119852066, 0.7977171540260315, 0.014421586878597736, 0.015865720808506012, 0.027096325531601906, 0.006471195258200169, 0.013426768593490124, 0.0156335961073637, 0.006362052168697119, 0.008242649957537651, 0.01966985873878002, 0.009265570901334286, 0.0022425197530537844, 0.06991323828697205, 0.10005412250757217, 0.018972255289554596, 0.05847277119755745, 0.0077947406098246574, 0.02889261208474636, 0.016637366265058517, 0.011893611401319504, 0.014522369019687176, 0.013637174852192402, 0.013546342961490154, 0.005002312827855349, 0.027826383709907532, 0.010772323235869408, 0.026431307196617126, 0.003390798345208168, 0.03126503899693489, 0.014802915044128895, 0.0009761783294379711, 0.012936802580952644, 0.013840584084391594, 0.011702138930559158, 0.021116120740771294, 0.02217256650328636, 0.05265570804476738, 0.02970072627067566, 0.009128168225288391, 0.027859026566147804, 0.023140188306570053, 0.03192972391843796, 0.008048677816987038, 0.04732881486415863, 0.00963572971522808, 0.009676186367869377, 0.03022809699177742, 0.022328080609440804, 0.007815653458237648, 0.7944053411483765, 0.009061048738658428, 0.022070053964853287, 0.005616520997136831, 0.019811712205410004, 0.7989731431007385, 0.010530505329370499, 0.026326527819037437, 0.0035682017914950848, 0.01494855247437954, 0.01197245717048645, 0.011065268889069557, 0.01619580388069153, 0.03833794966340065, 0.09424341470003128, 0.004663561470806599, 0.004711167421191931, 0.015341098420321941, 0.05412427708506584, 0.03842584788799286, 0.012596555054187775, 0.015521232970058918, 0.020831981673836708, 0.024355117231607437, 0.08478088676929474, 0.020198475569486618, 0.035508010536432266, 0.007851767353713512, 0.7427888512611389, 0.029704952612519264, 0.006181602366268635, 0.799292266368866, 0.018049994483590126, 0.004780139774084091, 0.03264761343598366, 0.02222144417464733, 0.02263813093304634, 0.01319374144077301, 0.028366655111312866, 0.007078567054122686, 0.015872685238718987, 0.02158256620168686, 0.020910004153847694, 0.7814533710479736, 0.021557170897722244, 0.019539879634976387, 0.009996350854635239, 0.0164174921810627, 0.007736891508102417, 0.005857677198946476, 0.008474083617329597, 0.009179584681987762, 0.021304812282323837, 0.013007487170398235, 0.010964424349367619, 0.002251287456601858, 0.0042485143058001995, 0.006300459615886211, 0.010626270435750484, 0.0018964611226692796, 0.004802278708666563, 0.012448849156498909, 0.016238335520029068, 0.0034204360563308, 0.005348517093807459, 0.024896560236811638, 0.012299750000238419, 0.7405999898910522, 0.02808241918683052, 0.03627726435661316, 0.03536381945014, 0.565003514289856, 0.7972384691238403, 0.032512497156858444, 0.03980829194188118, 0.01714838482439518, 0.03152630478143692, 0.0074035003781318665, 0.011518041603267193, 0.006421475205570459, 0.020600629970431328, 0.015187943354249, 0.791697084903717, 0.001897444948554039, 0.011579238809645176, 0.019372573122382164, 0.014283810742199421, 0.007346571423113346, 0.04039398580789566, 0.010731843300163746, 0.0015426338650286198, 0.003135905135422945, 0.0015662709483876824, 0.006758209317922592, 0.018574120476841927, 0.002674536081030965, 0.04073459282517433, 0.7883399724960327, 0.005677624139934778, 0.01032305508852005, 0.00914095714688301, 0.025207946076989174, 0.009390924125909805, 0.0072190179489552975, 0.04835141822695732, 0.09349651634693146, 0.02730383910238743, 0.007617869880050421, 0.0038379605393856764, 0.015789268538355827, 0.7903738021850586, 0.02402878925204277, 0.02207729034125805, 0.042302269488573074, 0.01388306450098753, 0.01513739489018917, 0.001544671831652522, 0.005603994242846966, 0.03689988702535629, 0.018321778625249863, 0.0316220298409462, 0.01104007475078106, 0.026234272867441177, 0.014842708595097065, 0.6864896416664124, 0.013136553578078747, 0.008831319399178028, 0.04763228818774223, 0.02125556766986847, 0.023542094975709915, 0.015849333256483078, 0.010171240195631981, 0.0015528457006439567, 0.014934616163372993]\n",
    "# sNDF\n",
    "# pass auc: 0.906219929469\n",
    "# np auc: 0.537146818279\n",
    "# all auc: 0.96693334906\n",
    "# raw all auc: 0.973497947064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y = [0.012500000000000001, 0.013333333333333334, 0.015000000000000001, 0.0050000000000000001, 0.030000000000000002, 0.0050000000000000001, 0.020833333333333336, 0.024999999999999994, 0.01, 0.0083333333333333332, 0.013333333333333334, 0.0066666666666666662, 0.0016666666666666668, 0.017499999999999998, 0.0, 0.15333333333333335, 0.0083333333333333332, 0.0058333333333333336, 0.024999999999999998, 0.024166666666666666, 0.0016666666666666668, 0.023333333333333331, 0.0058333333333333336, 0.02, 0.0016666666666666668, 0.0025000000000000001,0.0075000000000000006, 0.0066666666666666671, 0.010833333333333334, 0.014166666666666668, 0.025833333333333333, 0.90166666666666662, 0.019166666666666665, 0.014166666666666668, 0.0016666666666666668, 0.036666666666666667, 0.049166666666666664, 0.020833333333333332, 0.0, 0.0033333333333333335, 0.017499999999999998, 0.0066666666666666671, 0.01833333333333333, 0.011666666666666667, 0.0025000000000000001, 0.033333333333333333, 0.034166666666666665, 0.015000000000000001, 0.015000000000000001, 0.96250000000000002, 0.017499999999999998, 0.023333333333333334, 0.00083333333333333339, 0.010833333333333334, 0.010833333333333334, 0.0050000000000000001, 0.0091666666666666667, 0.0033333333333333335, 0.0016666666666666668, 0.0091666666666666667, 0.010833333333333334, 0.0016666666666666668, 0.017500000000000002, 0.011666666666666667, 0.02, 0.021666666666666667, 0.011666666666666667, 0.02416666666666667, 0.0041666666666666666, 0.014166666666666668, 0.9458333333333333, 0.0083333333333333332, 0.013333333333333334, 0.035000000000000003, 0.34749999999999998, 0.025000000000000001, 0.97499999999999987, 0.020833333333333332, 0.012500000000000001, 0.0, 0.0016666666666666668, 0.02, 0.0083333333333333332, 0.022500000000000003, 0.0083333333333333332, 0.018333333333333333, 0.011666666666666667, 0.014166666666666668, 0.011666666666666667, 0.92833333333333323, 0.032500000000000001, 0.012500000000000001, 0.022499999999999999, 0.015000000000000001, 0.0058333333333333336, 0.0074999999999999997, 0.0066666666666666671, 0.012500000000000001, 0.020833333333333336, 0.0058333333333333336, 0.0033333333333333335, 0.024999999999999998, 0.91083333333333327, 0.018333333333333333, 0.010833333333333334, 0.92916666666666659, 0.010833333333333334, 0.0083333333333333332, 0.025833333333333337, 0.0, 0.030833333333333334, 0.014166666666666668, 0.012500000000000001, 0.0066666666666666662, 0.0025000000000000001, 0.0050000000000000001, 0.0050000000000000001, 0.014166666666666668, 0.0016666666666666668, 0.021666666666666664, 0.0091666666666666667, 0.0083333333333333332, 0.025833333333333333, 0.94666666666666666, 0.013333333333333334, 0.0025000000000000001, 0.029166666666666667, 0.0058333333333333336, 0.022499999999999999, 0.0083333333333333332, 0.020833333333333332, 0.018333333333333333, 0.01, 0.011666666666666667, 0.020833333333333332, 0.0058333333333333336, 0.31166666666666665, 0.0033333333333333335, 0.044166666666666667, 0.025833333333333333, 0.015833333333333335, 0.0025000000000000001, 0.034999999999999996, 0.010833333333333334, 0.0075000000000000006, 0.0016666666666666668, 0.0041666666666666666, 0.0033333333333333335, 0.92000000000000004, 0.02, 0.028333333333333332, 0.0058333333333333336, 0.0, 0.014166666666666666, 0.019166666666666669, 0.019166666666666665, 0.0058333333333333336, 0.017500000000000002, 0.0025000000000000001, 0.0083333333333333332,0.0050000000000000001, 0.010833333333333334, 0.019166666666666665, 0.019166666666666669, 0.0091666666666666667, 0.025000000000000001, 0.0058333333333333336, 0.012500000000000001, 0.0066666666666666662, 0.019166666666666669, 0.02, 0.019166666666666662, 0.015833333333333335, 0.0058333333333333336, 0.0025000000000000001, 0.85333333333333328, 0.019166666666666669, 0.030000000000000002, 0.0091666666666666667, 0.018333333333333333, 0.0, 0.0058333333333333336, 0.91499999999999992, 0.0033333333333333335, 0.014166666666666668, 0.0033333333333333335, 0.012500000000000001, 0.011666666666666667, 0.00083333333333333339, 0.014166666666666668, 0.92749999999999999, 0.0, 0.018333333333333333, 0.0091666666666666667, 0.0050000000000000001, 0.0075000000000000006, 0.019166666666666665, 0.016666666666666666, 0.0025000000000000001, 0.017500000000000002, 0.015000000000000001, 0.021666666666666667, 0.012500000000000001, 0.0066666666666666671, 0.0, 0.0050000000000000001, 0.015833333333333335, 0.015833333333333335, 0.013333333333333334, 0.0050000000000000001, 0.015833333333333335, 0.016666666666666666, 0.015000000000000001, 0.0083333333333333332, 0.035833333333333328, 0.0050000000000000001, 0.023333333333333331, 0.0050000000000000001, 0.074166666666666672, 0.010833333333333334, 0.014166666666666668, 0.015833333333333335, 0.0025000000000000001, 0.0066666666666666671, 0.010833333333333334, 0.015833333333333335, 0.0083333333333333332, 0.0058333333333333336, 0.028333333333333332, 0.018333333333333333, 0.024166666666666666, 0.015000000000000001, 0.0074999999999999997, 0.015000000000000001, 0.011666666666666667, 0.0041666666666666666, 0.014166666666666668, 0.034166666666666665, 0.01, 0.011666666666666667, 0.02, 0.022499999999999996, 0.032500000000000001, 0.00083333333333333339, 0.0058333333333333336, 0.98666666666666658, 0.0, 0.024999999999999998, 0.01, 0.023333333333333334, 0.96750000000000003, 0.019166666666666665, 0.0091666666666666667, 0.017499999999999998, 0.017500000000000002, 0.015833333333333335, 0.028333333333333335, 0.97166666666666668, 0.0091666666666666667, 0.023333333333333331, 0.013333333333333334, 0.0016666666666666668, 0.069166666666666668, 0.0091666666666666667, 0.020833333333333336, 0.0074999999999999997, 0.029166666666666667, 0.016666666666666666, 0.00083333333333333339, 0.023333333333333334, 0.015000000000000001, 0.0058333333333333336, 0.0016666666666666668, 0.01, 0.0083333333333333332, 0.0083333333333333332, 0.013333333333333334, 0.9291666666666667, 0.02, 0.01, 0.0041666666666666666, 0.029999999999999999, 0.0275, 0.0066666666666666671, 0.0083333333333333332, 0.0083333333333333332, 0.0050000000000000001, 0.0041666666666666666, 0.0275,0.016666666666666666, 0.011666666666666667, 0.010833333333333334, 0.012500000000000001, 0.0066666666666666671, 0.013333333333333334, 0.036666666666666674, 0.023333333333333331, 0.012500000000000001, 0.014166666666666668, 0.017500000000000002, 0.0066666666666666671, 0.021666666666666667, 0.0058333333333333336, 0.024999999999999994, 0.0016666666666666668,0.0041666666666666666, 0.041666666666666664, 0.0275, 0.018333333333333333, 0.015000000000000001, 0.0058333333333333336, 0.017499999999999998, 0.0050000000000000001, 0.014166666666666668, 0.015000000000000001, 0.0033333333333333335, 0.01, 0.0058333333333333336, 0.0066666666666666671, 0.0091666666666666667, 0.017500000000000002, 0.020833333333333332, 0.0016666666666666668, 0.0075000000000000006, 0.00083333333333333339, 0.0050000000000000001, 0.010833333333333334, 0.024166666666666666, 0.0025000000000000001, 0.00083333333333333339, 0.015000000000000001, 0.015833333333333335, 0.019166666666666665, 0.012500000000000001, 0.0066666666666666671, 0.011666666666666667, 0.0033333333333333335, 0.013333333333333334, 0.0075000000000000006, 0.05333333333333333, 0.20666666666666669, 0.0074999999999999997, 0.0066666666666666671, 0.0050000000000000001, 0.014166666666666668, 0.0066666666666666671, 0.012500000000000001, 0.024999999999999998, 0.0041666666666666666, 0.15500000000000003, 0.016666666666666666, 0.0041666666666666666, 0.0041666666666666666, 0.0058333333333333336, 0.0066666666666666671, 0.0033333333333333335, 0.024166666666666666, 0.043333333333333335, 0.0075000000000000006, 0.29000000000000004, 0.014166666666666668, 0.0016666666666666668, 0.0091666666666666667, 0.01, 0.011666666666666667, 0.015833333333333335, 0.030833333333333331, 0.016666666666666666, 0.0041666666666666666, 0.015000000000000001, 0.03333333333333334, 0.0025000000000000001, 0.073333333333333334, 0.16250000000000001, 0.0041666666666666666, 0.019166666666666669, 0.015000000000000001, 0.75916666666666666, 0.015000000000000001, 0.028333333333333332, 0.050833333333333341, 0.0041666666666666666, 0.0083333333333333332, 0.0091666666666666667, 0.024999999999999998, 0.030833333333333334, 0.97000000000000008, 0.011666666666666667, 0.010833333333333334, 0.010833333333333334, 0.0075000000000000006, 0.016666666666666666, 0.019166666666666669, 0.0075000000000000006, 0.037500000000000006, 0.0016666666666666668, 0.058333333333333327, 0.029166666666666667, 0.0066666666666666671, 0.0091666666666666667, 0.0033333333333333335, 0.0033333333333333335, 0.0, 0.028333333333333335, 0.00083333333333333339, 0.014166666666666668, 0.042500000000000003, 0.012500000000000001, 0.0041666666666666666, 0.018333333333333333, 0.96583333333333343, 0.0041666666666666666, 0.98666666666666669, 0.013333333333333334, 0.0091666666666666667, 0.94166666666666643, 0.010833333333333334, 0.0050000000000000001, 0.0066666666666666671, 0.018333333333333333, 0.0066666666666666671, 0.0, 0.0050000000000000001, 0.0041666666666666666, 0.012500000000000001, 0.019166666666666665, 0.0050000000000000001, 0.010833333333333334,0.0, 0.017500000000000002, 0.018333333333333333, 0.01, 0.032500000000000001, 0.014166666666666668, 0.0074999999999999997, 0.0033333333333333335, 0.0025000000000000001, 0.012500000000000001, 0.0058333333333333336, 0.024999999999999998, 0.0074999999999999997, 0.0016666666666666668, 0.010833333333333334, 0.0041666666666666666, 0.014166666666666668, 0.026666666666666668, 0.92749999999999988, 0.0083333333333333332, 0.0, 0.018333333333333333, 0.013333333333333334, 0.014999999999999999, 0.013333333333333334, 0.0058333333333333336, 0.96750000000000003, 0.0033333333333333335, 0.010833333333333334, 0.00083333333333333339, 0.0050000000000000001, 0.0083333333333333332, 0.0091666666666666667, 0.022500000000000003, 0.021666666666666667, 0.010833333333333334, 0.0033333333333333335, 0.025833333333333333, 0.020833333333333332, 0.0091666666666666667, 0.017499999999999998, 0.0066666666666666671,0.010833333333333334, 0.023333333333333331, 0.0041666666666666666, 0.013333333333333334, 0.0016666666666666668, 0.0075000000000000006, 0.0074999999999999997, 0.0025000000000000001, 0.013333333333333334, 0.022499999999999999, 0.0033333333333333335, 0.0275, 0.0050000000000000001, 0.012500000000000001, 0.023333333333333331, 0.015833333333333335, 0.0075000000000000006, 0.013333333333333334, 0.0033333333333333335, 0.014166666666666668, 0.98333333333333328, 0.0033333333333333335, 0.034999999999999996, 0.95416666666666661, 0.029166666666666667, 0.010833333333333334, 0.0033333333333333335, 0.024166666666666666, 0.020833333333333332, 0.0058333333333333336, 0.0083333333333333332, 0.015000000000000001, 0.030833333333333331, 0.032500000000000001, 0.011666666666666667, 0.0075000000000000006, 0.0033333333333333335, 0.015833333333333335, 0.024166666666666666, 0.0058333333333333336, 0.0058333333333333336, 0.0083333333333333332, 0.010833333333333334, 0.015833333333333335, 0.020833333333333336, 0.013333333333333334, 0.0066666666666666671, 0.024166666666666666, 0.024166666666666666, 0.0033333333333333335, 0.54249999999999998, 0.033333333333333333, 0.0041666666666666666, 0.0025000000000000001, 0.0075000000000000006, 0.91666666666666652, 0.0, 0.0058333333333333336, 0.0050000000000000001, 0.0275, 0.017500000000000002, 0.0033333333333333335, 0.0033333333333333335, 0.0025000000000000001, 0.013333333333333334, 0.0016666666666666668, 0.015000000000000001, 0.019166666666666665, 0.0275, 0.024166666666666663, 0.020833333333333336, 0.0050000000000000001, 0.0016666666666666668, 0.010833333333333334, 0.024999999999999994, 0.96249999999999991, 0.0041666666666666666, 0.0091666666666666667, 0.015833333333333335, 0.0016666666666666668, 0.0066666666666666671, 0.0, 0.018333333333333333,0.0066666666666666671, 0.037500000000000006, 0.022499999999999996, 0.0083333333333333332, 0.0033333333333333335, 0.024166666666666666, 0.0066666666666666671, 0.0016666666666666668, 0.0041666666666666666, 0.0, 0.0, 0.012500000000000001, 0.024999999999999998, 0.0050000000000000001, 0.95916666666666661, 0.0, 0.0041666666666666666, 0.02, 0.02, 0.018333333333333333, 0.023333333333333334, 0.0066666666666666671, 0.016666666666666666, 0.0050000000000000001, 0.02, 0.0033333333333333335, 0.019166666666666669, 0.095000000000000001, 0.021666666666666664, 0.0058333333333333336, 0.029166666666666667, 0.019166666666666665, 0.012500000000000001, 0.91333333333333333, 0.95916666666666672, 0.01833333333333333, 0.011666666666666667, 0.0025000000000000001, 0.013333333333333334, 0.011666666666666667, 0.019166666666666669, 0.015000000000000001, 0.27500000000000002, 0.0058333333333333336, 0.0050000000000000001, 0.0041666666666666666, 0.011666666666666667, 0.011666666666666667, 0.0091666666666666667, 0.0050000000000000001, 0.0033333333333333335, 0.0058333333333333336, 0.98083333333333322, 0.02, 0.95750000000000002, 0.017500000000000002, 0.015000000000000001, 0.01, 0.043333333333333328, 0.015000000000000001, 0.96833333333333327, 0.021666666666666667, 0.0050000000000000001, 0.00083333333333333339, 0.019166666666666669, 0.0075000000000000006, 0.012500000000000001, 0.0058333333333333336, 0.0025000000000000001, 0.0091666666666666667, 0.0041666666666666666, 0.019166666666666665, 0.015000000000000001, 0.0050000000000000001, 0.0041666666666666666, 0.01, 0.019999999999999997, 0.0091666666666666667, 0.015833333333333335, 0.021666666666666664, 0.96166666666666667, 0.040000000000000001, 0.012500000000000001, 0.0033333333333333335, 0.98666666666666658, 0.029166666666666667, 0.010833333333333334, 0.011666666666666667, 0.050000000000000003, 0.010833333333333334, 0.0083333333333333332, 0.010833333333333334, 0.019166666666666665, 0.048333333333333339, 0.022500000000000003, 0.0, 0.012500000000000001, 0.029999999999999999, 0.0083333333333333332, 0.023333333333333331, 0.024166666666666666, 0.0016666666666666668, 0.0275, 0.93749999999999989, 0.0091666666666666667, 0.011666666666666665, 0.0066666666666666671, 0.0050000000000000001, 0.0, 0.056666666666666657, 0.18250000000000005, 0.0016666666666666668, 0.012500000000000001, 0.93833333333333313, 0.024166666666666666, 0.021666666666666667, 0.0075000000000000006, 0.0275, 0.026666666666666665, 0.01, 0.025000000000000001, 0.0091666666666666667, 0.025833333333333333, 0.012500000000000001, 0.97333333333333327, 0.014166666666666668, 0.0016666666666666668, 0.0091666666666666667, 0.013333333333333334, 0.0050000000000000001, 0.013333333333333334, 0.018333333333333333, 0.0, 0.023333333333333331, 0.94083333333333319, 0.015833333333333331, 0.015000000000000001, 0.0041666666666666666, 0.02, 0.014166666666666668, 0.0033333333333333335, 0.0066666666666666671, 0.0091666666666666667, 0.96666666666666679, 0.01, 0.0025000000000000001, 0.01, 0.96666666666666667, 0.014166666666666668, 0.01,0.031666666666666662, 0.0050000000000000001, 0.013333333333333334, 0.014166666666666666, 0.0025000000000000001, 0.021666666666666667, 0.010833333333333334, 0.0091666666666666667, 0.00083333333333333339, 0.018333333333333333, 0.0066666666666666671, 0.013333333333333334, 0.014166666666666668, 0.030833333333333334, 0.0066666666666666671, 0.012500000000000001, 0.00083333333333333339, 0.033333333333333333, 0.017500000000000002, 0.0, 0.023333333333333334, 0.011666666666666667, 0.016666666666666663, 0.015000000000000001, 0.96166666666666667, 0.97249999999999992, 0.0075000000000000006, 0.0016666666666666668, 0.94499999999999995, 0.0041666666666666666, 0.015833333333333335, 0.0083333333333333332, 0.018333333333333333, 0.019166666666666665, 0.015833333333333335, 0.024166666666666666, 0.022499999999999999, 0.0, 0.028333333333333335, 0.0041666666666666666, 0.047499999999999994, 0.032500000000000001, 0.016666666666666666, 0.013333333333333334, 0.0066666666666666671, 0.0075000000000000006, 0.016666666666666666, 0.9375, 0.012500000000000001, 0.013333333333333334, 0.010833333333333334, 0.011666666666666665, 0.015833333333333335, 0.031666666666666662, 0.0033333333333333335, 0.0050000000000000001, 0.017500000000000002, 0.015833333333333335, 0.011666666666666667, 0.0075000000000000006, 0.018333333333333333, 0.0041666666666666666, 0.0075000000000000006, 0.010833333333333334, 0.0091666666666666667, 0.0091666666666666667,0.0016666666666666668, 0.0074999999999999997, 0.013333333333333334, 0.014166666666666668, 0.024166666666666659, 0.015833333333333335, 0.0016666666666666668, 0.0083333333333333332, 0.010833333333333334, 0.029166666666666667, 0.0083333333333333332, 0.017500000000000002, 0.0091666666666666667, 0.0066666666666666671, 0.016666666666666666, 0.010833333333333334, 0.011666666666666667, 0.020833333333333336, 0.0016666666666666668, 0.015833333333333335, 0.93666666666666654, 0.017499999999999998, 0.02, 0.0041666666666666666, 0.023333333333333331, 0.93916666666666659, 0.021666666666666667, 0.0058333333333333336, 0.0033333333333333335, 0.012500000000000001, 0.039166666666666669, 0.0083333333333333332, 0.0041666666666666666, 0.011666666666666667, 0.94333333333333336, 0.0066666666666666671, 0.010833333333333334, 0.021666666666666667, 0.0033333333333333335, 0.21166666666666667, 0.010833333333333334, 0.011666666666666667, 0.013333333333333334, 0.014166666666666668, 0.029166666666666667, 0.0033333333333333335, 0.010833333333333334, 0.92833333333333323, 0.022500000000000003, 0.021666666666666664, 0.0041666666666666666, 0.017500000000000002, 0.017500000000000002, 0.012500000000000001, 0.0075000000000000006, 0.0050000000000000001, 0.013333333333333334, 0.037499999999999999, 0.0083333333333333332, 0.015833333333333335, 0.011666666666666667, 0.0050000000000000001, 0.02, 0.90083333333333349, 0.020833333333333332, 0.021666666666666667, 0.92249999999999988, 0.0041666666666666666, 0.020833333333333332, 0.0, 0.0058333333333333336, 0.0075000000000000006, 0.015833333333333335, 0.02, 0.01, 0.012500000000000001, 0.0016666666666666668, 0.017500000000000002, 0.0016666666666666668, 0.0016666666666666668, 0.028333333333333335, 0.014166666666666668, 0.039166666666666669, 0.0075000000000000006, 0.018333333333333333, 0.014166666666666668, 0.010833333333333334, 0.0083333333333333332, 0.0058333333333333336, 0.023333333333333331, 0.0033333333333333335, 0.85999999999999999, 0.010833333333333334, 0.024999999999999998, 0.01, 0.97083333333333333, 0.0041666666666666666, 0.015833333333333335, 0.014999999999999999, 0.020833333333333332, 0.010833333333333334, 0.015833333333333335, 0.0091666666666666667, 0.0050000000000000001, 0.0058333333333333336, 0.013333333333333334, 0.91833333333333322, 0.020833333333333336, 0.026666666666666665, 0.89833333333333332, 0.017499999999999998, 0.026666666666666665, 0.030833333333333331, 0.0016666666666666668, 0.015833333333333335, 0.0074999999999999997, 0.01, 0.016666666666666666, 0.99416666666666664, 0.012500000000000001, 0.0075000000000000006, 0.80916666666666659, 0.0025000000000000001, 0.013333333333333332, 0.016666666666666666, 0.018333333333333333, 0.044166666666666674, 0.0275, 0.0075000000000000006, 0.0075000000000000006, 0.011666666666666667, 0.0050000000000000001, 0.0075000000000000006, 0.032499999999999994, 0.010833333333333334, 0.020833333333333332, 0.016666666666666666, 0.16083333333333333, 0.0058333333333333336, 0.016666666666666666, 0.013333333333333334, 0.01, 0.016666666666666666, 0.00083333333333333339, 0.98666666666666669, 0.0083333333333333332, 0.0058333333333333336, 0.020833333333333332, 0.0050000000000000001, 0.9408333333333333, 0.014166666666666666, 0.96250000000000002, 0.013333333333333334, 0.021666666666666667, 0.0058333333333333336, 0.010833333333333334, 0.010833333333333334, 0.0, 0.0083333333333333332, 0.0083333333333333332, 0.0041666666666666666, 0.014166666666666668, 0.011666666666666667, 0.034999999999999996, 0.012500000000000001, 0.015833333333333335, 0.01833333333333333, 0.0066666666666666671, 0.018333333333333333, 0.0033333333333333335, 0.0016666666666666668, 0.0025000000000000001, 0.02416666666666667, 0.014166666666666668, 0.00083333333333333339, 0.060000000000000005, 0.038333333333333337, 0.010833333333333334, 0.00083333333333333339, 0.0058333333333333336, 0.0033333333333333335, 0.0066666666666666671, 0.0066666666666666671, 0.010833333333333334, 0.037500000000000006, 0.023333333333333331, 0.017499999999999998, 0.0083333333333333332, 0.016666666666666666, 0.01, 0.0074999999999999997, 0.0016666666666666668, 0.03833333333333333, 0.015000000000000001, 0.020833333333333332, 0.04083333333333334, 0.0025000000000000001, 0.011666666666666667, 0.0074999999999999997, 0.035000000000000003,0.029166666666666671, 0.94583333333333319, 0.017500000000000002, 0.025000000000000001, 0.0041666666666666666, 0.0066666666666666671, 0.018333333333333333, 0.019166666666666665, 0.0033333333333333335, 0.014166666666666668, 0.013333333333333334, 0.017499999999999998, 0.00083333333333333339, 0.015833333333333335, 0.033333333333333333, 0.013333333333333334,0.010833333333333334, 0.023333333333333334, 0.0025000000000000001, 0.00083333333333333339, 0.0041666666666666666, 0.023333333333333334, 0.0083333333333333332, 0.026666666666666665, 0.028333333333333332, 0.017500000000000002, 0.0066666666666666671, 0.037499999999999999, 0.017500000000000002, 0.0016666666666666668, 0.018333333333333333, 0.0058333333333333336, 0.026666666666666665, 0.01, 0.97416666666666663, 0.020833333333333332, 0.022499999999999996, 0.0058333333333333336, 0.023333333333333331, 0.0033333333333333335, 0.0091666666666666667, 0.95999999999999996, 0.0058333333333333336, 0.012500000000000001, 0.0083333333333333332, 0.018333333333333333, 0.015000000000000001, 0.0066666666666666671, 0.021666666666666667, 0.065000000000000002, 0.03833333333333333, 0.01, 0.019166666666666669, 0.017500000000000002, 0.0075000000000000006, 0.0066666666666666671, 0.015833333333333335, 0.012500000000000001, 0.0033333333333333335, 0.010833333333333334, 0.0025000000000000001, 0.029166666666666667, 0.00083333333333333339, 0.0041666666666666666, 0.023333333333333334, 0.0058333333333333336, 0.021666666666666667, 0.0033333333333333335, 0.014166666666666668, 0.020833333333333332, 0.012500000000000001, 0.0033333333333333335, 0.0033333333333333335, 0.016666666666666663, 0.017499999999999998, 0.0016666666666666668, 0.015833333333333335, 0.019166666666666669, 0.040000000000000001, 0.011666666666666667, 0.0058333333333333336, 0.0058333333333333336, 0.031666666666666669, 0.019166666666666665, 0.029166666666666667, 0.013333333333333334, 0.0, 0.98499999999999999, 0.0025000000000000001, 0.011666666666666667, 0.0041666666666666666, 0.20833333333333334, 0.036666666666666667, 0.0091666666666666667, 0.0066666666666666671, 0.029166666666666667, 0.0041666666666666666, 0.020833333333333336, 0.0033333333333333335, 0.011666666666666667, 0.020833333333333336, 0.015000000000000001, 0.02583333333333333, 0.0091666666666666667, 0.01, 0.019166666666666662, 0.0050000000000000001, 0.0058333333333333336, 0.0075000000000000006, 0.021666666666666667, 0.015833333333333335, 0.97333333333333338, 0.010833333333333334, 0.014166666666666668, 0.025833333333333333, 0.012500000000000001, 0.0075000000000000006, 0.0016666666666666668, 0.020833333333333332, 0.018333333333333333, 0.0075000000000000006, 0.015000000000000001, 0.018333333333333333, 0.98499999999999999, 0.90499999999999992, 0.99583333333333324, 0.9258333333333334, 0.02, 0.031666666666666669, 0.026666666666666665, 0.0066666666666666671, 0.034999999999999996, 0.0091666666666666667, 0.0050000000000000001, 0.013333333333333334, 0.0016666666666666668, 0.0058333333333333336, 0.014166666666666668, 0.014166666666666668, 0.93333333333333324, 0.97166666666666657, 0.015833333333333335, 0.025000000000000001, 0.0091666666666666667, 0.00083333333333333339, 0.020833333333333336, 0.98166666666666669, 0.012500000000000001, 0.0, 0.017500000000000002, 0.014166666666666668, 0.0033333333333333335, 0.026666666666666668, 0.044166666666666667, 0.0033333333333333335, 0.026666666666666665, 0.019999999999999997, 0.0041666666666666666, 0.024999999999999998, 0.0066666666666666662, 0.96500000000000008, 0.01, 0.016666666666666666, 0.91583333333333328, 0.0083333333333333332, 0.01, 0.0066666666666666671, 0.99249999999999994, 0.0066666666666666671, 0.00083333333333333339, 0.0083333333333333332, 0.030000000000000002, 0.97666666666666668, 0.0041666666666666666, 0.0033333333333333335, 0.01, 0.0050000000000000001, 0.014166666666666668, 0.0075000000000000006, 0.018333333333333333, 0.028333333333333328, 0.0058333333333333336, 0.16083333333333333, 0.0041666666666666666, 0.01, 0.0041666666666666666, 0.0275, 0.018333333333333333, 0.031666666666666669, 0.0066666666666666671, 0.0016666666666666668, 0.010833333333333334, 0.0033333333333333335, 0.014166666666666668, 0.0050000000000000001, 0.017500000000000002, 0.93833333333333324, 0.013333333333333334, 0.95833333333333326, 0.016666666666666666, 0.0016666666666666668, 0.0050000000000000001, 0.0050000000000000001, 0.0, 0.023333333333333334, 0.69916666666666671, 0.024166666666666666, 0.00083333333333333339, 0.017499999999999998, 0.011666666666666667, 0.0025000000000000001, 0.019166666666666669, 0.0083333333333333332, 0.031666666666666669, 0.88916666666666666, 0.014166666666666668, 0.014166666666666668, 0.0033333333333333335, 0.02416666666666667, 0.95250000000000001, 0.01, 0.01, 0.019166666666666669, 0.0033333333333333335, 0.0083333333333333332, 0.0016666666666666668,0.012500000000000001, 0.025833333333333333, 0.012500000000000001, 0.0033333333333333335, 0.0025000000000000001, 0.011666666666666667, 0.023333333333333331, 0.0041666666666666666, 0.0041666666666666666, 0.0083333333333333332, 0.016666666666666666, 0.0025000000000000001, 0.125, 0.0058333333333333336, 0.017499999999999998, 0.012500000000000001, 0.014166666666666668, 0.022500000000000003, 0.012500000000000001, 0.0041666666666666666, 0.020833333333333332, 0.043333333333333335, 0.032499999999999994, 0.020833333333333332, 0.032500000000000001, 0.01, 0.0058333333333333336, 0.0083333333333333332, 0.0083333333333333332, 0.016666666666666666, 0.0050000000000000001, 0.01, 0.055833333333333339, 0.17333333333333331,0.0025000000000000001, 0.0066666666666666671, 0.0083333333333333332, 0.014166666666666668, 0.024999999999999998, 0.00083333333333333339, 0.49916666666666665, 0.8091666666666667,0.022499999999999999, 0.0033333333333333335, 0.0075000000000000006, 0.015000000000000001, 0.0050000000000000001, 0.0016666666666666668, 0.011666666666666667, 0.02, 0.022499999999999999, 0.023333333333333331, 0.067500000000000004, 0.042500000000000003, 0.014166666666666668, 0.014166666666666668, 0.015000000000000001, 0.45416666666666672, 0.012500000000000001, 0.89333333333333331, 0.017500000000000002, 0.0025000000000000001, 0.029166666666666667, 0.016666666666666666, 0.016666666666666666, 0.012500000000000001, 0.0025000000000000001, 0.00083333333333333339, 0.0025000000000000001, 0.011666666666666667, 0.014166666666666668, 0.02416666666666667, 0.0058333333333333336, 0.0041666666666666666, 0.016666666666666666, 0.011666666666666667, 0.0075000000000000006, 0.0016666666666666668, 0.0050000000000000001, 0.017500000000000002, 0.17166666666666669, 0.00083333333333333339, 0.018333333333333333, 0.0275, 0.02, 0.014166666666666668, 0.020833333333333329, 0.013333333333333334, 0.01, 0.029166666666666667, 0.029999999999999999, 0.0058333333333333336, 0.0050000000000000001, 0.015000000000000001, 0.0066666666666666671, 0.0016666666666666668, 0.0083333333333333332, 0.0041666666666666666, 0.0033333333333333335, 0.033333333333333333, 0.026666666666666668, 0.0050000000000000001, 0.0025000000000000001, 0.00083333333333333339, 0.040000000000000001, 0.02416666666666667, 0.019166666666666669, 0.024999999999999998, 0.0058333333333333336, 0.016666666666666666, 0.012500000000000001, 0.0041666666666666666, 0.019166666666666669, 0.012500000000000001, 0.0075000000000000006, 0.022499999999999996, 0.020833333333333332, 0.0075000000000000006, 0.015000000000000001, 0.013333333333333334, 0.024999999999999998, 0.0016666666666666668, 0.012500000000000001, 0.021666666666666667, 0.02, 0.016666666666666663, 0.012500000000000001, 0.0025000000000000001, 0.95833333333333326, 0.024999999999999998, 0.98333333333333317, 0.025833333333333326, 0.021666666666666667, 0.022499999999999999, 0.015833333333333335, 0.020833333333333332, 0.92666666666666653, 0.063333333333333339, 0.0033333333333333335, 0.018333333333333333, 0.0066666666666666671, 0.0083333333333333332, 0.02, 0.015833333333333335, 0.021666666666666664, 0.012500000000000001, 0.020833333333333336, 0.011666666666666667, 0.0025000000000000001, 0.0050000000000000001, 0.00083333333333333339, 0.020833333333333332, 0.0041666666666666666, 0.0033333333333333335, 0.0074999999999999997, 0.98166666666666669, 0.035000000000000003, 0.0066666666666666671, 0.010833333333333334, 0.0033333333333333335, 0.029999999999999999, 0.014166666666666668, 0.0016666666666666668, 0.0058333333333333336, 0.0066666666666666671, 0.020833333333333332, 0.95583333333333331, 0.0066666666666666671, 0.010833333333333334, 0.064166666666666664, 0.022500000000000003, 0.0058333333333333336, 0.00083333333333333339, 0.96499999999999997, 0.013333333333333334, 0.036666666666666667, 0.0083333333333333332, 0.0075000000000000006, 0.014166666666666668, 0.96999999999999997, 0.01, 0.013333333333333334, 0.9375, 0.019999999999999997, 0.034166666666666665, 0.99166666666666659, 0.022499999999999999, 0.015000000000000001, 0.0058333333333333336, 0.017500000000000002, 0.015000000000000001, 0.0058333333333333336, 0.028333333333333328, 0.015000000000000001, 0.015833333333333335, 0.89916666666666667, 0.0050000000000000001, 0.92333333333333323, 0.29416666666666669, 0.022500000000000003, 0.015000000000000001, 0.021666666666666667, 0.010833333333333334, 0.16, 0.0050000000000000001, 0.02, 0.012500000000000001, 0.026666666666666668, 0.33833333333333332, 0.0041666666666666666, 0.0033333333333333335, 0.0058333333333333336, 0.023333333333333331, 0.018333333333333333, 0.0066666666666666671, 0.01, 0.0075000000000000006, 0.0041666666666666666, 0.011666666666666667, 0.0075000000000000006, 0.0016666666666666668, 0.0016666666666666668, 0.035000000000000003, 0.023333333333333331, 0.01, 0.0066666666666666671, 0.022499999999999999, 0.0033333333333333335, 0.0025000000000000001, 0.0083333333333333332, 0.0083333333333333332, 0.02, 0.011666666666666667, 0.01, 0.0058333333333333336, 0.011666666666666667, 0.0016666666666666668, 0.0066666666666666671, 0.0025000000000000001, 0.014166666666666668, 0.029166666666666667, 0.0, 0.014166666666666668, 0.011666666666666667, 0.0, 0.01, 0.015000000000000001, 0.021666666666666664, 0.0041666666666666666, 0.0066666666666666671, 0.010833333333333334, 0.0083333333333333332, 0.017499999999999998, 0.011666666666666667, 0.017499999999999998, 0.0074999999999999997, 0.015000000000000001, 0.0066666666666666662, 0.028333333333333335, 0.010833333333333334, 0.01833333333333333, 0.01, 0.017500000000000002, 0.026666666666666668, 0.017499999999999998, 0.97333333333333327, 0.032500000000000001, 0.01, 0.023333333333333327, 0.0025000000000000001, 0.01, 0.016666666666666666, 0.33250000000000002, 0.017500000000000002, 0.010833333333333334, 0.01, 0.020833333333333332, 0.014166666666666668, 0.0025000000000000001, 0.021666666666666667, 0.02, 0.96583333333333332, 0.015833333333333335, 0.054166666666666669, 0.0033333333333333335, 0.016666666666666666, 0.0066666666666666671, 0.025000000000000001, 0.025833333333333333, 0.9458333333333333, 0.011666666666666667, 0.0066666666666666671, 0.015833333333333335, 0.011666666666666667, 0.0033333333333333335, 0.020833333333333332, 0.019166666666666665, 0.0050000000000000001, 0.0041666666666666666, 0.0025000000000000001, 0.0050000000000000001, 0.0058333333333333336, 0.016666666666666666, 0.030000000000000002, 0.95333333333333325, 0.28916666666666668, 0.024166666666666666, 0.024999999999999998, 0.0025000000000000001, 0.02416666666666667, 0.010833333333333334, 0.0025000000000000001, 0.012499999999999999, 0.0016666666666666668, 0.012500000000000001, 0.0, 0.020833333333333332, 0.018333333333333333, 0.0066666666666666671, 0.0033333333333333335, 0.015833333333333335, 0.30999999999999994, 0.90166666666666662, 0.0066666666666666671, 0.014166666666666668, 0.0058333333333333336, 0.015833333333333335, 0.035833333333333335, 0.90000000000000002, 0.0075000000000000006, 0.97750000000000004, 0.029166666666666664, 0.0066666666666666671, 0.024166666666666663, 0.0066666666666666662, 0.054166666666666669, 0.024166666666666663, 0.013333333333333334, 0.0058333333333333336, 0.0066666666666666671, 0.024166666666666666, 0.0041666666666666666, 0.013333333333333334, 0.015833333333333335, 0.0083333333333333332, 0.055833333333333332, 0.0050000000000000001, 0.93666666666666654, 0.0, 0.023333333333333334, 0.0066666666666666671, 0.029999999999999999, 0.0, 0.022499999999999999, 0.02, 0.019166666666666669, 0.011666666666666667, 0.018333333333333333, 0.013333333333333334, 0.019166666666666662, 0.025833333333333333, 0.017500000000000002, 0.029999999999999999, 0.96083333333333332, 0.91166666666666674,0.026666666666666665, 0.0066666666666666671, 0.020833333333333332, 0.0083333333333333332, 0.0066666666666666671, 0.0, 0.19833333333333333, 0.021666666666666664, 0.012500000000000001, 0.056666666666666671, 0.00083333333333333339, 0.0033333333333333335, 0.0075000000000000006, 0.0066666666666666671, 0.013333333333333334, 0.0091666666666666667, 0.0025000000000000001, 0.015833333333333331, 0.016666666666666666, 0.01, 0.029999999999999999, 0.02416666666666667, 0.0041666666666666666, 0.010833333333333334, 0.89416666666666678, 0.029166666666666667, 0.0050000000000000001, 0.010833333333333334, 0.018333333333333333, 0.0083333333333333332, 0.0091666666666666667, 0.015833333333333335, 0.97583333333333333, 0.028333333333333332, 0.0066666666666666671, 0.017500000000000002, 0.0033333333333333335, 0.0, 0.0050000000000000001, 0.03333333333333334, 0.018333333333333333, 0.030833333333333334, 0.0016666666666666668, 0.019166666666666665, 0.014166666666666668, 0.0050000000000000001, 0.013333333333333334, 0.014166666666666668, 0.0025000000000000001, 0.0025000000000000001, 0.015000000000000001, 0.025833333333333333, 0.0083333333333333332, 0.017500000000000002, 0.0, 0.017500000000000002, 0.67000000000000004, 0.026666666666666665, 0.0083333333333333332, 0.0, 0.021666666666666667, 0.0091666666666666667, 0.0016666666666666668, 0.0025000000000000001, 0.0033333333333333335, 0.017500000000000002, 0.010833333333333334, 0.0083333333333333332, 0.012500000000000001, 0.014166666666666668, 0.90166666666666662, 0.01, 0.0091666666666666667, 0.019166666666666669, 0.012500000000000001, 0.01, 0.0058333333333333336, 0.86416666666666675, 0.0050000000000000001, 0.0033333333333333335, 0.0041666666666666666, 0.012500000000000001, 0.02, 0.0066666666666666662, 0.0066666666666666671, 0.00083333333333333339, 0.0091666666666666667, 0.017500000000000002, 0.0, 0.0050000000000000001, 0.011666666666666667, 0.020833333333333332, 0.011666666666666667, 0.0083333333333333332, 0.010833333333333334, 0.0091666666666666667, 0.017499999999999998, 0.95333333333333337, 0.023333333333333334, 0.0058333333333333336, 0.0041666666666666666, 0.016666666666666666, 0.016666666666666666, 0.0025000000000000001, 0.011666666666666667, 0.97416666666666685, 0.0058333333333333336, 0.022499999999999999, 0.0050000000000000001, 0.030000000000000002, 0.0050000000000000001, 0.01, 0.90166666666666662, 0.0083333333333333332, 0.030000000000000002, 0.0083333333333333332, 0.0075000000000000006, 0.013333333333333334, 0.055833333333333332,0.021666666666666667, 0.0075000000000000006, 0.023333333333333334, 0.92833333333333334, 0.014166666666666668, 0.011666666666666667, 0.017500000000000002, 0.014166666666666668, 0.0041666666666666666, 0.0050000000000000001, 0.021666666666666667, 0.013333333333333334, 0.0091666666666666667, 0.011666666666666667, 0.025833333333333333, 0.0083333333333333332,0.013333333333333332, 0.016666666666666666, 0.011666666666666667, 0.0058333333333333336, 0.028333333333333335, 0.015833333333333335, 0.02, 0.019166666666666669, 0.020833333333333332, 0.0083333333333333332, 0.0091666666666666667, 0.0050000000000000001, 0.01, 0.012500000000000001, 0.83166666666666655, 0.012500000000000001, 0.021666666666666667, 0.96499999999999986, 0.0016666666666666668, 0.0041666666666666666, 0.015000000000000001, 0.0066666666666666671, 0.0091666666666666667, 0.0041666666666666666, 0.0058333333333333336, 0.0066666666666666671, 0.015833333333333335, 0.94333333333333336, 0.0025000000000000001, 0.0025000000000000001, 0.023333333333333331, 0.0041666666666666666, 0.0066666666666666671, 0.022499999999999999, 0.013333333333333334, 0.037499999999999999, 0.0074999999999999997, 0.081666666666666665, 0.0091666666666666667, 0.010833333333333334, 0.0025000000000000001, 0.020833333333333329, 0.93999999999999984, 0.97249999999999992, 0.013333333333333334, 0.020833333333333332, 0.020833333333333332, 0.028333333333333335, 0.0058333333333333336, 0.026666666666666661, 0.0050000000000000001, 0.016666666666666666, 0.0016666666666666668, 0.022499999999999999, 0.015833333333333335, 0.043333333333333328, 0.0050000000000000001, 0.016666666666666666, 0.024999999999999998, 0.0025000000000000001, 0.0041666666666666666, 0.015833333333333335, 0.0083333333333333332, 0.014166666666666668, 0.015000000000000001, 0.01,0.0050000000000000001, 0.0066666666666666671, 0.0, 0.66500000000000004, 0.0066666666666666662, 0.015833333333333335, 0.0066666666666666671, 0.02, 0.012500000000000001, 0.0075000000000000006, 0.018333333333333333, 0.029999999999999999, 0.0091666666666666667, 0.034166666666666665, 0.025000000000000001, 0.010833333333333334, 0.15333333333333335, 0.0025000000000000001, 0.033333333333333333, 0.0050000000000000001, 0.01, 0.076666666666666661, 0.015000000000000001, 0.021666666666666667, 0.026666666666666665, 0.0041666666666666666, 0.021666666666666667, 0.0075000000000000006, 0.0074999999999999997, 0.011666666666666667, 0.014166666666666668, 0.0083333333333333332, 0.015000000000000001, 0.017500000000000002, 0.019166666666666665, 0.0075000000000000006, 0.0033333333333333335, 0.022499999999999999, 0.020833333333333336, 0.0075000000000000006, 0.0, 0.0066666666666666671, 0.0041666666666666666, 0.015833333333333335, 0.014166666666666668, 0.0025000000000000001, 0.018333333333333333, 0.016666666666666666, 0.0091666666666666667, 0.01, 0.019166666666666665, 0.022499999999999999, 0.014999999999999999, 0.0066666666666666662, 0.0275, 0.011666666666666667, 0.00083333333333333339, 0.019166666666666665, 0.025833333333333337, 0.0083333333333333332, 0.97999999999999998, 0.019166666666666665, 0.015000000000000001, 0.0033333333333333335, 0.011666666666666667, 0.0050000000000000001, 0.013333333333333334, 0.016666666666666666, 0.018333333333333333, 0.021666666666666667, 0.90166666666666662, 0.98333333333333328, 0.91166666666666674, 0.00083333333333333339, 0.0025000000000000001, 0.029166666666666667, 0.0091666666666666667, 0.019166666666666665, 0.010833333333333334, 0.010833333333333334, 0.0025000000000000001, 0.011666666666666667, 0.01, 0.0091666666666666667, 0.0091666666666666667, 0.011666666666666667, 0.0, 0.017500000000000002, 0.02, 0.0083333333333333332, 0.0058333333333333336, 0.015000000000000001, 0.0033333333333333335, 0.020833333333333332, 0.016666666666666666, 0.011666666666666667, 0.0033333333333333335, 0.020833333333333332, 0.015000000000000001, 0.015000000000000001, 0.0075000000000000006, 0.02, 0.96416666666666662, 0.0025000000000000001, 0.024166666666666659, 0.025833333333333333, 0.0050000000000000001, 0.023333333333333327, 0.035833333333333335, 0.022500000000000003, 0.0075000000000000006,0.0041666666666666666, 0.0025000000000000001, 0.013333333333333334, 0.015833333333333335, 0.125, 0.0083333333333333332, 0.031666666666666669, 0.0058333333333333336, 0.0066666666666666671, 0.0041666666666666666, 0.27249999999999996, 0.02, 0.0058333333333333336, 0.01, 0.029999999999999995, 0.0016666666666666668, 0.015000000000000001, 0.9850000000000001, 0.97833333333333328, 0.035000000000000003, 0.0091666666666666667, 0.015833333333333335, 0.0083333333333333332, 0.0058333333333333336, 0.00083333333333333339, 0.0075000000000000006, 0.013333333333333334, 0.016666666666666666, 0.025833333333333333, 0.010833333333333334, 0.0075000000000000006, 0.0091666666666666667, 0.0058333333333333336, 0.92166666666666675, 0.016666666666666666, 0.027499999999999997, 0.024999999999999998, 0.010833333333333334, 0.016666666666666666, 0.94916666666666649, 0.022499999999999999, 0.0050000000000000001, 0.015833333333333335, 0.016666666666666666, 0.018333333333333333, 0.036666666666666667, 0.020833333333333332, 0.0091666666666666667, 0.024166666666666666, 0.0075000000000000006, 0.0091666666666666667, 0.011666666666666667, 0.96583333333333332, 0.0041666666666666666, 0.0066666666666666662, 0.96999999999999997, 0.018333333333333333, 0.20666666666666667, 0.02, 0.0091666666666666667, 0.0083333333333333332, 0.0066666666666666671, 0.013333333333333334, 0.0074999999999999997, 0.022499999999999999, 0.015833333333333335, 0.0016666666666666668, 0.0091666666666666667, 0.025833333333333333, 0.024999999999999998, 0.0016666666666666668, 0.01, 0.013333333333333334, 0.0, 0.016666666666666666, 0.0075000000000000006]\n",
    "# pass auc: 0.906219929469\n",
    "# np auc: 0.988892362882\n",
    "# all auc: 0.973699005289\n",
    "# raw all auc: 0.973497947064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1948"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass auc: 0.906219929469\n",
      "np auc: 0.537146818279\n",
      "all auc: 0.96693334906\n",
      "raw all auc: 0.973497947064\n"
     ]
    }
   ],
   "source": [
    "print(\"pass auc:\", metrics.roc_auc_score(y_test_pass, y_test_pass_pred))\n",
    "print(\"np auc:\", metrics.roc_auc_score(y_test_np, pred_y))\n",
    "print(\"all auc:\", metrics.roc_auc_score(np.hstack((y_test_np, y_test_pass)), np.hstack((pred_y, y_test_pass_pred))))\n",
    "print(\"raw all auc:\", metrics.roc_auc_score(np.hstack((y_test_np, y_test_pass)), np.hstack((y_test_np_pred, y_test_pass_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9803024568447728"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97349794706353932"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_pass.copy()\n",
    "X_test = X_test_pass.copy()\n",
    "y_train = y_train_pass.copy()\n",
    "y_test = y_test_pass.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-24 03:48:54.271602\n",
      "\n",
      "layer: 1\n",
      "start train: 2018-03-24 03:48:54.271602\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AA472150>\n",
      "[train - p:0/1:0|n:185124/1:310] \n",
      "start test: 2018-03-24 03:49:19.963877\n",
      "end test: 2018-03-24 03:49:20.302777\n",
      "test loss: y_true 99683 99683, y_pred:99683 99683\n",
      "1 [test - now p:0/1:0 | all p:0/1:0 | np:99683/1:182] \n",
      "(0,) (99683,) 99683\n",
      "train loss ('roc', 0.99918043145034752)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.96386755192753515)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.97464940713501025)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 03:49:20.428137\n",
      "best test loss: 0.974649407135\n",
      "\n",
      "layer: 2\n",
      "start train: 2018-03-24 03:49:20.445155\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AEFE80A0>\n",
      "[train - p:182142/1:8|n:2982/1:302] start test: 2018-03-24 03:49:50.218287\n",
      "end test: 2018-03-24 03:49:52.527423\n",
      "test loss: y_true 1708 99683, y_pred:1708 99683\n",
      "2 [train - now p:182142/1:8 | all p:182142/1:8 | np:2982/1:302] \n",
      "2 [test - now p:97975/1:24 | all p:97975/1:24 | np:1708/1:158] \n",
      "(97975,) (1708,) 99683\n",
      "train loss ('roc', 0.99922764544090892)\n",
      "pass train loss ('roc', 0.98008059999780384)\n",
      "pass train loss now ('roc', 0.98008059999780384)\n",
      "vaild loss ('roc', 0.96850687194832674)\n",
      "pass vaild loss ('roc', 0.61968763383003722)\n",
      "pass vaild loss now ('roc', 0.61968763383003722)\n",
      "test loss ('roc', 0.97692546245324596)\n",
      "pass test loss ('roc', 0.83606705563666184)\n",
      "pass test loss now ('roc', 0.83606705563666184)\n",
      "2018-03-24 03:49:52.953557\n",
      "best test loss: 0.976925462453\n",
      "\n",
      "layer: 3\n",
      "start train: 2018-03-24 03:49:52.974612\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AAB95E08>\n",
      "[train - p:117/1:0|n:2865/1:302] start test: 2018-03-24 03:49:54.142717\n",
      "end test: 2018-03-24 03:49:54.493678\n",
      "test loss: y_true 1658 99683, y_pred:1658 99683\n",
      "3 [train - now p:117/1:0 | all p:182259/1:8 | np:2865/1:302] \n",
      "3 [test - now p:50/1:0 | all p:98025/1:24 | np:1658/1:158] \n",
      "(98025,) (1658,) 99683\n",
      "train loss ('roc', 0.99927451034466386)\n",
      "pass train loss ('roc', 0.97994455448804119)\n",
      "pass train loss now ('mean', 0.0026638250971391881, {0})\n",
      "vaild loss ('roc', 0.98924848417781508)\n",
      "pass vaild loss ('roc', 0.61935977031676093)\n",
      "pass vaild loss now ('mean', 0.0035038830512020024, {0})\n",
      "test loss ('roc', 0.976670757409142)\n",
      "pass test loss ('roc', 0.83570044353288908)\n",
      "pass test loss now ('mean', 0.0029062161626396575, {0})\n",
      "2018-03-24 03:49:54.789467\n",
      "best test loss: 0.976925462453\n",
      "\n",
      "layer: 4\n",
      "start train: 2018-03-24 03:49:54.806512\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AAB95E08>\n",
      "[train - p:39/1:0|n:2826/1:302] start test: 2018-03-24 03:49:55.966564\n",
      "end test: 2018-03-24 03:49:56.315515\n",
      "test loss: y_true 1645 99683, y_pred:1645 99683\n",
      "4 [train - now p:39/1:0 | all p:182298/1:8 | np:2826/1:302] \n",
      "4 [test - now p:13/1:0 | all p:98038/1:24 | np:1645/1:158] \n",
      "(98038,) (1645,) 99683\n",
      "train loss ('roc', 0.99927131620038556)\n",
      "pass train loss ('roc', 0.97989398760217239)\n",
      "pass train loss now ('mean', 0.0033169135313690459, {0})\n",
      "vaild loss ('roc', 0.98924917362425757)\n",
      "pass vaild loss ('roc', 0.619249204564156)\n",
      "pass vaild loss now ('mean', 0.0037464855382228937, {0})\n",
      "test loss ('roc', 0.976659326743748)\n",
      "pass test loss ('roc', 0.83559810333217699)\n",
      "pass test loss now ('mean', 0.0029765915485649294, {0})\n",
      "2018-03-24 03:49:56.614286\n",
      "best test loss: 0.976925462453\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### stackplot\n",
    "pass_data_len = []\n",
    "pass_data_pos_len = []\n",
    "### stackplot\n",
    "\n",
    "# 统计信息\n",
    "train_loss_lt = []\n",
    "pass_train_loss_lt = []\n",
    "pass_train_loss_lt_now = []\n",
    "vaild_loss_lt = []\n",
    "pass_vaild_loss_lt = []\n",
    "pass_vaild_loss_lt_now = []\n",
    "test_loss_lt = []\n",
    "pass_test_loss_lt = []\n",
    "pass_test_loss_lt_now = []\n",
    "pass_data_rate_lt = []\n",
    "pass_data_rate_train_lt = []\n",
    "\n",
    "# 数据\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "X_test = X_test.copy()\n",
    "test_y = np.array(([0.0] * len(X_test)))\n",
    "all_pass_data_mask = np.array([False] * len(X_test))\n",
    "# data_mask = np.array([False] * len(X_test))\n",
    "real_y = y_test.copy()\n",
    "\n",
    "# 不均衡数据进行layer\n",
    "X_train_np = X\n",
    "y_train_np = y\n",
    "maxlayer = 100\n",
    "maxlayer = 10\n",
    "layer = 0\n",
    "\n",
    "# 不降低不更新\n",
    "last_train_loss = 0\n",
    "last_vaild_loss = 0\n",
    "\n",
    "# enhancedDTree = EnhancedForest_0322.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
    "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
    "counter = 0\n",
    "early_stop = 0\n",
    "early_stop_up = 0\n",
    "tmp_test_loss = 0\n",
    "\n",
    "ts = time.time()\n",
    "tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "print(tm)\n",
    "    \n",
    "while 1:\n",
    "    layer += 1\n",
    "    print()\n",
    "    print(\"layer:\", layer)\n",
    "    X = X_train_np\n",
    "    y = y_train_np\n",
    "    if layer == 1: isFirst = True\n",
    "    else: isFirst = False\n",
    "        \n",
    "    clf, now_pass_data_mask, p_test = \\\n",
    "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
    "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
    "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
    "                                     )\n",
    "    feval=roc_metrix_mult\n",
    "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
    "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
    "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
    "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
    "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
    "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
    "    test_loss = enhancedDTree.getTestLoss(feval)\n",
    "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
    "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
    "    \n",
    "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
    "# #     if vaild_loss[1] < last_vaild_loss: \n",
    "#         if not isFirst: enhancedDTree.remove_last_items()\n",
    "# #         early_stop_up += 1\n",
    "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
    "#             break\n",
    "#         continue\n",
    "        \n",
    "    last_train_loss = train_loss[1]\n",
    "    last_vaild_loss = vaild_loss[1]\n",
    "    \n",
    "    \n",
    "    # 打印信息\n",
    "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
    "#     X_test_np = X_test[all_np_data_index]\n",
    "    \n",
    "    X_train_np = enhancedDTree.X_train_np\n",
    "    y_train_np = enhancedDTree.y_train_np\n",
    "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
    "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
    "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
    "    if layer != 1:\n",
    "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
    "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
    "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
    "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
    "    \n",
    "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
    "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
    "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
    "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
    "    now_test_y = real_y[~all_pass_data_mask]\n",
    "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
    "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
    "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
    "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
    "    \n",
    "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
    "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
    "\n",
    "    #len(pass_data_id),\n",
    "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
    "#                                       len(X_test_np) - len(pass_data_id), \\\n",
    "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
    "    ### stackplot\n",
    "#     pass_data_len.append(len(pass_data_id))\n",
    "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
    "    ### stackplot\n",
    "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
    "        \n",
    "    print(\"train loss\", train_loss)\n",
    "    print(\"pass train loss\", pass_train_loss)\n",
    "    print(\"pass train loss now\", pass_train_loss_now)\n",
    "    print(\"vaild loss\", vaild_loss)\n",
    "    print(\"pass vaild loss\", pass_vaild_loss)\n",
    "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
    "    print(\"test loss\", test_loss)\n",
    "    print(\"pass test loss\", pass_test_loss)\n",
    "    print(\"pass test loss now\", pass_test_loss_now)\n",
    "    \n",
    "    ts = time.time()\n",
    "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    print(tm)\n",
    "    \n",
    "    \n",
    "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
    "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
    "    tmp =  metrics.roc_auc_score(y_test, test_y)\n",
    "    if tmp_test_loss < tmp:\n",
    "        tmp_test_loss = tmp\n",
    "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
    "        best_test_y = test_y.copy()\n",
    "    print(\"best test loss:\", tmp_test_loss)\n",
    "    \n",
    "    train_loss_lt.append(train_loss[1])\n",
    "    pass_train_loss_lt.append(pass_train_loss[1])\n",
    "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
    "    vaild_loss_lt.append(vaild_loss[1])\n",
    "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
    "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
    "    test_loss_lt.append(test_loss[1])\n",
    "    pass_test_loss_lt.append(pass_test_loss[1])\n",
    "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
    "    \n",
    "    \n",
    "#     if len(pass_data_rate_lt) == 0:\n",
    "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
    "#         pass_data_rate_train_lt.append(0)\n",
    "#     else:\n",
    "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
    "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
    "    # 打印信息结束\n",
    "    \n",
    "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
    "#     if layer > maxlayer or early_stop > 5:\n",
    "#         break\n",
    "        \n",
    "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
    "    \n",
    "    if layer == 4: break\n",
    "#     if layer == 20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182519,)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancedDTree.p_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182519,)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancedDTree.p_all_fold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-24 01:56:57\n",
      "\n",
      "layer: 1\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC6359E8>\n",
      "[train - p:0/1:0|n:182519/1:8] \n",
      "test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "1 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49910690314556383)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.49766076506742501)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:57:08\n",
      "best test loss: 0.497660765067\n",
      "\n",
      "layer: 2\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC6359E8>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "2 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "2 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49893431080866357)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.49717151331682108)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:57:24\n",
      "best test loss: 0.497660765067\n",
      "\n",
      "layer: 3\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "3 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "3 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49893978993046995)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.538966013991241)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:57:40\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 4\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "4 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "4 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.4990055393921462)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.49728872988206996)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:57:56\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 5\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "5 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "5 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.4990438932447907)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.4975333557573719)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:58:12\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 6\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC6359E8>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "6 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "6 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49902197675756532)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.5182157090582924)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:58:28\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 7\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC6359E8>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "7 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "7 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49885486354247144)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.51775193916969897)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:58:44\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 8\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "8 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "8 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49875349978905381)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.51764725118660548)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:59:00\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 9\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC6359E8>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "9 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "9 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49895622729588901)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.51795239648418268)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:59:16\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 10\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "10 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "10 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49895622729588901)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.51816814291587243)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:59:31\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 11\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC6359E8>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "11 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "11 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 0.99999999999999989)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49898088334401763)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.53875536393195322)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 01:59:47\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 12\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "12 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "12 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49888773827330957)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.49704920037917011)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 02:00:02\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 13\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC6359E8>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "13 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "13 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49907128885382251)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.51808745035283887)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 02:00:18\n",
      "best test loss: 0.538966013991\n",
      "\n",
      "layer: 14\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "14 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "14 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49900827895304939)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.53902886925086713)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 02:00:34\n",
      "best test loss: 0.539028869251\n",
      "\n",
      "layer: 15\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC6359E8>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "15 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "15 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49876171847176337)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.53853621991866185)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 02:00:50\n",
      "best test loss: 0.539028869251\n",
      "\n",
      "layer: 16\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "16 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "16 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49901923719666214)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.49739065733011245)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 02:01:06\n",
      "best test loss: 0.539028869251\n",
      "\n",
      "layer: 17\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC6359E8>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "17 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "17 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49893978993046995)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.51788402015445412)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 02:01:21\n",
      "best test loss: 0.539028869251\n",
      "\n",
      "layer: 18\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "18 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "18 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.4988713009078905)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.49711035684799559)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 02:01:37\n",
      "best test loss: 0.539028869251\n",
      "\n",
      "layer: 19\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635410>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "19 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "19 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49892335256505088)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.49720209155123385)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 02:01:53\n",
      "best test loss: 0.539028869251\n",
      "\n",
      "layer: 20\n",
      "index_train: <generator object _BaseKFold.split at 0x000001B2AC635A40>\n",
      "[train - p:0/1:0|n:182519/1:8] test loss: y_true 98133 98133, y_pred:98133 98133\n",
      "20 [train - now p:0/1:0 | all p:0/1:0 | np:182519/1:8] \n",
      "20 [test - now p:0/1:0 | all p:0/1:0 | np:98133/1:24] \n",
      "(0,) (98133,) 98133\n",
      "train loss ('roc', 1.0)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.49883568661614919)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.49699314028274671)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-24 02:02:09\n",
      "best test loss: 0.539028869251\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### stackplot\n",
    "pass_data_len = []\n",
    "pass_data_pos_len = []\n",
    "### stackplot\n",
    "\n",
    "# 统计信息\n",
    "train_loss_lt = []\n",
    "pass_train_loss_lt = []\n",
    "pass_train_loss_lt_now = []\n",
    "vaild_loss_lt = []\n",
    "pass_vaild_loss_lt = []\n",
    "pass_vaild_loss_lt_now = []\n",
    "test_loss_lt = []\n",
    "pass_test_loss_lt = []\n",
    "pass_test_loss_lt_now = []\n",
    "pass_data_rate_lt = []\n",
    "pass_data_rate_train_lt = []\n",
    "\n",
    "# 数据\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "X_test = X_test.copy()\n",
    "test_y = np.array(([0.0] * len(X_test)))\n",
    "all_pass_data_mask = np.array([False] * len(X_test))\n",
    "# data_mask = np.array([False] * len(X_test))\n",
    "real_y = y_test.copy()\n",
    "\n",
    "# 不均衡数据进行layer\n",
    "X_train_np = X\n",
    "y_train_np = y\n",
    "maxlayer = 100\n",
    "maxlayer = 10\n",
    "layer = 0\n",
    "\n",
    "# 不降低不更新\n",
    "last_train_loss = 0\n",
    "last_vaild_loss = 0\n",
    "\n",
    "# enhancedDTree = EnhancedForest_0322.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
    "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
    "counter = 0\n",
    "early_stop = 0\n",
    "early_stop_up = 0\n",
    "tmp_test_loss = 0\n",
    "\n",
    "ts = time.time()\n",
    "tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(tm)\n",
    "    \n",
    "while 1:\n",
    "    layer += 1\n",
    "    print()\n",
    "    print(\"layer:\", layer)\n",
    "    X = X_train_np\n",
    "    y = y_train_np\n",
    "    if layer == 1: isFirst = True\n",
    "    else: isFirst = False\n",
    "        \n",
    "    clf, now_pass_data_mask, p_test = \\\n",
    "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
    "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
    "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
    "                                     )\n",
    "    feval=roc_metrix_mult\n",
    "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
    "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
    "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
    "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
    "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
    "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
    "    test_loss = enhancedDTree.getTestLoss(feval)\n",
    "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
    "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
    "    \n",
    "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
    "# #     if vaild_loss[1] < last_vaild_loss: \n",
    "#         if not isFirst: enhancedDTree.remove_last_items()\n",
    "# #         early_stop_up += 1\n",
    "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
    "#             break\n",
    "#         continue\n",
    "        \n",
    "    last_train_loss = train_loss[1]\n",
    "    last_vaild_loss = vaild_loss[1]\n",
    "    \n",
    "    \n",
    "    # 打印信息\n",
    "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
    "#     X_test_np = X_test[all_np_data_index]\n",
    "    \n",
    "    X_train_np = enhancedDTree.X_train_np\n",
    "    y_train_np = enhancedDTree.y_train_np\n",
    "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
    "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
    "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
    "    if layer != 1:\n",
    "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
    "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
    "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
    "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
    "    \n",
    "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
    "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
    "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
    "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
    "    now_test_y = real_y[~all_pass_data_mask]\n",
    "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
    "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
    "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
    "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
    "    \n",
    "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
    "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
    "\n",
    "    #len(pass_data_id),\n",
    "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
    "#                                       len(X_test_np) - len(pass_data_id), \\\n",
    "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
    "    ### stackplot\n",
    "#     pass_data_len.append(len(pass_data_id))\n",
    "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
    "    ### stackplot\n",
    "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
    "        \n",
    "    print(\"train loss\", train_loss)\n",
    "    print(\"pass train loss\", pass_train_loss)\n",
    "    print(\"pass train loss now\", pass_train_loss_now)\n",
    "    print(\"vaild loss\", vaild_loss)\n",
    "    print(\"pass vaild loss\", pass_vaild_loss)\n",
    "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
    "    print(\"test loss\", test_loss)\n",
    "    print(\"pass test loss\", pass_test_loss)\n",
    "    print(\"pass test loss now\", pass_test_loss_now)\n",
    "    \n",
    "    ts = time.time()\n",
    "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(tm)\n",
    "    \n",
    "    \n",
    "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
    "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
    "    tmp =  metrics.roc_auc_score(y_test, test_y)\n",
    "    if tmp_test_loss < tmp:\n",
    "        tmp_test_loss = tmp\n",
    "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
    "        best_test_y = test_y.copy()\n",
    "    print(\"best test loss:\", tmp_test_loss)\n",
    "    \n",
    "    train_loss_lt.append(train_loss[1])\n",
    "    pass_train_loss_lt.append(pass_train_loss[1])\n",
    "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
    "    vaild_loss_lt.append(vaild_loss[1])\n",
    "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
    "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
    "    test_loss_lt.append(test_loss[1])\n",
    "    pass_test_loss_lt.append(pass_test_loss[1])\n",
    "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
    "    \n",
    "    \n",
    "#     if len(pass_data_rate_lt) == 0:\n",
    "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
    "#         pass_data_rate_train_lt.append(0)\n",
    "#     else:\n",
    "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
    "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
    "    # 打印信息结束\n",
    "    \n",
    "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
    "#     if layer > maxlayer or early_stop > 5:\n",
    "#         break\n",
    "        \n",
    "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
    "    \n",
    "#     if layer == 2: break\n",
    "    if layer == 20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2605, 30), (2605,), (182519, 30), (182519,))"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np = enhancedDTree.X_train_np.copy()\n",
    "y_train_np = enhancedDTree.y_train_np.copy()\n",
    "X_train_pass_lt = enhancedDTree.pass_data_x_list.copy()\n",
    "y_train_pass_lt = enhancedDTree.pass_data_y_list.copy()\n",
    "X_train_pass = np.array([j for i in np.array(X_train_pass_lt) for j in i])\n",
    "y_train_pass = np.array([j for i in np.array(y_train_pass_lt) for j in i])\n",
    "X_train_np.shape, y_train_np.shape, X_train_pass.shape, y_train_pass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((98133, 30), (98133,), (1550, 30), (1550,))"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_np = X_test[~all_pass_data_mask].copy()\n",
    "y_test_np = real_y[~all_pass_data_mask].copy()\n",
    "X_test_pass = X_test[all_pass_data_mask].copy()\n",
    "y_test_pass = real_y[all_pass_data_mask].copy()\n",
    "X_test_pass.shape, y_test_pass.shape, X_test_np.shape, y_test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_pass.copy()\n",
    "X_test = X_test_pass.copy()\n",
    "y_train = y_train_pass.copy()\n",
    "y_test = y_test_pass.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int64),\n",
       " array([ 0.95877878,  0.98315427,  0.97645002,  0.96749512,  0.97563014,\n",
       "         0.94486974,  0.9369539 ,  0.96217077]))"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_y[all_pass_test_data_id], test_y[all_pass_test_data_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97947450083609511"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_test_y_ = best_test_y.copy()\n",
    "best_test_y_[all_pass_test_data_id] = 1\n",
    "best_test_y_[best_test_y_ < 0.00001] = 0\n",
    "best_test_y_[best_test_y_ > 0.9] = 1\n",
    "metrics.roc_auc_score(y_test, best_test_y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.43074933e-04,   1.79052656e-04,   5.02422838e-04, ...,\n",
       "         1.40892487e-04,   9.42264133e-05,   1.07041333e-04])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_test_y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97947450083609511"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_test, best_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_test_y[now_test_y[now_np_test_data_id] < 0.000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_test_y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer: 1\n",
      "[train - p:0/1:0|n:185124/1:310] \n",
      "<class 'numpy.ndarray'> (185124,)\n",
      "<class 'numpy.ndarray'> (185124,)\n",
      "test loss: y_true 99683 99683, y_pred:99683 99683\n",
      "<class 'numpy.ndarray'> (99683,)\n",
      "1 [test - now p:0/1:0 | all p:0/1:0 | np:99683/1:182] \n",
      "(0,) (99683,) 99683\n",
      "train loss ('roc', 0.99763055584743099)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.96743750560720687)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.97538875582563578)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-23 12:49:45\n",
      "best test loss: 0.975388755826\n",
      "\n",
      "layer: 2\n",
      "[train - p:0/1:0|n:185124/1:310] <class 'numpy.ndarray'> (185124,)\n",
      "<class 'numpy.ndarray'> (185124,)\n",
      "test loss: y_true 99683 99683, y_pred:99683 99683\n",
      "<class 'numpy.ndarray'> (99683,)\n",
      "2 [train - now p:0/1:0 | all p:0/1:0 | np:185124/1:310] \n",
      "2 [test - now p:0/1:0 | all p:0/1:0 | np:99683/1:182] \n",
      "(0,) (99683,) 99683\n",
      "train loss ('roc', 0.99694611880052375)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.96209605856559532)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.97181573413973088)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 0)\n",
      "2018-03-23 12:50:24\n",
      "best test loss: 0.97181573414\n",
      "\n",
      "layer: 3\n",
      "[train - p:7/1:7|n:185117/1:303] <class 'numpy.ndarray'> (185124,)\n",
      "<class 'numpy.ndarray'> (185124,)\n",
      "test loss: y_true 99679 99683, y_pred:99679 99683\n",
      "<class 'numpy.ndarray'> (99683,)\n",
      "3 [train - now p:7/1:7 | all p:7/1:7 | np:185117/1:303] \n",
      "3 [test - now p:4/1:4 | all p:4/1:4 | np:99679/1:178] \n",
      "(4,) (99679,) 99683\n",
      "train loss ('roc', 0.9984277304784549)\n",
      "pass train loss ('mean', 0.97223327761032152, {1.0})\n",
      "pass train loss now ('mean', 0.97223327761032152, {1})\n",
      "vaild loss ('roc', 0.96479509302639754)\n",
      "pass vaild loss ('mean', 0.96103399871919393, {1.0})\n",
      "pass vaild loss now ('mean', 0.96103399871919393, {1})\n",
      "test loss ('roc', 0.97877446921677635)\n",
      "pass test loss ('mean', 0.96246562992271134, {1.0})\n",
      "pass test loss now ('mean', 0.96246562992271134, {1})\n",
      "2018-03-23 12:51:12\n",
      "best test loss: 0.978774469217\n",
      "\n",
      "layer: 4\n",
      "[train - p:0/1:0|n:185117/1:303] <class 'numpy.ndarray'> (185124,)\n",
      "<class 'numpy.ndarray'> (185124,)\n",
      "test loss: y_true 99679 99683, y_pred:99679 99683\n",
      "<class 'numpy.ndarray'> (99683,)\n",
      "4 [train - now p:0/1:0 | all p:7/1:7 | np:185117/1:303] \n",
      "4 [test - now p:0/1:0 | all p:4/1:4 | np:99679/1:178] \n",
      "(4,) (99679,) 99683\n",
      "train loss ('roc', 0.99886908092774707)\n",
      "pass train loss ('mean', 0.97223327761032152, {1.0})\n",
      "pass train loss now (0, 0)\n",
      "vaild loss ('roc', 0.96769335132759471)\n",
      "pass vaild loss ('mean', 0.96103399871919393, {1.0})\n",
      "pass vaild loss now (0, 0)\n",
      "test loss ('roc', 0.97427824183334177)\n",
      "pass test loss ('mean', 0.96246562992271134, {1.0})\n",
      "pass test loss now (0, 0)\n",
      "2018-03-23 12:51:44\n",
      "best test loss: 0.974278241833\n",
      "\n",
      "layer: 5\n",
      "[train - p:3/1:3|n:185114/1:300] <class 'numpy.ndarray'> (185124,)\n",
      "<class 'numpy.ndarray'> (185124,)\n",
      "test loss: y_true 99678 99683, y_pred:99678 99683\n",
      "<class 'numpy.ndarray'> (99683,)\n",
      "5 [train - now p:3/1:3 | all p:10/1:10 | np:185114/1:300] \n",
      "5 [test - now p:1/1:1 | all p:5/1:5 | np:99678/1:177] \n",
      "(5,) (99678,) 99683\n",
      "train loss ('roc', 0.9982109126630192)\n",
      "pass train loss ('mean', 0.96997607540961395, {1.0})\n",
      "pass train loss now ('mean', 0.96470927027462972, {1})\n",
      "vaild loss ('roc', 0.97003826340484611)\n",
      "pass vaild loss ('mean', 0.96750713031470814, {1.0})\n",
      "pass vaild loss now ('mean', 0.98261110403757457, {1})\n",
      "test loss ('roc', 0.97681427576353264)\n",
      "pass test loss ('mean', 0.96660335839159317, {1.0})\n",
      "pass test loss now ('mean', 0.9831542722671206, {1})\n",
      "2018-03-23 12:52:16\n",
      "best test loss: 0.976814275764\n",
      "\n",
      "layer: 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-288-1d24f9fe136e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0misFirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnow_pass_data_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_test\u001b[0m \u001b[1;33m=\u001b[0m         \u001b[0menhancedDTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainModelLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_pass_data_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m                                       \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroc_metrix_mult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m                                       \u001b[0misFirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misFirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m                                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroc_metrix_mult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menhancedDTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrainLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\github_workspace\\ecoForest\\EnhancedForest.py\u001b[0m in \u001b[0;36mTrainModelLayer\u001b[1;34m(self, X, y, X_test, all_pass_data_mask, y_test, real_y, verbose, feval, max_depth, random_state, min_samples_leaf, criterion, dropout, isFirst, num_class, kfold, n_estimators)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \"\"\"\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misFirst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[train - p:0/1:0|n:%d/1:%d] \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\github_workspace\\ecoForest\\EnhancedForest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, X_test, real_y, verbose, feval, max_depth, random_state, min_samples_leaf, criterion)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;31m#                                  n_estimators=2, n_jobs=8, oob_score=True, verbose=1, boostrap=False,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                                      criterion=criterion)\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;31m# cross_score = cross_val_score(clf, X_valid, y_valid, cv=3, scoring='roc_auc')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;31m# if verbose:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 327\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### stackplot\n",
    "pass_data_len = []\n",
    "pass_data_pos_len = []\n",
    "### stackplot\n",
    "\n",
    "# 统计信息\n",
    "train_loss_lt = []\n",
    "pass_train_loss_lt = []\n",
    "pass_train_loss_lt_now = []\n",
    "vaild_loss_lt = []\n",
    "pass_vaild_loss_lt = []\n",
    "pass_vaild_loss_lt_now = []\n",
    "test_loss_lt = []\n",
    "pass_test_loss_lt = []\n",
    "pass_test_loss_lt_now = []\n",
    "pass_data_rate_lt = []\n",
    "pass_data_rate_train_lt = []\n",
    "\n",
    "# 数据\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "X_test = X_test.copy()\n",
    "test_y = np.array(([0.0] * len(X_test)))\n",
    "all_pass_data_mask = np.array([False] * len(X_test))\n",
    "# data_mask = np.array([False] * len(X_test))\n",
    "real_y = y_test.copy()\n",
    "\n",
    "# 不均衡数据进行layer\n",
    "X_train_np = X\n",
    "y_train_np = y\n",
    "maxlayer = 100\n",
    "maxlayer = 10\n",
    "layer = 0\n",
    "\n",
    "# 不降低不更新\n",
    "last_train_loss = 0\n",
    "last_vaild_loss = 0\n",
    "\n",
    "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
    "counter = 0\n",
    "early_stop = 0\n",
    "early_stop_up = 0\n",
    "\n",
    "while 1:\n",
    "    layer += 1\n",
    "    print()\n",
    "    print(\"layer:\", layer)\n",
    "    X = X_train_np\n",
    "    y = y_train_np\n",
    "    if layer == 1: isFirst = True\n",
    "    else: isFirst = False\n",
    "        \n",
    "    clf, now_pass_data_mask, p_test = \\\n",
    "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
    "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
    "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
    "                                     )\n",
    "    feval=roc_metrix_mult\n",
    "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
    "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
    "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
    "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
    "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
    "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
    "    test_loss = enhancedDTree.getTestLoss(feval)\n",
    "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
    "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
    "    \n",
    "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
    "# #     if vaild_loss[1] < last_vaild_loss: \n",
    "#         if not isFirst: enhancedDTree.remove_last_items()\n",
    "# #         early_stop_up += 1\n",
    "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
    "#             break\n",
    "#         continue\n",
    "        \n",
    "    last_train_loss = train_loss[1]\n",
    "    last_vaild_loss = vaild_loss[1]\n",
    "    \n",
    "    \n",
    "    # 打印信息\n",
    "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
    "#     X_test_np = X_test[all_np_data_index]\n",
    "    \n",
    "    X_train_np = enhancedDTree.X_train_np\n",
    "    y_train_np = enhancedDTree.y_train_np\n",
    "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
    "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
    "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
    "    if layer != 1:\n",
    "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
    "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
    "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
    "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
    "    \n",
    "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
    "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
    "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
    "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
    "    now_test_y = real_y[~all_pass_data_mask]\n",
    "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
    "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
    "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
    "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
    "    \n",
    "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
    "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
    "\n",
    "    #len(pass_data_id),\n",
    "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
    "#                                       len(X_test_np) - len(pass_data_id), \\\n",
    "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
    "    ### stackplot\n",
    "#     pass_data_len.append(len(pass_data_id))\n",
    "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
    "    ### stackplot\n",
    "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
    "        \n",
    "    print(\"train loss\", train_loss)\n",
    "    print(\"pass train loss\", pass_train_loss)\n",
    "    print(\"pass train loss now\", pass_train_loss_now)\n",
    "    print(\"vaild loss\", vaild_loss)\n",
    "    print(\"pass vaild loss\", pass_vaild_loss)\n",
    "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
    "    print(\"test loss\", test_loss)\n",
    "    print(\"pass test loss\", pass_test_loss)\n",
    "    print(\"pass test loss now\", pass_test_loss_now)\n",
    "    \n",
    "    ts = time.time()\n",
    "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(tm)\n",
    "    \n",
    "    \n",
    "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
    "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
    "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
    "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
    "    best_test_y = test_y.copy()\n",
    "    print(\"best test loss:\", tmp_test_loss)\n",
    "    \n",
    "    train_loss_lt.append(train_loss[1])\n",
    "    pass_train_loss_lt.append(pass_train_loss[1])\n",
    "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
    "    vaild_loss_lt.append(vaild_loss[1])\n",
    "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
    "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
    "    test_loss_lt.append(test_loss[1])\n",
    "    pass_test_loss_lt.append(pass_test_loss[1])\n",
    "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
    "    \n",
    "    \n",
    "#     if len(pass_data_rate_lt) == 0:\n",
    "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
    "#         pass_data_rate_train_lt.append(0)\n",
    "#     else:\n",
    "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
    "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
    "    # 打印信息结束\n",
    "    \n",
    "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
    "#     if layer > maxlayer or early_stop > 5:\n",
    "#         break\n",
    "        \n",
    "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
    "    \n",
    "#     if layer == 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "df = pd.read_csv(\"./datasetes/credit/creditcard.csv\", low_memory=False)\n",
      "# df = pd.read_csv('creditcard.csv', low_memory=False)\n",
      "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
      "df.head()\n",
      "frauds = df.loc[df['Class'] == 1]\n",
      "non_frauds = df.loc[df['Class'] == 0]\n",
      "print(\"We have\", len(frauds), \"fraud data points and\", len(non_frauds), \"nonfraudulent data points.\")\n",
      "from sklearn import datasets, linear_model\n",
      "from sklearn.preprocessing import PolynomialFeatures\n",
      "from sklearn.model_selection import train_test_split\n",
      "X = df.iloc[:,:-1]\n",
      "y = df['Class']\n",
      "\n",
      "print(\"X and y sizes, respectively:\", len(X), len(y))\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=500)\n",
      "print(\"Train and test sizes, respectively:\", len(X_train), len(y_train), \"|\", len(X_test), len(y_test))\n",
      "print(\"Total number of frauds:\", len(y.loc[df['Class'] == 1]), len(y.loc[df['Class'] == 1])/len(y))\n",
      "print(\"Number of frauds on y_test:\", len(y_test.loc[df['Class'] == 1]), len(y_test.loc[df['Class'] == 1]) / len(y_test))\n",
      "print(\"Number of frauds on y_train:\", len(y_train.loc[df['Class'] == 1]), len(y_train.loc[df['Class'] == 1])/len(y_train))\n",
      "\n",
      "X_train = X_train.values\n",
      "X_test = X_test.values\n",
      "y_train = y_train.values\n",
      "y_test = y_test.values\n",
      "X_train[0], y_train[0]\n",
      "X_test[0], y_test[0]\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "import numpy as np\n",
      "\n",
      "import EnhancedForest_multiclass\n",
      "import EnhancedForest\n",
      "import DecomposerForest\n",
      "import LogUtils\n",
      "import AlgorithmUtils\n",
      "import importlib\n",
      "importlib.reload(DecomposerForest)\n",
      "importlib.reload(LogUtils)\n",
      "importlib.reload(EnhancedForest_multiclass)\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(AlgorithmUtils)\n",
      "np.seterr(divide='ignore', invalid='ignore')\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "# X_train = X_train.values\n",
      "# X_test = X_test.values\n",
      "# y_train = y_train.values\n",
      "# y_test = y_test.values\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "# decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "# decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "import numpy as np\n",
      "\n",
      "import EnhancedForest_multiclass\n",
      "import EnhancedForest\n",
      "import DecomposerForest\n",
      "import LogUtils\n",
      "import AlgorithmUtils\n",
      "import importlib\n",
      "importlib.reload(DecomposerForest)\n",
      "importlib.reload(LogUtils)\n",
      "importlib.reload(EnhancedForest_multiclass)\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(AlgorithmUtils)\n",
      "np.seterr(divide='ignore', invalid='ignore')\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "# X_train = X_train.values\n",
      "# X_test = X_test.values\n",
      "# y_train = y_train.values\n",
      "# y_test = y_test.values\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "# decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "# decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "import numpy as np\n",
      "\n",
      "import EnhancedForest_multiclass\n",
      "import EnhancedForest\n",
      "import DecomposerForest\n",
      "import LogUtils\n",
      "import AlgorithmUtils\n",
      "import importlib\n",
      "importlib.reload(DecomposerForest)\n",
      "importlib.reload(LogUtils)\n",
      "importlib.reload(EnhancedForest_multiclass)\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(AlgorithmUtils)\n",
      "np.seterr(divide='ignore', invalid='ignore')\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "# X_train = X_train.values\n",
      "# X_test = X_test.values\n",
      "# y_train = y_train.values\n",
      "# y_test = y_test.values\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "# decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "# decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "import numpy as np\n",
      "\n",
      "import EnhancedForest_multiclass\n",
      "import EnhancedForest\n",
      "import DecomposerForest\n",
      "import LogUtils\n",
      "import AlgorithmUtils\n",
      "import importlib\n",
      "importlib.reload(DecomposerForest)\n",
      "importlib.reload(LogUtils)\n",
      "importlib.reload(EnhancedForest_multiclass)\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(AlgorithmUtils)\n",
      "np.seterr(divide='ignore', invalid='ignore')\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "# X_train = X_train.values\n",
      "# X_test = X_test.values\n",
      "# y_train = y_train.values\n",
      "# y_test = y_test.values\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "# decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "# decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "#     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "import numpy as np\n",
      "\n",
      "import EnhancedForest_multiclass\n",
      "import EnhancedForest\n",
      "import DecomposerForest\n",
      "import LogUtils\n",
      "import AlgorithmUtils\n",
      "import importlib\n",
      "importlib.reload(DecomposerForest)\n",
      "importlib.reload(LogUtils)\n",
      "importlib.reload(EnhancedForest_multiclass)\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(AlgorithmUtils)\n",
      "np.seterr(divide='ignore', invalid='ignore')\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "import numpy as np\n",
      "\n",
      "import EnhancedForest_multiclass\n",
      "import EnhancedForest\n",
      "import DecomposerForest\n",
      "import LogUtils\n",
      "import AlgorithmUtils\n",
      "import importlib\n",
      "importlib.reload(DecomposerForest)\n",
      "importlib.reload(LogUtils)\n",
      "importlib.reload(EnhancedForest_multiclass)\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(AlgorithmUtils)\n",
      "np.seterr(divide='ignore', invalid='ignore')\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "# X_train = X_train.values\n",
      "# X_test = X_test.values\n",
      "# y_train = y_train.values\n",
      "# y_test = y_test.values\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "import numpy as np\n",
      "\n",
      "import EnhancedForest_multiclass\n",
      "import EnhancedForest\n",
      "import DecomposerForest\n",
      "import LogUtils\n",
      "import AlgorithmUtils\n",
      "import importlib\n",
      "importlib.reload(DecomposerForest)\n",
      "importlib.reload(LogUtils)\n",
      "importlib.reload(EnhancedForest_multiclass)\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(AlgorithmUtils)\n",
      "np.seterr(divide='ignore', invalid='ignore')\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "# X_train = X_train.values\n",
      "# X_test = X_test.values\n",
      "# y_train = y_train.values\n",
      "# y_test = y_test.values\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "import numpy as np\n",
      "\n",
      "import EnhancedForest_multiclass\n",
      "import EnhancedForest\n",
      "import DecomposerForest\n",
      "import LogUtils\n",
      "import AlgorithmUtils\n",
      "import importlib\n",
      "importlib.reload(DecomposerForest)\n",
      "importlib.reload(LogUtils)\n",
      "importlib.reload(EnhancedForest_multiclass)\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(AlgorithmUtils)\n",
      "np.seterr(divide='ignore', invalid='ignore')\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "# X_train = X_train.values\n",
      "# X_test = X_test.values\n",
      "# y_train = y_train.values\n",
      "# y_test = y_test.values\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "import numpy as np\n",
      "\n",
      "import EnhancedForest_multiclass\n",
      "import EnhancedForest\n",
      "import DecomposerForest\n",
      "import LogUtils\n",
      "import AlgorithmUtils\n",
      "import importlib\n",
      "importlib.reload(DecomposerForest)\n",
      "importlib.reload(LogUtils)\n",
      "importlib.reload(EnhancedForest_multiclass)\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(AlgorithmUtils)\n",
      "np.seterr(divide='ignore', invalid='ignore')\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "# X_train = X_train.values\n",
      "# X_test = X_test.values\n",
      "# y_train = y_train.values\n",
      "# y_test = y_test.values\n",
      "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
      "print(decoForest.enhancedDTree)\n",
      "decoForest.set_parameter(criterion=\"gini\", dropout=None, min_samples_leaf=10)\n",
      "decoForest.fit(n_estimators=200, kfold=2, feval=roc_metrix_mult)\n",
      "y_test, test_y\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test))\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(y_train_np == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(y_train_np == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "#     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(y_train_np == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "#     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(y_train_np == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "#     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(y_train_np == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id))\\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "#     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "#     if len(set(a)) == 1:\n",
      "# #         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    if type(p) == np.float:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    if type(p) == np.int64:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    elif len(p[0]) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "a = 1.0\n",
      "type(a)\n",
      "a = 1.0\n",
      "type(a) == np.float64\n",
      "a = 1.0\n",
      "type(a) == np.float64,\n",
      "type(a) == float64\n",
      "a = 1.0\n",
      "type(a) == np.float64,\n",
      "type(a) == float\n",
      "a = 1.0\n",
      "type(a) == np.float64, type(a) == int\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "#     if len(set(a)) == 1:\n",
      "# #         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    if type(p) == np.float or type(p) == float:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    if type(p) == np.int64 or type(p) == int64:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    elif len(p[0]) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "#     if len(set(a)) == 1:\n",
      "# #         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    if type(p) == np.float or type(p) == float:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    if type(p) == np.int64 or type(p) == int:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    elif len(p[0]) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "#     if len(set(a)) == 1:\n",
      "# #         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    if type(p) == np.float64 or type(p) == float:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    if type(p) == np.int64 or type(p) == int:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    elif len(p[0]) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "a = np.array([1.0], dtype=np.float64)[0]\n",
      "print(type(a)), type(a) == np.float64, type(a) == int\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "#     if len(set(a)) == 1:\n",
      "# #         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    print(type(a))\n",
      "    if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    elif len(p[0]) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "#     if len(set(a)) == 1:\n",
      "# #         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "    print(type(p), p.shape)\n",
      "    if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    elif len(p[0]) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "    return \"roc\", metrics.roc_auc_score(a, p)\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "len((185124,))\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "#     if len(set(a)) == 1:\n",
      "# #         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id)), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   )#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[pass_data_id] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "#     if len(set(a)) == 1:\n",
      "# #         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "#     if len(set(a)) == 1:\n",
      "# #         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(data_mask.shape, real_y.shape)\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "        return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(data_mask.shape, real_y.shape)\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [test - p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(data_mask.shape, real_y.shape)\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [test - p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "    break\n",
      "X_test_np\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(data_mask.shape, real_y.shape)\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [test - p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "    break\n",
      "X_test_np\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "        return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(data_mask.shape, real_y.shape)\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [test - p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "    break\n",
      "X_test_np\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "        return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(data_mask.shape, real_y.shape)\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [test - p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(y_train_np == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "    break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "        return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_data_mask = np.array([False] * len(X_test))\n",
      "data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, data_mask, all_false_data_index, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(data_mask.shape, real_y.shape)\n",
      "    pass_data_id = data_mask[data_mask==True]\n",
      "    np_data_id = data_mask[data_mask==False]\n",
      "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_false_data_index]\n",
      "    print(\"%d [test - p:%d,1:%d | np:%d,1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                      len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "                                      len(X_test_np) - len(pass_data_id), \\\n",
      "                                      len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "    pass_data_len.append(len(pass_data_id))\n",
      "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(pass_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    if len(pass_data_rate_lt) == 0:\n",
      "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(0)\n",
      "    else:\n",
      "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
      "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_data_mask[~all_data_mask] = data_mask\n",
      "    \n",
      "    if layer == 2: break\n",
      "all_false_data_index\n",
      "X_test_np\n",
      "X_test_np.shaoe\n",
      "X_test_np.shape\n",
      "X_test[all_false_data_index].shape\n",
      "data_mask\n",
      "data_mask[data_mask == True]\n",
      "data_mask[data_mask == True].shape\n",
      "data_mask[data_mask == True].shape, data_mask[data_mask == False].shape\n",
      "all_data_mask[all_data_mask == True].shape, all_data_mask[all_data_mask == False].shape\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "        return \"acc\", metrics.accuracy_score(a, p)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack(now_pass_test_data_id, last_pass_test_data_id)\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_np_data_index]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "    if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "    X_test_np = X_test[all_np_data_index]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "    if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer, len(pass_data_id),\\\n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "    if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer, \\ #len(pass_data_id),\n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "    if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer, \\ \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \\\n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "    if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "    if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.reshape(y_train_pass_lt, -1)\n",
      "    print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.reshape(y_train_pass_lt, -1)\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "X_train_pass_lt\n",
      "X_train_pass_lt[0]\n",
      "X_train_pass_lt[0].shape\n",
      "y_train_pass_lt[0].shape\n",
      "y_train_pass_lt[1].shape\n",
      "y_train_pass_lt[2].shape\n",
      "y_train_pass_lt[0].shape, y_train_pass_lt[1].shape, y_train_pass_lt[2].shape\n",
      "y_train_pass_all\n",
      "y_train_pass_lt[0]\n",
      "np.squeeze(y_train_pass_all)\n",
      "y_train_pass_lt[0][0]\n",
      "y_train_pass_lt.shape\n",
      "np.array(y_train_pass_lt).shape\n",
      "np.squeeze(np.array(y_train_pass_lt))\n",
      "[i for i in y_train_pass_lt]\n",
      "[j for j in i for i in y_train_pass_lt]\n",
      "[i for j in y_train_pass_lt for i in j]\n",
      "np.array([i for j in y_train_pass_lt for i in j]).shape\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "now_np_test_data_id\n",
      "real_y[now_np_test_data_id]\n",
      "real_y[now_np_test_data_id] == 1\n",
      "real_y[now_np_test_data_id]\n",
      "now_np_test_data_id.shape\n",
      "real_y.shape\n",
      "\",\".join(now_np_test_data_id)\n",
      "real_y[now_np_test_data_id == 1]\n",
      "real_y[now_np_test_data_id == 0]\n",
      "real_y[now_np_test_data_id] == 1\n",
      "np.where(real_y[now_np_test_data_id] == 1)\n",
      "np.where(real_y == 1)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    \n",
      "    print(np.where(real_y[now_np_test_data_id] == 1))\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "all_pass_test_data_id\n",
      "all_pass_test_data_id.shape\n",
      "np.where(real_y[all_pass_test_data_id] == 1)\n",
      "np.where(real_y[all_pass_test_data_id] == 0)\n",
      "np.where(real_y[now_np_test_data_id] == 1)\n",
      "all_pass_test_data_id.shape, all_np_test_data_id.shape\n",
      "all_pass_test_data_id.shape, now_np_test_data_id.shape\n",
      "all_pass_test_data_id.shape, now_np_test_data_id.shape\n",
      "all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0]\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "    print(now_pass_data_mask.shape, real_y.shape)\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1))\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y_copy[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y_copy[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=True, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y_copy[now_pass_test_data_id] > 0)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] > 0)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y_copy[now_np_test_data_id] > 0)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y_copy[now_pass_test_data_id] > 0)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] > 0)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y_copy[now_np_test_data_id] > 0)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y_copy[now_pass_test_data_id] > 0)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] > 0)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y_copy[now_np_test_data_id] > 0)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1)[0], len(np.where(real_y[now_np_test_data_id] == 1)[0]))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0]\n",
      "np.where(real_y[all_pass_test_data_id] == 1)\n",
      "np.where(real_y[now_np_test_data_id] == 1)\n",
      "all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0]\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    print(now_pass_data_mask, now_pass_data_mask.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y_copy[now_pass_test_data_id] > 0)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] > 0)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y_copy[now_np_test_data_id] > 0)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1)[0], len(np.where(real_y[now_np_test_data_id] == 1)[0]))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    print(now_pass_data_mask, now_pass_data_mask.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(real_y_copy[now_pass_test_data_id] > 0)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] > 0)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(real_y_copy[now_np_test_data_id] > 0)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1)[0], len(np.where(real_y[now_np_test_data_id] == 1)[0]))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "now_pass_data_mask\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    print(now_pass_data_mask, now_pass_data_mask.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] > 0)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] > 0)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] > 0)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1)[0], len(np.where(real_y[now_np_test_data_id] == 1)[0]))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    print(now_pass_data_mask, now_pass_data_mask.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[all_pass_data_mask]\n",
      "    print(now_test_y[now_pass_test_data_id].shape)\n",
      "    print(now_test_y[now_np_test_data_id].shape)\n",
      "    print(real_y[all_pass_test_data_id].shape)\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] > 0)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] > 0)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] > 0)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1)[0], len(np.where(real_y[now_np_test_data_id] == 1)[0]))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "now_test_y\n",
      "now_np_test_data_id\n",
      "now_test_y\n",
      "all_pass_data_mask\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    print(now_pass_data_mask, now_pass_data_mask.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(now_test_y[now_pass_test_data_id].shape)\n",
      "    print(now_test_y[now_np_test_data_id].shape)\n",
      "    print(real_y[all_pass_test_data_id].shape)\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] > 0)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] > 0)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] > 0)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1)[0], len(np.where(real_y[now_np_test_data_id] == 1)[0]))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "real_y_copy = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    print(now_pass_data_mask, now_pass_data_mask.shape)\n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(now_test_y[now_pass_test_data_id].shape)\n",
      "    print(now_test_y[now_np_test_data_id].shape)\n",
      "    print(real_y[all_pass_test_data_id].shape)\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] > 0)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y_copy[all_pass_test_data_id] > 0)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] > 0)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1)[0], len(np.where(real_y[now_np_test_data_id] == 1)[0]))\n",
      "    for i in range(len(real_y_copy)):\n",
      "        if real_y_copy[i] != real_y[i]:\n",
      "            print(\"error!!!\", i, real_y_copy[i], real_y[i] )\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(real_y[now_np_test_data_id] == 1)[0], len(np.where(real_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "    print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=1\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "    if layer > maxlayer or early_stop > 5:\n",
      "        break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "    best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "import EnhancedForest\n",
      "import EnhancedDTree\n",
      "import time\n",
      "import datetime\n",
      "import importlib\n",
      "import numpy as np\n",
      "importlib.reload(EnhancedForest)\n",
      "importlib.reload(EnhancedDTree)\n",
      "from sklearn import metrics\n",
      "def acc_metrix_mult(a, p):\n",
      "#     print(p)\n",
      "    return \"acc\", metrics.accuracy_score(a, p)\n",
      "def roc_metrix_mult(a, p, labels=[0,1]):\n",
      "# #     print(p)\n",
      "    if len(set(a)) == 1:\n",
      "#         return \"acc\", metrics.accuracy_score(a, p)\n",
      "        return \"mean\", np.mean(p), set(a)\n",
      "#         return \"acc\", len(a) - len(np.where(a == p)[0])\n",
      "#     if type(p) == np.float64 or type(p) == float or type(p) == np.int64 or type(p) == int:\n",
      "    if len(p.shape) == 1:\n",
      "        print(type(p), p.shape)\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "#     elif len(p[0]) == 2:\n",
      "    elif len(p.shape) == 2:\n",
      "        p = [i[1] for i in p]\n",
      "        return \"roc\", metrics.roc_auc_score(a, p)\n",
      "    else:\n",
      "        print(type(p), p.shape, \"error\")\n",
      "def confusion_matrix_mult(a, p):\n",
      "    if len(set(a)) == 1:\n",
      "        return len(a), len(a) - len(np.where(a == p)[0])\n",
      "    return metrics.confusion_matrix(a, p)\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=0.8, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=True)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=None, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=0.8, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "### stackplot\n",
      "pass_data_len = []\n",
      "pass_data_pos_len = []\n",
      "### stackplot\n",
      "\n",
      "# 统计信息\n",
      "train_loss_lt = []\n",
      "pass_train_loss_lt = []\n",
      "pass_train_loss_lt_now = []\n",
      "vaild_loss_lt = []\n",
      "pass_vaild_loss_lt = []\n",
      "pass_vaild_loss_lt_now = []\n",
      "test_loss_lt = []\n",
      "pass_test_loss_lt = []\n",
      "pass_test_loss_lt_now = []\n",
      "pass_data_rate_lt = []\n",
      "pass_data_rate_train_lt = []\n",
      "\n",
      "# 数据\n",
      "X = X_train.copy()\n",
      "y = y_train.copy()\n",
      "\n",
      "X_test = X_test.copy()\n",
      "test_y = np.array(([0.0] * len(X_test)))\n",
      "all_pass_data_mask = np.array([False] * len(X_test))\n",
      "# data_mask = np.array([False] * len(X_test))\n",
      "real_y = y_test.copy()\n",
      "\n",
      "# 不均衡数据进行layer\n",
      "X_train_np = X\n",
      "y_train_np = y\n",
      "maxlayer = 100\n",
      "maxlayer = 10\n",
      "layer = 0\n",
      "\n",
      "# 不降低不更新\n",
      "last_train_loss = 0\n",
      "last_vaild_loss = 0\n",
      "\n",
      "enhancedDTree = EnhancedForest.EnhancedForest(len(X_train), len(X_test), isLRStacker=False)\n",
      "counter = 0\n",
      "early_stop = 0\n",
      "early_stop_up = 0\n",
      "\n",
      "while 1:\n",
      "    layer += 1\n",
      "    print()\n",
      "    print(\"layer:\", layer)\n",
      "    X = X_train_np\n",
      "    y = y_train_np\n",
      "    if layer == 1: isFirst = True\n",
      "    else: isFirst = False\n",
      "        \n",
      "    clf, now_pass_data_mask, p_test = \\\n",
      "        enhancedDTree.TrainModelLayer(X, y, X_test, all_pass_data_mask, test_y, real_y, verbose=False, \\\n",
      "                                      feval=roc_metrix_mult, dropout=0.8, criterion='gini', random_state=layer, \\\n",
      "                                      isFirst=isFirst, min_samples_leaf=10\\\n",
      "                                     )\n",
      "    feval=roc_metrix_mult\n",
      "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
      "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
      "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
      "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
      "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
      "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
      "    test_loss = enhancedDTree.getTestLoss(feval)\n",
      "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
      "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
      "    \n",
      "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
      "# #     if vaild_loss[1] < last_vaild_loss: \n",
      "#         if not isFirst: enhancedDTree.remove_last_items()\n",
      "# #         early_stop_up += 1\n",
      "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
      "#             break\n",
      "#         continue\n",
      "        \n",
      "    last_train_loss = train_loss[1]\n",
      "    last_vaild_loss = vaild_loss[1]\n",
      "    \n",
      "    \n",
      "    # 打印信息\n",
      "#     all_false_data_index = np.where(all_pass_data_mask == False)[0]\n",
      "#     X_test_np = X_test[all_np_data_index]\n",
      "    \n",
      "    X_train_np = enhancedDTree.X_train_np\n",
      "    y_train_np = enhancedDTree.y_train_np\n",
      "    X_train_pass_lt = enhancedDTree.pass_data_x_list\n",
      "    y_train_pass_lt = enhancedDTree.pass_data_y_list\n",
      "    y_train_pass_all = np.array([i for j in y_train_pass_lt for i in j])\n",
      "    if layer != 1:\n",
      "        print(\"%d [train - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(y_train_pass_lt[-1]), len(np.where(y_train_pass_lt[-1] == 1)[0]), \n",
      "                                    len(y_train_pass_all), len(np.where(y_train_pass_all == 1)[0]), \n",
      "                                    len(y_train_np), len(np.where(y_train_np == 1)[0]) ))\n",
      "    \n",
      "    now_pass_test_data_id = np.where(now_pass_data_mask==True)[0]\n",
      "    now_np_test_data_id = np.where(now_pass_data_mask==False)[0]\n",
      "    last_pass_test_data_id = np.where(all_pass_data_mask==True)[0]\n",
      "    all_pass_test_data_id = np.hstack((now_pass_test_data_id, last_pass_test_data_id))\n",
      "    now_test_y = real_y[~all_pass_data_mask]\n",
      "    print(\"%d [test - now p:%d/1:%d | all p:%d/1:%d | np:%d/1:%d] \" % (layer,  \n",
      "                                    len(now_pass_test_data_id), len(np.where(now_test_y[now_pass_test_data_id] == 1)[0]), \n",
      "                                    len(all_pass_test_data_id), len(np.where(real_y[all_pass_test_data_id] == 1)[0]), \n",
      "                                    len(now_np_test_data_id), len(np.where(now_test_y[now_np_test_data_id] == 1)[0]) ))\n",
      "    \n",
      "    print(all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0])\n",
      "#     print(np.where(now_test_y[now_np_test_data_id] == 1)[0], len(np.where(now_test_y[now_np_test_data_id] == 1)[0]))\n",
      "\n",
      "    #len(pass_data_id),\n",
      "#                                       len(np.where(real_y[data_mask] == 1)[0]), \\\n",
      "#                                       len(X_test_np) - len(pass_data_id), \\\n",
      "#                                       len(np.where(real_y[np_data_id] == 1)[0])   ))#, end=\"\")\n",
      "    ### stackplot\n",
      "#     pass_data_len.append(len(pass_data_id))\n",
      "#     pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
      "    ### stackplot\n",
      "    if len(now_pass_test_data_id) == 0: early_stop += 1\n",
      "        \n",
      "    print(\"train loss\", train_loss)\n",
      "    print(\"pass train loss\", pass_train_loss)\n",
      "    print(\"pass train loss now\", pass_train_loss_now)\n",
      "    print(\"vaild loss\", vaild_loss)\n",
      "    print(\"pass vaild loss\", pass_vaild_loss)\n",
      "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
      "    print(\"test loss\", test_loss)\n",
      "    print(\"pass test loss\", pass_test_loss)\n",
      "    print(\"pass test loss now\", pass_test_loss_now)\n",
      "    \n",
      "    ts = time.time()\n",
      "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
      "    print(tm)\n",
      "    \n",
      "    \n",
      "#     tmp_all_data_mask = all_false_data_index[~now_pass_data_mask]\n",
      "#     test_y[tmp_all_data_mask] = p_test[~now_pass_data_mask]\n",
      "    if tmp_test_loss < metrics.roc_auc_score(y_test, test_y):\n",
      "        tmp_test_loss =  metrics.roc_auc_score(y_test, test_y)\n",
      "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
      "        best_test_y = test_y.copy()\n",
      "    print(\"best test loss:\", tmp_test_loss)\n",
      "    \n",
      "    train_loss_lt.append(train_loss[1])\n",
      "    pass_train_loss_lt.append(pass_train_loss[1])\n",
      "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
      "    vaild_loss_lt.append(vaild_loss[1])\n",
      "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
      "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
      "    test_loss_lt.append(test_loss[1])\n",
      "    pass_test_loss_lt.append(pass_test_loss[1])\n",
      "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
      "    \n",
      "    \n",
      "#     if len(pass_data_rate_lt) == 0:\n",
      "#         pass_data_rate_lt.append(len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(0)\n",
      "#     else:\n",
      "#         pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(now_pass_data_mask[now_pass_data_mask==True])/len(X_test))\n",
      "#         pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
      "    # 打印信息结束\n",
      "    \n",
      "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
      "#     if layer > maxlayer or early_stop > 5:\n",
      "#         break\n",
      "        \n",
      "    all_pass_data_mask[~all_pass_data_mask] = now_pass_data_mask\n",
      "    \n",
      "#     if layer == 2: break\n",
      "    if layer > 100: break\n",
      "%history\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.975534041239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pass_data_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 99680, 99681, 99682], dtype=int64)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_pass_data_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pass_test_data_id.shape, now_np_test_data_id.shape, all_pass_test_data_id.shape[0] + now_np_test_data_id.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14452, 16457, 16589, 29850, 35421, 36247, 36382, 39375, 42683,\n",
       "        45881, 47322, 50637, 50928, 53114, 54670, 70282, 75955, 76901,\n",
       "        87462, 89825, 92182, 93112, 94984, 95631], dtype=int64),)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(real_y[all_pass_test_data_id] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(real_y[now_np_test_data_id] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1583,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_np_test_data_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, numpy.int64 found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-ab664e274da8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow_np_test_data_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, numpy.int64 found"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1629,  2197,  2575,  3608,  3756,  4425,  5010,  5137,  5167,\n",
       "         6065,  6689,  7032,  7440,  7829,  8872,  9176,  9469,  9668,\n",
       "         9773, 10348, 12187, 12273, 12412, 12438, 12912, 14688, 16658,\n",
       "        16705, 16727, 16860, 17331, 17750, 18880, 19222, 20430, 20440,\n",
       "        20627, 21372, 21497, 22319, 22651, 24928, 25027, 26157, 26850,\n",
       "        26971, 28269, 28453, 29317, 30318, 30334, 30392, 30812, 31600,\n",
       "        31637, 31834, 33153, 33302, 34092, 34610, 35261, 35505, 35705,\n",
       "        35993, 36074, 36346, 36834, 36973, 37930, 37970, 38173, 39141,\n",
       "        40012, 41116, 41458, 41736, 42010, 42442, 42651, 43149, 43299,\n",
       "        43376, 43967, 44084, 44687, 44806, 45353, 45483, 45665, 46396,\n",
       "        46550, 46634, 46754, 47956, 48035, 48098, 49705, 51463, 51622,\n",
       "        51757, 52085, 52295, 53977, 54392, 55512, 55555, 56131, 56190,\n",
       "        56200, 56967, 56978, 57137, 57532, 57629, 57851, 58109, 59207,\n",
       "        59330, 60162, 60502, 63063, 63767, 65122, 68046, 69185, 69969,\n",
       "        70071, 70200, 70662, 70830, 71023, 71394, 71427, 74622, 75474,\n",
       "        75745, 76089, 77177, 77181, 78085, 78110, 78141, 78558, 78639,\n",
       "        79580, 80528, 80551, 81849, 82410, 83694, 84404, 84448, 85799,\n",
       "        86108, 86408, 86740, 87927, 88012, 88404, 88872, 89502, 89508,\n",
       "        91278, 93267, 93664, 93693, 93793, 93874, 94608, 95476, 96058,\n",
       "        96512, 96680, 96691, 97166, 97404, 97459, 97680, 97705, 98263,\n",
       "        98404, 99640], dtype=int64),)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(real_y == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(real_y[now_np_test_data_id] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182440,)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([i for j in y_train_pass_lt for i in j]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train_pass_lt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182142,), (117,), (39,))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pass_lt[0].shape, y_train_pass_lt[1].shape, y_train_pass_lt[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97975,), (1708,))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mask[data_mask == True].shape, data_mask[data_mask == False].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0,), (99683,))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_mask[all_data_mask == True].shape, all_data_mask[all_data_mask == False].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99683, 30)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[all_false_data_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99683, 30)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, True, False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1.0], dtype=np.float64)[0]\n",
    "print(type(a)), type(a) == np.float64, type(a) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer: 1\n",
      "X_train.shape, y_train.shape:(157355, 30)(157355,)\n",
      "X_valid.shape, y_valid.shape:(27769, 30)(27769,)\n",
      "----start train\n",
      "all data ('roc', 0.94422210864178968)\n",
      "train data ('roc', 0.95781738883637257)\n",
      "valid data ('roc', 0.86694491048664024)\n",
      "mean of all impurity:0.0\n",
      "pass node id shape:(13,)\n",
      "pass data shape:(1364, 30) (166,)\n",
      "not pass data shape:(183760, 30) (8838,)\n",
      "all data shape:185124\n",
      "mean of all impurity:0.141738114294\n",
      "pass node id shape:(36,)\n",
      "pass test data shape: 99575\n",
      "not pass test data shape: 108\n",
      "pass test data ('roc', 0.90879338064534598)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EnhancedDTree' object has no attribute 'getTrainLoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-50363101b318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_false_data_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_test\u001b[0m \u001b[1;33m=\u001b[0m         \u001b[0menhancedDTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainModelLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_data_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m                                       \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroc_metrix_mult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m                                       \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m                                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroc_metrix_mult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menhancedDTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrainLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mpass_train_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menhancedDTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPassTrainLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mpass_train_loss_now\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menhancedDTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPassTrainLossNow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EnhancedDTree' object has no attribute 'getTrainLoss'"
     ]
    }
   ],
   "source": [
    "### stackplot\n",
    "pass_data_len = []\n",
    "pass_data_pos_len = []\n",
    "### stackplot\n",
    "\n",
    "# 统计信息\n",
    "train_loss_lt = []\n",
    "pass_train_loss_lt = []\n",
    "pass_train_loss_lt_now = []\n",
    "vaild_loss_lt = []\n",
    "pass_vaild_loss_lt = []\n",
    "pass_vaild_loss_lt_now = []\n",
    "test_loss_lt = []\n",
    "pass_test_loss_lt = []\n",
    "pass_test_loss_lt_now = []\n",
    "pass_data_rate_lt = []\n",
    "pass_data_rate_train_lt = []\n",
    "\n",
    "# 数据\n",
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "X_test = X_test.copy()\n",
    "test_y = np.array(([0.0] * len(X_test)))\n",
    "all_data_mask = np.array([False] * len(X_test))\n",
    "data_mask = np.array([False] * len(X_test))\n",
    "real_y = y_test.copy()\n",
    "\n",
    "# 不均衡数据进行layer\n",
    "X_train_np = X\n",
    "y_train_np = y\n",
    "maxlayer = 100\n",
    "layer = 0\n",
    "\n",
    "# 不降低不更新\n",
    "last_train_loss = 0\n",
    "last_vaild_loss = 0\n",
    "\n",
    "# enhancedDTree = EnhancedDTree.EnhancedDTree(len(X_train), len(X_test))\n",
    "enhancedDTree = EnhancedDTree.EnhancedDTree()\n",
    "counter = 0\n",
    "early_stop = 0\n",
    "early_stop_up = 0\n",
    "\n",
    "while 1:\n",
    "    layer += 1\n",
    "    print()\n",
    "    print(\"layer:\", layer)\n",
    "    X = X_train_np\n",
    "    y = y_train_np\n",
    "    if layer == 1: isFirst = True\n",
    "    else: isFirst = False\n",
    "        \n",
    "    clf, data_mask, all_false_data_index, p_test = \\\n",
    "        enhancedDTree.TrainModelLayer(X, y, X_test, all_data_mask, test_y, real_y, verbose=True, \\\n",
    "                                      feval=roc_metrix_mult, criterion='gini', random_state=layer, \\\n",
    "                                      min_samples_leaf=10\\\n",
    "                                     )\n",
    "    feval=roc_metrix_mult\n",
    "    train_loss = enhancedDTree.getTrainLoss(feval)\n",
    "    pass_train_loss = enhancedDTree.getPassTrainLoss(feval)\n",
    "    pass_train_loss_now = enhancedDTree.getPassTrainLossNow(feval)\n",
    "    vaild_loss = enhancedDTree.getVaildLoss(feval)\n",
    "    pass_vaild_loss = enhancedDTree.getPassVaildLoss(feval)\n",
    "    pass_vaild_loss_now = enhancedDTree.getPassVaildLossNow(feval)\n",
    "    test_loss = enhancedDTree.getTestLoss(feval)\n",
    "    pass_test_loss = enhancedDTree.getPassTestLoss(feval)\n",
    "    pass_test_loss_now = enhancedDTree.getPassTestLossNow(feval)\n",
    "    \n",
    "#     if train_loss[1] < last_train_loss and vaild_loss[1] < last_vaild_loss: \n",
    "# #     if vaild_loss[1] < last_vaild_loss: \n",
    "#         if not isFirst: enhancedDTree.remove_last_items()\n",
    "# #         early_stop_up += 1\n",
    "#         if layer > maxlayer or early_stop > 5 or early_stop_up > 15:\n",
    "#             break\n",
    "#         continue\n",
    "        \n",
    "    last_train_loss = train_loss[1]\n",
    "    last_vaild_loss = vaild_loss[1]\n",
    "    \n",
    "    X_train_np = enhancedDTree.X_train_np\n",
    "    y_train_np = enhancedDTree.y_train_np\n",
    "    \n",
    "    # 打印信息\n",
    "    pass_data_id = data_mask[data_mask==True]\n",
    "#     all_false_data_index = np.where(all_data_mask == False)[0]\n",
    "    X_test_np = X_test[all_false_data_index]\n",
    "    print(\"%d [p:%d,1:%d/np:%d] \" % (layer, len(pass_data_id),\\\n",
    "                                      len(np.where(y_train_np == 1)), \\\n",
    "                                      len(X_test_np) - len(pass_data_id)))#, end=\"\")\n",
    "    ### stackplot\n",
    "    pass_data_len.append(len(pass_data_id))\n",
    "    pass_data_pos_len.append(len(np.where(y_train_np == 1)[0]))\n",
    "    ### stackplot\n",
    "    if len(pass_data_id) == 0: early_stop += 1\n",
    "        \n",
    "    print(\"train loss\", train_loss)\n",
    "    print(\"pass train loss\", pass_train_loss)\n",
    "    print(\"pass train loss now\", pass_train_loss_now)\n",
    "    print(\"vaild loss\", vaild_loss)\n",
    "    print(\"pass vaild loss\", pass_vaild_loss)\n",
    "    print(\"pass vaild loss now\", pass_vaild_loss_now)\n",
    "    print(\"test loss\", test_loss)\n",
    "    print(\"pass test loss\", pass_test_loss)\n",
    "    print(\"pass test loss now\", pass_test_loss_now)\n",
    "    \n",
    "    ts = time.time()\n",
    "    tm = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(tm)\n",
    "    \n",
    "    \n",
    "#     tmp_all_data_mask = all_false_data_index[~data_mask]\n",
    "#     test_y[tmp_all_data_mask] = p_test[~data_mask]\n",
    "    tmp_test_loss = metrics.roc_auc_score(y_test, test_y)\n",
    "#     tmp_test_loss = metrics.accuracy_score(y_sub, test_y)\n",
    "    best_test_y = test_y.copy()\n",
    "    print(\"best test loss:\", tmp_test_loss)\n",
    "    \n",
    "    train_loss_lt.append(train_loss[1])\n",
    "    pass_train_loss_lt.append(pass_train_loss[1])\n",
    "    pass_train_loss_lt_now.append(pass_train_loss_now[1])\n",
    "    vaild_loss_lt.append(vaild_loss[1])\n",
    "    pass_vaild_loss_lt.append(pass_vaild_loss[1])\n",
    "    pass_vaild_loss_lt_now.append(pass_vaild_loss_now[1])\n",
    "    test_loss_lt.append(test_loss[1])\n",
    "    pass_test_loss_lt.append(pass_test_loss[1])\n",
    "    pass_test_loss_lt_now.append(pass_test_loss_now[1])\n",
    "    if len(pass_data_rate_lt) == 0:\n",
    "        pass_data_rate_lt.append(len(data_mask[data_mask==True])/len(X_test))\n",
    "        pass_data_rate_train_lt.append(0)\n",
    "    else:\n",
    "        pass_data_rate_lt.append(pass_data_rate_lt[-1]+len(data_mask[data_mask==True])/len(X_test))\n",
    "        pass_data_rate_train_lt.append(pass_data_rate_train_lt[-1]+len(enhancedDTree.pass_data_y_list[-1])/len(X_train))\n",
    "    # 打印信息结束\n",
    "    \n",
    "#     if X_train_np.shape[0] < 10 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10 or early_stop > 5:\n",
    "    if layer > maxlayer or early_stop > 5:\n",
    "        break\n",
    "        \n",
    "    all_data_mask[~all_data_mask] = data_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.9798360803747881,\n",
       " 0.9829860658286769,\n",
       " 0.9839691823079161,\n",
       " 0.9853435390186892,\n",
       " 0.9857046838477975,\n",
       " 0.9862263374898428,\n",
       " 0.9863768145019712,\n",
       " 0.9865573869165254,\n",
       " 0.9868282455383566,\n",
       " 0.9871793585666563,\n",
       " 0.9873599309812104,\n",
       " 0.9875405033957646,\n",
       " 0.9877511712127445,\n",
       " 0.9878113620175959,\n",
       " 0.987971870830533,\n",
       " 0.987971870830533,\n",
       " 0.98799193443215,\n",
       " 0.9880220298345758,\n",
       " 0.9880922524402357,\n",
       " 0.9881223478426614,\n",
       " 0.98813237964347,\n",
       " 0.9881725068467042,\n",
       " 0.9882427294523641,\n",
       " 0.9883229838588327,\n",
       " 0.9884032382653012,\n",
       " 0.9884834926717697,\n",
       " 0.9885436834766211,\n",
       " 0.9885737788790468,\n",
       " 0.9886239378830897,\n",
       " 0.9886841286879411,\n",
       " 0.9887844466960267,\n",
       " 0.9888446375008781,\n",
       " 0.9888446375008781,\n",
       " 0.9888747329033039,\n",
       " 0.9888847647041125,\n",
       " 0.9889048283057296,\n",
       " 0.9889349237081553,\n",
       " 0.9889449555089639,\n",
       " 0.988965019110581,\n",
       " 0.9889750509113896,\n",
       " 0.9889750509113896,\n",
       " 0.9889750509113896,\n",
       " 0.9889951145130067,\n",
       " 0.9890151781146238,\n",
       " 0.9890352417162409,\n",
       " 0.9890352417162409]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_data_rate_lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.9816117091179037,\n",
       " 0.9838688642998304,\n",
       " 0.9853535708194978,\n",
       " 0.9860257014736715,\n",
       " 0.986266464693077,\n",
       " 0.9865272915140997,\n",
       " 0.986747991131888,\n",
       " 0.9869586589488679,\n",
       " 0.9870790405585707,\n",
       " 0.9871994221682734,\n",
       " 0.9875003761925303,\n",
       " 0.9876006942006159,\n",
       " 0.9877010122087015,\n",
       " 0.9877311076111273,\n",
       " 0.9877912984159787,\n",
       " 0.9878213938184044,\n",
       " 0.9878514892208301,\n",
       " 0.9879518072289157,\n",
       " 0.9879919344321499,\n",
       " 0.9880220298345757,\n",
       " 0.9880521252370014,\n",
       " 0.9880922524402356,\n",
       " 0.9882527612531726,\n",
       " 0.988312952058024,\n",
       " 0.9883530792612583,\n",
       " 0.9884333336677268,\n",
       " 0.9884533972693439,\n",
       " 0.9884834926717696,\n",
       " 0.9885336516758124,\n",
       " 0.9885637470782381,\n",
       " 0.988613906082281,\n",
       " 0.9887242558911752,\n",
       " 0.9887543512936009,\n",
       " 0.9887643830944095,\n",
       " 0.9888245738992609,\n",
       " 0.9888346057000695,\n",
       " 0.9888647011024952,\n",
       " 0.988894796504921,\n",
       " 0.9889048283057296,\n",
       " 0.9889449555089638,\n",
       " 0.988985082712198,\n",
       " 0.9890051463138151,\n",
       " 0.9890252099154322,\n",
       " 0.9890352417162408,\n",
       " 0.9890553053178579,\n",
       " 0.9890653371186665,\n",
       " 0.9891154961227093,\n",
       " 0.989145591525135,\n",
       " 0.9891556233259436,\n",
       " 0.9891556233259436,\n",
       " 0.9891756869275607,\n",
       " 0.9891957505291779,\n",
       " 0.989215814130795,\n",
       " 0.989215814130795,\n",
       " 0.9892258459316036,\n",
       " 0.9892358777324122,\n",
       " 0.9892760049356464,\n",
       " 0.9892760049356464,\n",
       " 0.9892960685372635,\n",
       " 0.9893261639396892,\n",
       " 0.9893261639396892,\n",
       " 0.9893261639396892]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_data_rate_lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.9826872798772714,\n",
       " 0.9848101812838962,\n",
       " 0.9862308506730624,\n",
       " 0.9869654933990191,\n",
       " 0.9873490201162465,\n",
       " 0.9876353147079796,\n",
       " 0.9878405825284675,\n",
       " 0.9880566539184548,\n",
       " 0.9881592878286987,\n",
       " 0.9883807610034356,\n",
       " 0.988629243101921,\n",
       " 0.9887102698731662,\n",
       " 0.988748082366414,\n",
       " 0.9887750912901624,\n",
       " 0.9888723234156567,\n",
       " 0.9888993323394051,\n",
       " 0.9889479484021522,\n",
       " 0.9890451805276465,\n",
       " 0.9890775912361446,\n",
       " 0.9891100019446427,\n",
       " 0.989120805514142,\n",
       " 0.9891478144378905,\n",
       " 0.9892666537023834,\n",
       " 0.9892990644108816,\n",
       " 0.9893206715498802,\n",
       " 0.9894827250923707,\n",
       " 0.9895151358008688,\n",
       " 0.9895313411551179,\n",
       " 0.9895691536483656,\n",
       " 0.9896015643568637,\n",
       " 0.9896501804196108,\n",
       " 0.9897204036213567,\n",
       " 0.9897582161146045,\n",
       " 0.9897744214688535,\n",
       " 0.9898446446705994,\n",
       " 0.9898500464553491,\n",
       " 0.9898770553790975,\n",
       " 0.9898878589485969,\n",
       " 0.9898986625180962,\n",
       " 0.9899418767960937,\n",
       " 0.9899634839350924,\n",
       " 0.989985091074091,\n",
       " 0.9900283053520885,\n",
       " 0.9900499124910872,\n",
       " 0.9900715196300859,\n",
       " 0.9900769214148356,\n",
       " 0.9901201356928331,\n",
       " 0.9901309392623324,\n",
       " 0.9901525464013311,\n",
       " 0.9901687517555802,\n",
       " 0.9901741535403299,\n",
       " 0.990206564248828,\n",
       " 0.9902389749573262,\n",
       " 0.9902443767420759,\n",
       " 0.9902875910200734,\n",
       " 0.9903037963743224,\n",
       " 0.9903308052980708,\n",
       " 0.9903416088675702,\n",
       " 0.9903578142218192,\n",
       " 0.9903794213608179,\n",
       " 0.9903794213608179,\n",
       " 0.9903902249303173]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_data_rate_train_lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-b0d22e21f9e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_y' is not defined"
     ]
    }
   ],
   "source": [
    "y_test, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass_data_len_ = []\n",
    "for index, item in enumerate(pass_data_len):\n",
    "    if index == 0: \n",
    "        pass_data_len_.append(item)\n",
    "    else:\n",
    "        pass_data_len_.append(item+pass_data_len_[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 98013, 98196, 98275, 98334, 98403, 98432, 98463, 98484, 98489, 98500, 98507, 98511, 98522, 98529, 98538, 98545, 98550, 98553, 98560, 98567, 98575, 98578, 98584, 98590, 98593, 98595, 98601, 98603, 98608, 98609, 98612, 98620, 98622, 98625, 98627, 98630, 98631, 98634, 98637, 98643, 98644, 98646, 98648, 98650, 98650, 98652, 98652, 98652, 98653, 98658, 98658]\n",
      "[0, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26]\n",
      "[99683, 1670, 1487, 1408, 1349, 1280, 1251, 1220, 1199, 1194, 1183, 1176, 1172, 1161, 1154, 1145, 1138, 1133, 1130, 1123, 1116, 1108, 1105, 1099, 1093, 1090, 1088, 1082, 1080, 1075, 1074, 1071, 1063, 1061, 1058, 1056, 1053, 1052, 1049, 1046, 1040, 1039, 1037, 1035, 1033, 1033, 1031, 1031, 1031, 1030, 1025, 1025]\n",
      "[316, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290, 290]\n"
     ]
    }
   ],
   "source": [
    "print(pass_data_len_)\n",
    "print(list(np.array([316]*len(pass_data_len)) - np.array(pass_data_pos_len)))\n",
    "print(list(np.array([99683]*len(pass_data_len)) - np.array(pass_data_len_)))\n",
    "print(pass_data_pos_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pass_data_len_ = []\n",
    "for index, item in enumerate(pass_data_len):\n",
    "    if index == 0: \n",
    "        pass_data_len_.append(item)\n",
    "    else:\n",
    "        pass_data_len_.append(item+pass_data_len_[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 97821, 98103, 98240, 98347, 98375, 98410, 98434, 98456, 98467, 98482, 98493, 98504, 98515, 98521, 98532, 98533, 98534, 98536, 98545, 98552, 98552, 98557, 98570, 98572, 98576, 98583, 98584, 98590, 98591, 98598, 98599, 98602, 98604, 98604, 98609, 98612, 98614, 98614, 98614, 98617, 98618, 98620, 98623, 98625, 98628, 98629, 98630, 98630]\n",
      "[0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25]\n",
      "[99683, 1862, 1580, 1443, 1336, 1308, 1273, 1249, 1227, 1216, 1201, 1190, 1179, 1168, 1162, 1151, 1150, 1149, 1147, 1138, 1131, 1131, 1126, 1113, 1111, 1107, 1100, 1099, 1093, 1092, 1085, 1084, 1081, 1079, 1079, 1074, 1071, 1069, 1069, 1069, 1066, 1065, 1063, 1060, 1058, 1055, 1054, 1053, 1053]\n",
      "[316, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291, 291]\n"
     ]
    }
   ],
   "source": [
    "print(pass_data_len_)\n",
    "print(list(np.array([316]*len(pass_data_len)) - np.array(pass_data_pos_len)))\n",
    "print(list(np.array([99683]*len(pass_data_len)) - np.array(pass_data_len_)))\n",
    "print(pass_data_pos_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAJCCAYAAACMOMDuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVx2TPzMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18ad853fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0222\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "x = range(len(train_loss_lt))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(x[1:],pass_train_loss_lt[1:], label=\"train-pass\", color=\"blue\")\n",
    "plt.plot(x[1:],pass_vaild_loss_lt[1:], label=\"vaild-pass\", color=\"green\")\n",
    "plt.plot(x[1:],pass_test_loss_lt[1:], label=\"test-pass\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(222)\n",
    "plt.plot(x[1:],pass_train_loss_lt_now[1:], label=\"train-pass-now\", color=\"blue\")\n",
    "plt.plot(x[1:],pass_vaild_loss_lt_now[1:], label=\"vaild-pass-now\", color=\"green\")\n",
    "plt.plot(x[1:],pass_test_loss_lt_now[1:], label=\"test-pass-now\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(223)\n",
    "plt.plot(x,train_loss_lt, label=\"train-loss\", color=\"blue\")\n",
    "plt.plot(x,vaild_loss_lt, label=\"vaild-loss\", color=\"green\")\n",
    "plt.plot(x,test_loss_lt, label=\"test-loss\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(224)\n",
    "plt.plot(x,pass_data_rate_lt[:], label=\"data-pass-rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAJCCAYAAABu5NuXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d52b5eb240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0123\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "x = range(len(train_loss_lt))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(x[1:],pass_train_loss_lt[1:], label=\"train-pass\", color=\"blue\")\n",
    "plt.plot(x[1:],pass_vaild_loss_lt[1:], label=\"vaild-pass\", color=\"green\")\n",
    "plt.plot(x[1:],pass_test_loss_lt[1:], label=\"test-pass\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(222)\n",
    "plt.plot(x[1:],pass_train_loss_lt_now[1:], label=\"train-pass-now\", color=\"blue\")\n",
    "plt.plot(x[1:],pass_vaild_loss_lt_now[1:], label=\"vaild-pass-now\", color=\"green\")\n",
    "plt.plot(x[1:],pass_test_loss_lt_now[1:], label=\"test-pass-now\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(223)\n",
    "plt.plot(x,train_loss_lt, label=\"train-loss\", color=\"blue\")\n",
    "plt.plot(x,vaild_loss_lt, label=\"vaild-loss\", color=\"green\")\n",
    "plt.plot(x,test_loss_lt, label=\"test-loss\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(224)\n",
    "plt.plot(x,pass_data_rate_lt[:], label=\"data-pass-rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAJCCAYAAACMOMDuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgghfEiCMSGEEEIIH5JgTAghhBDCh/4/QO6YZ+6p8t4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e686525160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0123\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "x = range(len(train_loss_lt))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(x[1:],pass_train_loss_lt[1:], label=\"train-pass\", color=\"blue\")\n",
    "plt.plot(x[1:],pass_vaild_loss_lt[1:], label=\"vaild-pass\", color=\"green\")\n",
    "plt.plot(x[1:],pass_test_loss_lt[1:], label=\"test-pass\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(222)\n",
    "plt.plot(x[1:],pass_train_loss_lt_now[1:], label=\"train-pass-now\", color=\"blue\")\n",
    "plt.plot(x[1:],pass_vaild_loss_lt_now[1:], label=\"vaild-pass-now\", color=\"green\")\n",
    "plt.plot(x[1:],pass_test_loss_lt_now[1:], label=\"test-pass-now\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(223)\n",
    "plt.plot(x,train_loss_lt, label=\"train-loss\", color=\"blue\")\n",
    "plt.plot(x,vaild_loss_lt, label=\"vaild-loss\", color=\"green\")\n",
    "plt.plot(x,test_loss_lt, label=\"test-loss\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(224)\n",
    "plt.plot(x,pass_data_rate_lt[:], label=\"data-pass-rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import EnhancedForest_multiclass\n",
    "import EnhancedForest\n",
    "import DecomposerForest\n",
    "import LogUtils\n",
    "import AlgorithmUtils\n",
    "import importlib\n",
    "importlib.reload(DecomposerForest)\n",
    "importlib.reload(LogUtils)\n",
    "importlib.reload(EnhancedForest_multiclass)\n",
    "importlib.reload(EnhancedForest)\n",
    "importlib.reload(AlgorithmUtils)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.values\n",
    "# X_test = X_test.values\n",
    "# y_train = y_train.values\n",
    "# y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EnhancedForest_multiclass.EnhancedForest object at 0x000001B2AAB604E0>\n",
      "\n",
      "2018-03-24 11:44:43 layer: 1\n",
      "all data ('roc', 0.8773490138472263)\n",
      "train loss ('roc', 0.8773490138472263)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.85958543498136053)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.87357612287512498)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 1)\n",
      "1 [p:0/np:0] \n",
      "\n",
      "2018-03-24 11:45:18 layer: 2\n",
      "all data ('roc', 0.87252924212905247)\n",
      "[p:3/1:2|n:185121/1:308] \n",
      "train loss ('roc', 0.87252924212905247)\n",
      "pass train loss ('roc', 1.0)\n",
      "pass train loss now ('roc', 1.0)\n",
      "vaild loss ('roc', 0.85314464376913224)\n",
      "pass vaild loss ('roc', 0.75)\n",
      "pass vaild loss now ('roc', 0.75)\n",
      "test loss ('roc', 0.87358114795024977)\n",
      "pass test loss ('mean', 1.0, {1.0})\n",
      "pass test loss now ('mean', 1.0, {1})\n",
      "not pass\n",
      "\n",
      "2018-03-24 11:46:44 layer: 3\n",
      "all data ('roc', 0.8805829365670873)\n",
      "[p:0/1:0|n:185124/1:310] \n",
      "train loss ('roc', 0.8805829365670873)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.86118751651616954)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.88182290619200798)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 1)\n",
      "3 [p:0/np:99683] \n",
      "\n",
      "2018-03-24 11:48:10 layer: 4\n",
      "all data ('roc', 0.87575504858066533)\n",
      "[p:0/1:0|n:185124/1:310] \n",
      "train loss ('roc', 0.87575504858066533)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.85475484157218917)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.8680866424557443)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 11:49:37 layer: 5\n",
      "all data ('roc', 0.8741448507776084)\n",
      "[p:0/1:0|n:185124/1:310] \n",
      "train loss ('roc', 0.8741448507776084)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.86444578804077465)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.87358617302537467)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 1)\n",
      "5 [p:0/np:99683] \n",
      "\n",
      "2018-03-24 11:51:04 layer: 6\n",
      "all data ('roc', 0.87897273876403026)\n",
      "[p:2/1:0|n:185122/1:310] \n",
      "train loss ('roc', 0.87897273876403026)\n",
      "pass train loss ('mean', 0.0, {0.0})\n",
      "pass train loss now ('mean', 0.0, {0})\n",
      "vaild loss ('roc', 0.86119022193891892)\n",
      "pass vaild loss ('mean', 0.0, {0.0})\n",
      "pass vaild loss now ('mean', 0.0, {0})\n",
      "test loss ('roc', 0.87907565344475525)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 11:52:30 layer: 7\n",
      "all data ('roc', 0.87252383128355371)\n",
      "[p:1/1:0|n:185123/1:310] \n",
      "train loss ('roc', 0.87252383128355371)\n",
      "pass train loss ('mean', 0.0, {0.0})\n",
      "pass train loss now ('mean', 0.0, {0})\n",
      "vaild loss ('roc', 0.85798335344655163)\n",
      "pass vaild loss ('mean', 0.0, {0.0})\n",
      "pass vaild loss now ('mean', 0.0, {0})\n",
      "test loss ('roc', 0.87358114795024977)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 11:53:55 layer: 8\n",
      "all data ('roc', 0.87092445517149408)\n",
      "[p:0/1:0|n:185124/1:310] \n",
      "train loss ('roc', 0.87092445517149408)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.85637045022074509)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.87907565344475525)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 11:55:20 layer: 9\n",
      "all data ('roc', 0.87091363348049677)\n",
      "[p:0/1:0|n:185124/1:310] \n",
      "train loss ('roc', 0.87091363348049677)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.85476295784043732)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.87358617302537467)\n",
      "pass test loss (0, 0)\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 11:56:46 layer: 10\n",
      "all data ('roc', 0.87575234315791595)\n",
      "[p:0/1:0|n:185124/1:310] \n",
      "train loss ('roc', 0.87575234315791595)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.86280853601022411)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.87083389520299703)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now ('mean', 0.0, {0})\n",
      "10 [p:1/np:99682] \n",
      "\n",
      "2018-03-24 11:58:12 layer: 11\n",
      "all data ('roc', 0.87898356045502768)\n",
      "[p:2/1:0|n:185122/1:310] \n",
      "train loss ('roc', 0.87898356045502768)\n",
      "pass train loss ('mean', 0.0, {0.0})\n",
      "pass train loss now ('mean', 0.0, {0})\n",
      "vaild loss ('roc', 0.85637856648899324)\n",
      "pass vaild loss ('mean', 0.0, {0.0})\n",
      "pass vaild loss now ('mean', 0.0, {0})\n",
      "test loss ('roc', 0.8763284006975024)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now ('mean', 0.0, {0})\n",
      "not pass\n",
      "\n",
      "2018-03-24 11:59:38 layer: 12\n",
      "all data ('roc', 0.87574422688966791)\n",
      "[p:0/1:0|n:185124/1:310] \n",
      "train loss ('roc', 0.87574422688966791)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.86120374905266572)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.87358114795024977)\n",
      "pass test loss ('roc', 1.0)\n",
      "pass test loss now ('mean', 1.0, {1})\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:01:03 layer: 13\n",
      "all data ('roc', 0.87090822263499801)\n",
      "[p:2/1:0|n:185122/1:310] \n",
      "train loss ('roc', 0.87090822263499801)\n",
      "pass train loss ('mean', 0.0, {0.0})\n",
      "pass train loss now ('mean', 0.0, {0})\n",
      "vaild loss ('roc', 0.85151550800682951)\n",
      "pass vaild loss ('mean', 0.0, {0.0})\n",
      "pass vaild loss now ('mean', 0.0, {0})\n",
      "test loss ('roc', 0.87083892027812193)\n",
      "pass test loss ('roc', 1.0)\n",
      "pass test loss now ('mean', 1.0, {1})\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:02:29 layer: 14\n",
      "all data ('roc', 0.87413132366386159)\n",
      "[p:1/1:1|n:185123/1:309] \n",
      "train loss ('roc', 0.87413132366386159)\n",
      "pass train loss ('mean', 1.0, {1.0})\n",
      "pass train loss now ('mean', 1.0, {1})\n",
      "vaild loss ('roc', 0.85635151226149953)\n",
      "pass vaild loss ('mean', 1.0, {1.0})\n",
      "pass vaild loss now ('mean', 1.0, {1})\n",
      "test loss ('roc', 0.87633342577262741)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now ('mean', 0.0, {0})\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:03:56 layer: 15\n",
      "all data ('roc', 0.87412591281836294)\n",
      "[p:1/1:1|n:185123/1:309] \n",
      "train loss ('roc', 0.87412591281836294)\n",
      "pass train loss ('mean', 0.0, {1.0})\n",
      "pass train loss now ('mean', 0.0, {1})\n",
      "vaild loss ('roc', 0.85958543498136053)\n",
      "pass vaild loss ('mean', 0.0, {1.0})\n",
      "pass vaild loss now ('mean', 0.0, {1})\n",
      "test loss ('roc', 0.87358114795024977)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:05:22 layer: 16\n",
      "all data ('roc', 0.88059105283533545)\n",
      "[p:0/1:0|n:185124/1:310] \n",
      "train loss ('roc', 0.88059105283533545)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.86442143923603043)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.8763284006975024)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "16 [p:0/np:99682] \n",
      "\n",
      "2018-03-24 12:06:48 layer: 17\n",
      "all data ('roc', 0.87735983553822383)\n",
      "[p:0/1:0|n:185124/1:310] \n",
      "train loss ('roc', 0.87735983553822383)\n",
      "pass train loss (0, 0)\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.85960437294060599)\n",
      "pass vaild loss (0, 0)\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.87907565344475525)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:08:15 layer: 18\n",
      "all data ('roc', 0.87252653670630309)\n",
      "[p:1/1:1|n:185123/1:309] \n",
      "train loss ('roc', 0.87252653670630309)\n",
      "pass train loss ('mean', 0.0, {1.0})\n",
      "pass train loss now ('mean', 0.0, {1})\n",
      "vaild loss ('roc', 0.86121186532091387)\n",
      "pass vaild loss ('mean', 0.0, {1.0})\n",
      "pass vaild loss now ('mean', 0.0, {1})\n",
      "test loss ('roc', 0.87358114795024977)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:09:40 layer: 19\n",
      "all data ('roc', 0.8789808550322783)\n",
      "[p:4/1:1|n:185120/1:309] \n",
      "train loss ('roc', 0.8789808550322783)\n",
      "pass train loss ('roc', 1.0)\n",
      "pass train loss now ('roc', 1.0)\n",
      "vaild loss ('roc', 0.85959084582685918)\n",
      "pass vaild loss ('roc', 1.0)\n",
      "pass vaild loss now ('roc', 1.0)\n",
      "test loss ('roc', 0.87908067851988014)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:11:05 layer: 20\n",
      "all data ('roc', 0.86929531940919158)\n",
      "[p:1/1:1|n:185123/1:309] \n",
      "train loss ('roc', 0.86929531940919158)\n",
      "pass train loss ('mean', 1.0, {1.0})\n",
      "pass train loss now ('mean', 1.0, {1})\n",
      "vaild loss ('roc', 0.86604245873008512)\n",
      "pass vaild loss ('mean', 1.0, {1.0})\n",
      "pass vaild loss now ('mean', 1.0, {1})\n",
      "test loss ('roc', 0.87907565344475525)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "20 [p:0/np:99682] \n",
      "\n",
      "2018-03-24 12:12:30 layer: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data ('roc', 0.87210876548915817)\n",
      "[p:1/1:0|n:185122/1:309] \n",
      "train loss ('roc', 0.87252112586080444)\n",
      "pass train loss ('roc', 1.0)\n",
      "pass train loss now ('mean', 0.0, {0})\n",
      "vaild loss ('roc', 0.86442955550427869)\n",
      "pass vaild loss ('roc', 1.0)\n",
      "pass vaild loss now ('mean', 0.0, {0})\n",
      "test loss ('roc', 0.8763284006975024)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:13:57 layer: 22\n",
      "all data ('roc', 0.87858396282129259)\n",
      "[p:1/1:0|n:185122/1:309] \n",
      "train loss ('roc', 0.87897544418677964)\n",
      "pass train loss ('roc', 1.0)\n",
      "pass train loss now ('mean', 0.0, {0})\n",
      "vaild loss ('roc', 0.85797523717830348)\n",
      "pass vaild loss ('roc', 1.0)\n",
      "pass vaild loss now ('mean', 0.0, {0})\n",
      "test loss ('roc', 0.87083389520299703)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:15:23 layer: 23\n",
      "all data ('roc', 0.87857855197579393)\n",
      "[p:0/1:0|n:185123/1:309] \n",
      "train loss ('roc', 0.87897003334128088)\n",
      "pass train loss ('mean', 1.0, {1.0})\n",
      "pass train loss now (0, 1)\n",
      "vaild loss ('roc', 0.86120104362991634)\n",
      "pass vaild loss ('mean', 1.0, {1.0})\n",
      "pass vaild loss now (0, 1)\n",
      "test loss ('roc', 0.8763284006975024)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "23 [p:0/np:99682] \n",
      "\n",
      "2018-03-24 12:16:49 layer: 24\n",
      "all data ('roc', 0.8753450114438508)\n",
      "[p:1/1:1|n:185122/1:308] \n",
      "train loss ('roc', 0.8757469323124174)\n",
      "pass train loss ('mean', 1.0, {1.0})\n",
      "pass train loss now ('mean', 1.0, {1})\n",
      "vaild loss ('roc', 0.8644268500815292)\n",
      "pass vaild loss ('mean', 1.0, {1.0})\n",
      "pass vaild loss now ('mean', 1.0, {1})\n",
      "test loss ('roc', 0.8763284006975024)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "24 [p:0/np:99682] \n",
      "\n",
      "2018-03-24 12:18:16 layer: 25\n",
      "all data ('roc', 0.868457795897005)\n",
      "[p:2/1:0|n:185120/1:308] \n",
      "train loss ('roc', 0.869306141100189)\n",
      "pass train loss ('roc', 0.5)\n",
      "pass train loss now ('mean', 1.0, {0})\n",
      "vaild loss ('roc', 0.8547521361494399)\n",
      "pass vaild loss ('roc', 0.5)\n",
      "pass vaild loss now ('mean', 1.0, {0})\n",
      "test loss ('roc', 0.87358114795024977)\n",
      "pass test loss ('mean', 0.0, {0.0})\n",
      "pass test loss now (0, 1)\n",
      "not pass\n",
      "\n",
      "2018-03-24 12:19:44 layer: 26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-494-7e004e0eedbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoForest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menhancedDTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdecoForest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gini\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdecoForest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroc_metrix_mult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\github_workspace\\ecoForest\\DecomposerForest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, n_estimators, kfold, feval)\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train_np\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[0mstatus_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misFirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus_fit\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSTATUS_FIT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTATUS_BREAK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STATUS_BREAK\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\github_workspace\\ecoForest\\DecomposerForest.py\u001b[0m in \u001b[0;36m_fit_layer\u001b[1;34m(self, X, y, isFirst, layer)\u001b[0m\n\u001b[0;32m    159\u001b[0m                                             \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                                           \u001b[0misFirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misFirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                                           \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m                                          )\n\u001b[0;32m    163\u001b[0m         \u001b[0mlayer_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\github_workspace\\ecoForest\\EnhancedForest_multiclass.py\u001b[0m in \u001b[0;36mTrainModelLayer\u001b[1;34m(self, X, y, X_test, all_data_mask, y_test, real_y, verbose, feval, max_depth, random_state, min_samples_leaf, criterion, dropout, isFirst, num_class, kfold, n_estimators)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misFirst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misLRStacker\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\github_workspace\\ecoForest\\EnhancedForest_multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, verbose, feval, max_depth, random_state, min_samples_leaf, criterion, num_class, kfold, n_estimators)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;31m## vaild\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mforest_leaf_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAlgorithmUtils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_forest_leaf_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[0mest_leaf_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest_leaf_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\github_workspace\\ecoForest\\AlgorithmUtils.py\u001b[0m in \u001b[0;36mget_forest_leaf_index\u001b[1;34m(clf, X_valid, y_valid, num_class)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mnode_id_y_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mnode_id_y_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id_argmax\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_id_y_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id_argmax\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;31m# node_id_argmin = np.argmin(node_id_cnt_p_n, axis=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# node_id_argmax = node_id_argmax * len(X_valid[y_valid==0])/len(X_valid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoForest = DecomposerForest.DecomposerForest(X_train, y_train, X_test, y_test, num_class=2, flag=\"creditcard\", isLRStacker=False)\n",
    "print(decoForest.enhancedDTree)\n",
    "decoForest.set_parameter(criterion=\"gini\", dropout=0.9, min_samples_leaf=10)\n",
    "decoForest.fit(n_estimators=50, kfold=3, feval=roc_metrix_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99949840995957184,\n",
       " [(0, 0.99944825095552903),\n",
       "  (1, 0.99949840995957184),\n",
       "  (2, 0.99944825095552903),\n",
       "  (3, 0.99946831455714613),\n",
       "  (4, 0.99945828275633763),\n",
       "  (5, 0.99945828275633763),\n",
       "  (6, 0.99947834635795474),\n",
       "  (7, 0.99946831455714613),\n",
       "  (8, 0.99946831455714613),\n",
       "  (9, 0.99945828275633763),\n",
       "  (10, 0.99945828275633763),\n",
       "  (11, 0.99944825095552903),\n",
       "  (12, 0.99944825095552903),\n",
       "  (13, 0.99945828275633763),\n",
       "  (14, 0.99944825095552903),\n",
       "  (15, 0.99944825095552903),\n",
       "  (16, 0.99944825095552903),\n",
       "  (17, 0.99944825095552903),\n",
       "  (18, 0.99946831455714613),\n",
       "  (19, 0.99945828275633763),\n",
       "  (20, 0.99944825095552903)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.array(decoForest.test_loss_lt)),list(enumerate(decoForest.test_loss_lt) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAJCCAYAAABAofoFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz/w/xSBwLr83I6cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d52b4b6f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "x = range(len(decoForest.train_loss_lt))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(x[1:],decoForest.pass_train_loss_lt[1:], label=\"train-pass\", color=\"blue\")\n",
    "plt.plot(x[1:],decoForest.pass_vaild_loss_lt[1:], label=\"vaild-pass\", color=\"green\")\n",
    "plt.plot(x[1:],decoForest.pass_test_loss_lt[1:], label=\"test-pass\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(222)\n",
    "plt.plot(x[1:],decoForest.pass_train_loss_lt_now[1:], label=\"train-pass-now\", color=\"blue\")\n",
    "plt.plot(x[1:],decoForest.pass_vaild_loss_lt_now[1:], label=\"vaild-pass-now\", color=\"green\")\n",
    "plt.plot(x[1:],decoForest.pass_test_loss_lt_now[1:], label=\"test-pass-now\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(223)\n",
    "plt.plot(x,decoForest.train_loss_lt, label=\"train-loss\", color=\"blue\")\n",
    "plt.plot(x,decoForest.vaild_loss_lt, label=\"vaild-loss\", color=\"green\")\n",
    "plt.plot(x,decoForest.test_loss_lt, label=\"test-loss\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.subplot(224)\n",
    "plt.plot(x,decoForest.pass_data_rate_lt[:], label=\"data-pass-rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
